{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf1be1b2f55b62c0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Food Classification with CNN - Building a Restaurant Recommendation System\n",
    "\n",
    "This assignment focuses on developing a deep learning-based food classification system using Convolutional Neural Networks (CNNs). You will build a model that can recognize different food categories and use it to return the food preferences of a user.\n",
    "\n",
    "## Learning Objectives\n",
    "- Implement CNNs for image classification\n",
    "- Work with real-world food image datasets\n",
    "- Build a preference-detector system\n",
    "\n",
    "## Background: AI-Powered Food Preference Discovery\n",
    "\n",
    "The system's core idea is simple:\n",
    "\n",
    "1. Users upload 10 photos of dishes they enjoy\n",
    "2. Your CNN classifies these images into the 91 categories\n",
    "3. Based on these categories, the system returns the user's taste profile\n",
    "\n",
    "Your task is to develop the core computer vision component that will power this detection engine.\n",
    "\n",
    "You are given a training (\"train\" folder) and a test (\"test\" folder) dataset which have ~45k and ~22k samples respectively. For each one of the 91 classes there is a subdirectory containing the images of the respective class.\n",
    "\n",
    "## Assignment Requirements\n",
    "\n",
    "### Technical Requirements\n",
    "- Implement your own pytorch CNN architecture for food image classification\n",
    "- Use only the provided training dataset split for training\n",
    "- Train the network from scratch ; No pretrained weights can be used\n",
    "- Report test-accuracy after every epoch\n",
    "- Report all hyperparameters of final model\n",
    "- Use a fixed seed and do not use any CUDA-features that break reproducibility\n",
    "- Use Pytorch 2.6\n",
    "\n",
    "### Deliverables\n",
    "1. Jupyter Notebook with CNN implementation, training code etc.\n",
    "2. README file\n",
    "3. Report (max 3 pages)\n",
    "\n",
    "Submit your report, README and all code files as a single zip file named GROUP_[number]_NC2425_PA. The names and IDs of the group components must be mentioned in the README.\n",
    "Do not include the dataset in your submission.\n",
    "\n",
    "### Grading\n",
    "\n",
    "1. Correct CNN implementation, training runs on the uni DSLab computers according to the README.MD instructions without ANY exceptions on the DSLab machines: 3pt\n",
    "2. Perfect 1:1 reproducibility on DSLab machines: 1pt\n",
    "3. Very clear github-repo-style README.MD with instructions for running the code: 1pt\n",
    "4. Report: 1pt\n",
    "5. Model test performance on test-set: interpolated from 30-80% test-accuracy: 0-3pt\n",
    "6. Pick 10 random pictures of the test set to simulate a user uploading images and report which categories occur how often in these: 1pt\n",
    "7. Bonus point: use an LLM (API) to generate short description / profile of preferences of the simulated user\n",
    "\n",
    "**If there is anything unclear about this assignment please post your question in the Brightspace discussions forum or send an email**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c222e5c4ff1b26",
   "metadata": {},
   "source": [
    "# Loading the datasets\n",
    "The dataset is already split into a train and test set in the directories \"train\" and \"test\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a3e5a5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### IMPORTS ###\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from time import time\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets\n",
    "from datetime import datetime as dt\n",
    "from torchvision.transforms import v2\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "26c3b3bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "### DEVICE ###\n",
    "# Use the GPU to speed up the training\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c270505a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### SEED FOR REPRODUCIBILITY ###\n",
    "random_seed = 13\n",
    "np.random.seed(random_seed)\n",
    "torch.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed_all(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "416f413f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### HYPER-PARAMETERS ###\n",
    "\n",
    "# Model training\n",
    "workers = 8\n",
    "batch_size = 16\n",
    "num_epochs = 100 #50 I hope 100 is high enough\n",
    "lr = 0.01\n",
    "momentum = 0.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aed23ce7b9cbfbf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### DATA LOADING ###\n",
    "# This section loads the data from the train and test folders and applies the transformations\n",
    "# All the images are resized to 256x256 pixels and normalized\n",
    "# The training data is augmented with random transformations\n",
    "\n",
    "# Define the transformations for the data\n",
    "train_transform = v2.Compose([\n",
    "    v2.Resize((256, 256)),\n",
    "    v2.RandomApply([v2.TrivialAugmentWide()], p=0.3),\n",
    "    v2.ToImage(), \n",
    "    v2.ToDtype(torch.float32, scale=True),\n",
    "    v2.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "test_transform = v2.Compose([\n",
    "    v2.Resize((256, 256)),\n",
    "    v2.ToImage(), \n",
    "    v2.ToDtype(torch.float32, scale=True),\n",
    "    v2.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "# Collect the data and set the augmentation\n",
    "train_dataset = datasets.ImageFolder(root='train', transform=train_transform)\n",
    "test_dataset = datasets.ImageFolder(root='test', transform=test_transform) \n",
    "\n",
    "# Prepare the data loaders with the batches, shuffling, and workers\n",
    "train_loader = DataLoader(train_dataset, batch_size, shuffle=True, num_workers=workers)\n",
    "test_loader = DataLoader(test_dataset, batch_size, shuffle=False, num_workers=workers)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7bb30ae14ffa42",
   "metadata": {},
   "source": [
    "# CNN Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fab0ebdf",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "### MODEL TOPOLOGY DEFINITION ###\n",
    "\n",
    "class Block(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Sequential(nn.Conv2d(in_channels, out_channels, 3, stride, 1),\n",
    "                                    nn.BatchNorm2d(out_channels),\n",
    "                                    nn.SiLU())\n",
    "        \n",
    "        self.layer2 = nn.Sequential(nn.Conv2d(out_channels, out_channels, 3, 1, 1),\n",
    "                                    nn.BatchNorm2d(out_channels))\n",
    "        \n",
    "        self.proj = False\n",
    "        if in_channels != out_channels or stride != 1:\n",
    "            self.proj = True\n",
    "            self.p_layer = nn.Conv2d(in_channels, out_channels, 1, stride)\n",
    "\n",
    "    def forward(self, x):\n",
    "        res = x\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        if self.proj:\n",
    "            res = self.p_layer(x)\n",
    "        return nn.ReLU()(out+res)\n",
    "\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    \"\"\"\n",
    "    Made to emulate the Residual Network.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_blocks=None):\n",
    "        super().__init__()\n",
    "        if num_blocks is None:\n",
    "            num_blocks = [3, 4, 6, 3]\n",
    "        self.layer1 = nn.Sequential(nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3),\n",
    "                                    nn.ReLU(),\n",
    "                                    nn.BatchNorm2d(64),\n",
    "                                    nn.MaxPool2d(3, 2, 1))          # 64\n",
    "\n",
    "        self.layer2 = self._make_layer(64, 64, num_blocks[0], 1)\n",
    "        self.layer3 = self._make_layer(64, 128, num_blocks[1])      # 32\n",
    "        self.layer4 = self._make_layer(128, 256, num_blocks[2])     # 16\n",
    "        self.layer5 = self._make_layer(256, 512, num_blocks[3])     # 8\n",
    "\n",
    "        self.layer6 = nn.Sequential(nn.AvgPool2d(8),\n",
    "                                    nn.Flatten(),\n",
    "                                    nn.Dropout(0.25),\n",
    "                                    nn.Linear(512, 91))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.layer5(x)\n",
    "        x = self.layer6(x)\n",
    "        return F.softmax(x, dim=1)\n",
    "    \n",
    "    def _make_layer(self, in_channels, out_channels, blocks, stride=2):\n",
    "        layers = [Block(in_channels, out_channels, stride)]\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(Block(out_channels, out_channels))\n",
    "        return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c602d154e795a27",
   "metadata": {},
   "source": [
    "# Training the model\n",
    "Implement your training process below. Report the test-accuracy after every epoch for the training run of the final model.\n",
    "\n",
    "Hint: before training your model make sure to reset the seed in the training cell, as otherwise the seed may have changed due to previous training runs in the notebook\n",
    "\n",
    "Note: If you implement automatic hyperparameter tuning, split the train set into train and validation subsets for the objective function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7ff7d9d84c06f5d8",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "### TRAINING FUNCTIONS ###\n",
    "\n",
    "def train(model, dataloader, optimizer, loss_fn):\n",
    "    \"\"\"\n",
    "    One epoch of model training.\n",
    "    \"\"\"\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for _, data in enumerate(dataloader):\n",
    "        images, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "        # Forward propagate\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "\n",
    "\n",
    "        # Back-propagate and optimize\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        running_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "def accuracy(model, dataloader):\n",
    "    \"\"\"\n",
    "    One test accuracy test.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    running_accuracy = 0.0\n",
    "    for data in iter(dataloader):\n",
    "        images, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(images)\n",
    "            correct = sum(labels == torch.argmax(outputs, 1)).item()\n",
    "            running_accuracy += correct/batch_size\n",
    "\n",
    "    avg_acc_across_batches = (running_accuracy / len(dataloader)) * 100\n",
    "    print('Accuracy on test set: {:.2f}%'.format(avg_acc_across_batches))\n",
    "    return avg_acc_across_batches\n",
    "\n",
    "\n",
    "def run_epochs(num_epochs, model, optimizer, loss_fn, pride=0.0, max_strikes=5):\n",
    "    \"\"\"\n",
    "    An entire training session.\n",
    "    \"\"\"\n",
    "    strike = 0 # how many time in a row the accuracy can decrease before stopping\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # Start epoch\n",
    "        print(f\"Epoch {epoch+1} begin: {dt.now()}.\")\n",
    "        start = time()\n",
    "\n",
    "        # Train the model\n",
    "        train(model, train_loader, optimizer, loss_fn)\n",
    "        print('Completed training after {:.2f} seconds.'.format((time() - start)))\n",
    "        check_point = time()\n",
    "\n",
    "        # Test the model\n",
    "        acc = accuracy(model, test_loader)\n",
    "        print('Completed testing after {:.2f} seconds.'.format((time() - check_point)))\n",
    "\n",
    "        # Output an update\n",
    "        print('Total epoch time: {:.2f} seconds.'.format((time() - start)))\n",
    "        print('Epoch [{}/{}]'.format(epoch+1, num_epochs))\n",
    "        check_point = time()\n",
    "\n",
    "        # Update emotional state\n",
    "        if pride < acc:\n",
    "            pride = acc\n",
    "            strike = 0\n",
    "            print(\"Check-point!\")\n",
    "            torch.save(model.state_dict(), \"./checkpoint.pth\")\n",
    "\n",
    "        else:\n",
    "            strike += 1\n",
    "            if strike >= max_strikes:\n",
    "                print(\"The model is not improving!\")\n",
    "                torch.save(model.state_dict(), \"./endpoint.pth\")\n",
    "                break\n",
    "\n",
    "        print(\"####################################################################################################\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dde65578",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 begin: 2025-05-16 12:58:09.072842.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Define mental state and start\u001b[39;00m\n\u001b[1;32m     11\u001b[0m peak_accuracy, max_strikes \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m, \u001b[38;5;241m5\u001b[39m\n\u001b[0;32m---> 12\u001b[0m \u001b[43mrun_epochs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpeak_accuracy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_strikes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[17], line 59\u001b[0m, in \u001b[0;36mrun_epochs\u001b[0;34m(num_epochs, model, optimizer, loss_fn, pride, max_strikes)\u001b[0m\n\u001b[1;32m     56\u001b[0m start \u001b[38;5;241m=\u001b[39m time()\n\u001b[1;32m     58\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m---> 59\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCompleted training after \u001b[39m\u001b[38;5;132;01m{:.2f}\u001b[39;00m\u001b[38;5;124m seconds.\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat((time() \u001b[38;5;241m-\u001b[39m start)))\n\u001b[1;32m     61\u001b[0m check_point \u001b[38;5;241m=\u001b[39m time()\n",
      "Cell \u001b[0;32mIn[17], line 12\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, dataloader, optimizer, loss_fn)\u001b[0m\n\u001b[1;32m      8\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m     10\u001b[0m running_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m     13\u001b[0m     images, labels \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device), data[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;66;03m# Forward propagate\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/neural_computing/lib/python3.10/site-packages/torch/utils/data/dataloader.py:439\u001b[0m, in \u001b[0;36mDataLoader.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    437\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator\n\u001b[1;32m    438\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 439\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/neural_computing/lib/python3.10/site-packages/torch/utils/data/dataloader.py:387\u001b[0m, in \u001b[0;36mDataLoader._get_iterator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    385\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    386\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_worker_number_rationality()\n\u001b[0;32m--> 387\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_MultiProcessingDataLoaderIter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/neural_computing/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1040\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter.__init__\u001b[0;34m(self, loader)\u001b[0m\n\u001b[1;32m   1033\u001b[0m w\u001b[38;5;241m.\u001b[39mdaemon \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   1034\u001b[0m \u001b[38;5;66;03m# NB: Process.start() actually take some time as it needs to\u001b[39;00m\n\u001b[1;32m   1035\u001b[0m \u001b[38;5;66;03m#     start a process and pass the arguments over via a pipe.\u001b[39;00m\n\u001b[1;32m   1036\u001b[0m \u001b[38;5;66;03m#     Therefore, we only add a worker to self._workers list after\u001b[39;00m\n\u001b[1;32m   1037\u001b[0m \u001b[38;5;66;03m#     it started, so that we do not call .join() if program dies\u001b[39;00m\n\u001b[1;32m   1038\u001b[0m \u001b[38;5;66;03m#     before it starts, and __del__ tries to join but will get:\u001b[39;00m\n\u001b[1;32m   1039\u001b[0m \u001b[38;5;66;03m#     AssertionError: can only join a started process.\u001b[39;00m\n\u001b[0;32m-> 1040\u001b[0m \u001b[43mw\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1041\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index_queues\u001b[38;5;241m.\u001b[39mappend(index_queue)\n\u001b[1;32m   1042\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_workers\u001b[38;5;241m.\u001b[39mappend(w)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/neural_computing/lib/python3.10/multiprocessing/process.py:121\u001b[0m, in \u001b[0;36mBaseProcess.start\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _current_process\u001b[38;5;241m.\u001b[39m_config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdaemon\u001b[39m\u001b[38;5;124m'\u001b[39m), \\\n\u001b[1;32m    119\u001b[0m        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdaemonic processes are not allowed to have children\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    120\u001b[0m _cleanup()\n\u001b[0;32m--> 121\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sentinel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen\u001b[38;5;241m.\u001b[39msentinel\n\u001b[1;32m    123\u001b[0m \u001b[38;5;66;03m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;66;03m# reference to the process object (see bpo-30775)\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/neural_computing/lib/python3.10/multiprocessing/context.py:224\u001b[0m, in \u001b[0;36mProcess._Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_Popen\u001b[39m(process_obj):\n\u001b[0;32m--> 224\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mProcess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/neural_computing/lib/python3.10/multiprocessing/context.py:288\u001b[0m, in \u001b[0;36mSpawnProcess._Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m    286\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_Popen\u001b[39m(process_obj):\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpopen_spawn_posix\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Popen\n\u001b[0;32m--> 288\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/neural_computing/lib/python3.10/multiprocessing/popen_spawn_posix.py:32\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, process_obj):\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fds \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 32\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/neural_computing/lib/python3.10/multiprocessing/popen_fork.py:19\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturncode \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfinalizer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_launch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/neural_computing/lib/python3.10/multiprocessing/popen_spawn_posix.py:62\u001b[0m, in \u001b[0;36mPopen._launch\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msentinel \u001b[38;5;241m=\u001b[39m parent_r\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(parent_w, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m, closefd\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m---> 62\u001b[0m         \u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetbuffer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     64\u001b[0m     fds_to_close \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "### TRAINING ###\n",
    "\n",
    "# Create model object and connect it to the corresponding processing\n",
    "model = CNN().to(device)\n",
    "\n",
    "# Define loss and optimizer\n",
    "loss_fn = nn.CrossEntropyLoss()  \n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
    "\n",
    "# Define mental state and start\n",
    "peak_accuracy, max_strikes = 0.0, 5\n",
    "run_epochs(num_epochs, model, optimizer, loss_fn, peak_accuracy, max_strikes=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1c8b0bea-7537-4bcd-acd8-dc2a5b30e212",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(CNN(\n",
       "   (layer1): Sequential(\n",
       "     (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
       "     (1): ReLU()\n",
       "     (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "   )\n",
       "   (layer2): Sequential(\n",
       "     (0): Block(\n",
       "       (layer1): Sequential(\n",
       "         (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "         (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (2): SiLU()\n",
       "       )\n",
       "       (layer2): Sequential(\n",
       "         (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "         (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       )\n",
       "     )\n",
       "     (1): Block(\n",
       "       (layer1): Sequential(\n",
       "         (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "         (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (2): SiLU()\n",
       "       )\n",
       "       (layer2): Sequential(\n",
       "         (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "         (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       )\n",
       "     )\n",
       "     (2): Block(\n",
       "       (layer1): Sequential(\n",
       "         (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "         (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (2): SiLU()\n",
       "       )\n",
       "       (layer2): Sequential(\n",
       "         (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "         (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (layer3): Sequential(\n",
       "     (0): Block(\n",
       "       (layer1): Sequential(\n",
       "         (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "         (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (2): SiLU()\n",
       "       )\n",
       "       (layer2): Sequential(\n",
       "         (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "         (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       )\n",
       "       (p_layer): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2))\n",
       "     )\n",
       "     (1): Block(\n",
       "       (layer1): Sequential(\n",
       "         (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "         (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (2): SiLU()\n",
       "       )\n",
       "       (layer2): Sequential(\n",
       "         (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "         (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       )\n",
       "     )\n",
       "     (2): Block(\n",
       "       (layer1): Sequential(\n",
       "         (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "         (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (2): SiLU()\n",
       "       )\n",
       "       (layer2): Sequential(\n",
       "         (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "         (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       )\n",
       "     )\n",
       "     (3): Block(\n",
       "       (layer1): Sequential(\n",
       "         (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "         (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (2): SiLU()\n",
       "       )\n",
       "       (layer2): Sequential(\n",
       "         (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "         (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (layer4): Sequential(\n",
       "     (0): Block(\n",
       "       (layer1): Sequential(\n",
       "         (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "         (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (2): SiLU()\n",
       "       )\n",
       "       (layer2): Sequential(\n",
       "         (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "         (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       )\n",
       "       (p_layer): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2))\n",
       "     )\n",
       "     (1): Block(\n",
       "       (layer1): Sequential(\n",
       "         (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "         (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (2): SiLU()\n",
       "       )\n",
       "       (layer2): Sequential(\n",
       "         (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "         (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       )\n",
       "     )\n",
       "     (2): Block(\n",
       "       (layer1): Sequential(\n",
       "         (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "         (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (2): SiLU()\n",
       "       )\n",
       "       (layer2): Sequential(\n",
       "         (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "         (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       )\n",
       "     )\n",
       "     (3): Block(\n",
       "       (layer1): Sequential(\n",
       "         (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "         (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (2): SiLU()\n",
       "       )\n",
       "       (layer2): Sequential(\n",
       "         (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "         (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       )\n",
       "     )\n",
       "     (4): Block(\n",
       "       (layer1): Sequential(\n",
       "         (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "         (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (2): SiLU()\n",
       "       )\n",
       "       (layer2): Sequential(\n",
       "         (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "         (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       )\n",
       "     )\n",
       "     (5): Block(\n",
       "       (layer1): Sequential(\n",
       "         (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "         (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (2): SiLU()\n",
       "       )\n",
       "       (layer2): Sequential(\n",
       "         (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "         (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (layer5): Sequential(\n",
       "     (0): Block(\n",
       "       (layer1): Sequential(\n",
       "         (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "         (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (2): SiLU()\n",
       "       )\n",
       "       (layer2): Sequential(\n",
       "         (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "         (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       )\n",
       "       (p_layer): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2))\n",
       "     )\n",
       "     (1): Block(\n",
       "       (layer1): Sequential(\n",
       "         (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "         (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (2): SiLU()\n",
       "       )\n",
       "       (layer2): Sequential(\n",
       "         (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "         (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       )\n",
       "     )\n",
       "     (2): Block(\n",
       "       (layer1): Sequential(\n",
       "         (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "         (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (2): SiLU()\n",
       "       )\n",
       "       (layer2): Sequential(\n",
       "         (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "         (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (layer6): Sequential(\n",
       "     (0): AvgPool2d(kernel_size=8, stride=8, padding=0)\n",
       "     (1): Flatten(start_dim=1, end_dim=-1)\n",
       "     (2): Dropout(p=0.25, inplace=False)\n",
       "     (3): Linear(in_features=512, out_features=91, bias=True)\n",
       "   )\n",
       " ),\n",
       " 13,\n",
       " 16,\n",
       " 0.01,\n",
       " 0.75)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model, random_seed, batch_size, lr, momentum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb476e18bd30968c",
   "metadata": {},
   "source": [
    "# Calculating model performance\n",
    "Load the best version of your model ( which should be produced and saved by previous cells ), calculate and report the test accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1eaa35096547d04",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'checkpoint.pth'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m### MODEL COMPARISONS ###\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Load the best model weights\u001b[39;00m\n\u001b[1;32m      4\u001b[0m model \u001b[38;5;241m=\u001b[39m CNN()\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m----> 5\u001b[0m model\u001b[38;5;241m.\u001b[39mload_state_dict(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcheckpoint.pth\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Calculate and present final scores\u001b[39;00m\n\u001b[1;32m      8\u001b[0m final_test_acc \u001b[38;5;241m=\u001b[39m accuracy(model, test_loader)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/neural_computing/lib/python3.10/site-packages/torch/serialization.py:998\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m    995\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    996\u001b[0m     pickle_load_args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 998\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[1;32m    999\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m   1000\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m   1001\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m   1002\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m   1003\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/neural_computing/lib/python3.10/site-packages/torch/serialization.py:445\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    443\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[1;32m    444\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[0;32m--> 445\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    446\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    447\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/neural_computing/lib/python3.10/site-packages/torch/serialization.py:426\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    425\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[0;32m--> 426\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'checkpoint.pth'"
     ]
    }
   ],
   "source": [
    "### MODEL COMPARISONS ###\n",
    "\n",
    "# Load the best model weights\n",
    "model = CNN().to(device)\n",
    "model.load_state_dict(torch.load(\"checkpoint.pth\", weights_only=True))\n",
    "\n",
    "# Calculate and present final scores\n",
    "final_test_acc = accuracy(model, test_loader)\n",
    "print(f\"Final Test Accuracy: {final_test_acc:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ecc6f7f921591e",
   "metadata": {},
   "source": [
    "# Summary of hyperparameters\n",
    "Report the hyperparameters ( learning rate etc ) that you used in your final model for reproducibility."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b6a524e28b431a",
   "metadata": {},
   "source": [
    "# Simulation of random user\n",
    "Pick 10 random pictures of the test set to simulate a user uploading images and report which categories occur how often in these: 1pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b6e8175cacc8dfe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-02T17:04:06.539916Z",
     "start_time": "2025-04-02T17:04:05.929092Z"
    },
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Your code here\n",
    "# Below an example showing the format of the code output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e7a3634bf6861f",
   "metadata": {},
   "source": [
    "# Bonus point\n",
    "Use an LLM (API) to generate a description of the food preference of a user based on 10 images that a potential user could provide. \n",
    "Please include an example of the output of your code, especially if you used an API other than the OpenAI API.\n",
    "\n",
    "This should work well even with differing test images by setting different random seeds for the image selector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6819fa0042485dae",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neural_computing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
