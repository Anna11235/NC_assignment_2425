{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf1be1b2f55b62c0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Food Classification with CNN - Building a Restaurant Recommendation System\n",
    "\n",
    "This assignment focuses on developing a deep learning-based food classification system using Convolutional Neural Networks (CNNs). You will build a model that can recognize different food categories and use it to return the food preferences of a user.\n",
    "\n",
    "## Learning Objectives\n",
    "- Implement CNNs for image classification\n",
    "- Work with real-world food image datasets\n",
    "- Build a preference-detector system\n",
    "\n",
    "## Background: AI-Powered Food Preference Discovery\n",
    "\n",
    "The system's core idea is simple:\n",
    "\n",
    "1. Users upload 10 photos of dishes they enjoy\n",
    "2. Your CNN classifies these images into the 91 categories\n",
    "3. Based on these categories, the system returns the user's taste profile\n",
    "\n",
    "Your task is to develop the core computer vision component that will power this detection engine.\n",
    "\n",
    "You are given a training (\"train\" folder) and a test (\"test\" folder) dataset which have ~45k and ~22k samples respectively. For each one of the 91 classes there is a subdirectory containing the images of the respective class.\n",
    "\n",
    "## Assignment Requirements\n",
    "\n",
    "### Technical Requirements\n",
    "- Implement your own pytorch CNN architecture for food image classification\n",
    "- Use only the provided training dataset split for training\n",
    "- Train the network from scratch ; No pretrained weights can be used\n",
    "- Report test-accuracy after every epoch\n",
    "- Report all hyperparameters of final model\n",
    "- Use a fixed seed and do not use any CUDA-features that break reproducibility\n",
    "- Use Pytorch 2.6\n",
    "\n",
    "### Deliverables\n",
    "1. Jupyter Notebook with CNN implementation, training code etc.\n",
    "2. README file\n",
    "3. Report (max 3 pages)\n",
    "\n",
    "Submit your report, README and all code files as a single zip file named GROUP_[number]_NC2425_PA. The names and IDs of the group components must be mentioned in the README.\n",
    "Do not include the dataset in your submission.\n",
    "\n",
    "### Grading\n",
    "\n",
    "1. Correct CNN implementation, training runs on the uni DSLab computers according to the README.MD instructions without ANY exceptions on the DSLab machines: 3pt\n",
    "2. Perfect 1:1 reproducibility on DSLab machines: 1pt\n",
    "3. Very clear github-repo-style README.MD with instructions for running the code: 1pt\n",
    "4. Report: 1pt\n",
    "5. Model test performance on test-set: interpolated from 30-80% test-accuracy: 0-3pt\n",
    "6. Pick 10 random pictures of the test set to simulate a user uploading images and report which categories occur how often in these: 1pt\n",
    "7. Bonus point: use an LLM (API) to generate short description / profile of preferences of the simulated user\n",
    "\n",
    "**If there is anything unclear about this assignment please post your question in the Brightspace discussions forum or send an email**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c222e5c4ff1b26",
   "metadata": {},
   "source": [
    "# Loading the datasets\n",
    "The dataset is already split into a train and test set in the directories \"train\" and \"test\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "416f413f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "### HYPER-PARAMETER SET-UP ###\n",
    "\n",
    "# Randomization\n",
    "random_seed = 13\n",
    "\n",
    "# Model training\n",
    "workers = 8\n",
    "batch_size = 32\n",
    "num_epochs = 100\n",
    "lr = 0.01\n",
    "momentum = 0.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a3e5a5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### IMPORTS AND DEVICE ###\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from time import time\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets\n",
    "from torch.autograd import Variable\n",
    "from datetime import datetime as dt\n",
    "from torchvision.transforms import v2\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "\n",
    "\n",
    "# Use the GPU to speed up the training\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "aed23ce7b9cbfbf3",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "### DATA LOADING ###\n",
    "\n",
    "# Allow repeatability\n",
    "np.random.seed(random_seed)\n",
    "torch.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed_all(random_seed)\n",
    "\n",
    "# Define the transformer for the data\n",
    "train_transform = v2.Compose([\n",
    "    v2.Resize((256, 256)),\n",
    "    v2.RandomApply([v2.TrivialAugmentWide()], p=0.5),\n",
    "    v2.ToImage(), \n",
    "    v2.ToDtype(torch.float32, scale=True),\n",
    "    v2.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "test_transform = v2.Compose([\n",
    "    v2.Resize((256, 256)),\n",
    "    v2.ToImage(), \n",
    "    v2.ToDtype(torch.float32, scale=True),\n",
    "    v2.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "# Collect the data and set the augmentation\n",
    "train_dataset = datasets.ImageFolder(root='../train', transform=train_transform)\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(train_dataset, [0.9, 0.1])\n",
    "test_dataset = datasets.ImageFolder(root='../test', transform=test_transform) \n",
    "\n",
    "# Prepare the data loaders with the batches, shuffling, and workers\n",
    "train_loader = DataLoader(train_dataset, batch_size, shuffle=True, num_workers=workers)\n",
    "test_loader = DataLoader(test_dataset, batch_size, shuffle=False, num_workers=workers)\n",
    "val_loader = DataLoader(val_dataset, batch_size, shuffle=False, num_workers=workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f0c424fb",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1287, 143, 704)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader), len(val_loader), len(test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7bb30ae14ffa42",
   "metadata": {},
   "source": [
    "# CNN Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fab0ebdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ResNet ###\n",
    "\n",
    "class Block(nn.Module):\n",
    "    def __init__(self, in_channels, mid_channels, stride=1, expansion=4):\n",
    "        super().__init__()\n",
    "        self.layer = nn.Sequential(nn.Conv2d(in_channels, mid_channels, 1, 1, 0),\n",
    "                                   nn.SELU(),\n",
    "                                   nn.BatchNorm2d(mid_channels),\n",
    "                                   nn.Conv2d(mid_channels, mid_channels, 3, stride, 1),\n",
    "                                   nn.SELU(),\n",
    "                                   nn.Conv2d(mid_channels, mid_channels*expansion, 1, 1, 0),\n",
    "                                   nn.BatchNorm2d(mid_channels*expansion))\n",
    "        \n",
    "        self.proj = False\n",
    "        if in_channels != (mid_channels*expansion) or stride != 1:\n",
    "            self.proj = True\n",
    "            self.p_layer = nn.Conv2d(in_channels, mid_channels*4, 1, stride)\n",
    "\n",
    "    def forward(self, x):\n",
    "        res = x\n",
    "        out = self.layer(x)\n",
    "        if self.proj:\n",
    "            res = self.p_layer(x)\n",
    "        return nn.SELU()(out+res)\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    \"\"\"\n",
    "    Made to emulate the Residual Network.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_blocks=None):\n",
    "        super().__init__()\n",
    "        if num_blocks is None:\n",
    "            num_blocks = [3, 4, 6, 3]\n",
    "        self.layer1 = nn.Sequential(nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3),\n",
    "                                    nn.SELU(),\n",
    "                                    nn.MaxPool2d(3, 2, 1))          # 64\n",
    "\n",
    "        self.layer2 = self._make_layer(64, 64, num_blocks[0], 1)\n",
    "        self.layer3 = self._make_layer(256, 128, num_blocks[1])     # 32\n",
    "        self.layer4 = self._make_layer(512, 256, num_blocks[2])     # 16\n",
    "        self.layer5 = self._make_layer(1024, 512, num_blocks[3])    # 8\n",
    "\n",
    "        self.layer6 = nn.Sequential(nn.AvgPool2d(8),\n",
    "                                    nn.Flatten(),\n",
    "                                    nn.Dropout(0.25),\n",
    "                                    nn.Linear(2048, 1024),\n",
    "                                    nn.ReLU(),\n",
    "                                    nn.Dropout(0.25),\n",
    "                                    nn.Linear(1024, 91))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.layer5(x)\n",
    "        x = self.layer6(x)\n",
    "        return x\n",
    "    \n",
    "    def _make_layer(self, in_channels, mid_channels, blocks, stride=2, expansion=4):\n",
    "        layers = [Block(in_channels, mid_channels, stride)]\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(Block(mid_channels*expansion, mid_channels))\n",
    "        return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "27efb73f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "### GoogLeNet ####\n",
    "\n",
    "class Block(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=1, stride=1, padding=0):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)\n",
    "        self.bn = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return F.silu(self.bn(self.conv(x)))\n",
    "\n",
    "\n",
    "class MultiStream(nn.Module):\n",
    "    def __init__(self, in_channels, s1, s3, s5):\n",
    "        super().__init__()\n",
    "        self.stream1 = nn.Sequential(nn.AvgPool2d(3, 1, 1), Block(in_channels, s1))     # 1x1\n",
    "        self.stream2 = nn.Sequential(Block(in_channels, s3), Block(s3, s3, 3, 1, 1))    # 3x3\n",
    "        self.stream3 = nn.Sequential(Block(in_channels, s5), Block(s5, s5, 5, 1, 2))    # 4x4\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return torch.cat([self.stream1(x), self.stream2(x), self.stream3(x)], 1)\n",
    "\n",
    "\n",
    "class GoogLeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, 3, 1, 1), \n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(32), \n",
    "            nn.MaxPool2d(2, 2))  # 256 -> 128\n",
    "\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, 3, 1, 1), \n",
    "            nn.ReLU(), \n",
    "            nn.MaxPool2d(2, 2))  # 128 -> 64\n",
    "\n",
    "        self.layer3 = nn.Sequential(\n",
    "            MultiStream(64, 32, 64, 32),\n",
    "            MultiStream(128, 16, 80, 32),\n",
    "            nn.MaxPool2d(2, 2))  # 64 -> 32\n",
    "\n",
    "        self.layer4 = nn.Sequential(\n",
    "            MultiStream(128, 64, 128, 64),\n",
    "            MultiStream(256, 32, 160, 64),\n",
    "            nn.MaxPool2d(2, 2))  # 32 -> 16\n",
    "\n",
    "        self.layer5 = nn.Sequential(\n",
    "            MultiStream(256, 256, 192, 64),\n",
    "            MultiStream(512, 128, 256, 128),\n",
    "            MultiStream(512, 64, 320, 128),\n",
    "            nn.AvgPool2d(2, 2))  # 16 -> 8\n",
    "\n",
    "        self.layer6 = nn.Sequential(\n",
    "            nn.Conv2d(512, 1024, 4, 2, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(1024),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(1024, 1024, 1, 1, 0),\n",
    "            nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(1024, 1024),\n",
    "            nn.Dropout(),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 91))\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.layer5(x)\n",
    "        x = self.layer6(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4509483a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "### AlexNet ###\n",
    "\n",
    "class AlexNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.blck1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, 11, 4, 4),\n",
    "            nn.SELU(),\n",
    "            nn.MaxPool2d(2, 2))  # 32\n",
    "\n",
    "        self.blck2 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, 7, 2, 3),\n",
    "            nn.SELU(),\n",
    "            nn.MaxPool2d(2, 2))  # 8\n",
    "\n",
    "        self.blck3 = nn.Sequential(\n",
    "            nn.Conv2d(128, 256, 5, 1, 2), \n",
    "            nn.SELU(),\n",
    "            nn.BatchNorm2d(256),\n",
    "            \n",
    "            nn.Conv2d(256, 256, 3, 1, 1), \n",
    "            nn.SELU(),\n",
    "\n",
    "            nn.Conv2d(256, 512, 3, 1, 1), \n",
    "            nn.SELU(),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.MaxPool2d(2, 2))  # 4\n",
    "        \n",
    "        self.blck4 = nn.Sequential(\n",
    "            nn.Conv2d(256, 512, 5, 1, 2), \n",
    "            nn.SELU(),\n",
    "            nn.Conv2d(512, 512, 3, 1, 1), \n",
    "            nn.SELU(),\n",
    "            nn.Conv2d(512, 1024, 3, 1, 1), \n",
    "            nn.SELU(),\n",
    "            nn.BatchNorm2d(1024),\n",
    "            nn.MaxPool2d(2, 2))  # 2\n",
    "        \n",
    "        self.fcll = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Flatten(),\n",
    "            nn.Dropout(0.25),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.25),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 91)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.blck1(x)\n",
    "        x = self.blck2(x)\n",
    "        x = self.blck3(x)\n",
    "        x = self.fcll(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "607c9951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 91])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(batch_size, 3, 256, 256)\n",
    "trial = ResNet()\n",
    "print(trial(x).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c602d154e795a27",
   "metadata": {},
   "source": [
    "# Training the model\n",
    "Implement your training process below. Report the test-accuracy after every epoch for the training run of the final model.\n",
    "\n",
    "Hint: before training your model make sure to reset the seed in the training cell, as otherwise the seed may have changed due to previous training runs in the notebook\n",
    "\n",
    "Note: If you implement automatic hyperparameter tuning, split the train set into train and validation subsets for the objective function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7ff7d9d84c06f5d8",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "### TRAINING FUNCTIONS ###\n",
    "\n",
    "def train(model, dataloader, optimizer, loss_fn, updates):\n",
    "    \"\"\"\n",
    "    One epoch of model training.\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "\n",
    "    running_loss = 0.0\n",
    "    running_accuracy = 0.0\n",
    "    for idx, data in enumerate(dataloader):\n",
    "        images, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "        # Forward propagate\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        correct = sum(labels == torch.argmax(outputs, 1)).item()\n",
    "        running_accuracy += correct/batch_size\n",
    "\n",
    "        # Back-propagate and optimize\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        running_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Print a snapshot of the training\n",
    "        if idx % updates == (updates-1):\n",
    "            avg_loss_across_batches = running_loss / updates\n",
    "            avg_acc_across_batches = (running_accuracy / updates) * 100\n",
    "            print('Batch {}, Loss: {:.3f}, Accuracy: {:.2f}%'.format(idx+1, avg_loss_across_batches, avg_acc_across_batches))\n",
    "            running_loss = 0.0\n",
    "            running_accuracy = 0.0\n",
    "\n",
    "\n",
    "def validate(model, dataloader, loss_fn):\n",
    "    \"\"\"\n",
    "    One validation test.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    running_loss = 0.0\n",
    "    running_accuracy = 0.0\n",
    "    for data in iter(dataloader):\n",
    "        images, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "        # With no gradient to increase efficiency\n",
    "        with torch.no_grad():\n",
    "            outputs = model(images)\n",
    "            correct = sum(labels == torch.argmax(outputs, 1)).item()\n",
    "            running_accuracy += correct/batch_size\n",
    "\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            running_loss += loss.item()\n",
    "\n",
    "    avg_loss_across_batches = running_loss / len(dataloader)\n",
    "    avg_acc_across_batches = (running_accuracy / len(dataloader)) * 100\n",
    "    \n",
    "    print('Val Loss: {:.3f}, Val Accuracy: {:.2f}%'.format(avg_loss_across_batches, avg_acc_across_batches))\n",
    "    return avg_loss_across_batches\n",
    "\n",
    "\n",
    "def accuracy(model, dataloader):\n",
    "    \"\"\"\n",
    "    One test accuracy test.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    running_accuracy = 0.0\n",
    "    for data in iter(dataloader):\n",
    "        images, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(images)\n",
    "            correct = sum(labels == torch.argmax(outputs, 1)).item()\n",
    "            running_accuracy += correct/batch_size\n",
    "\n",
    "    avg_acc_across_batches = (running_accuracy / len(dataloader)) * 100\n",
    "    print('Accuracy: {:.2f}%'.format(avg_acc_across_batches))\n",
    "    return avg_acc_across_batches\n",
    "\n",
    "\n",
    "def run_epochs(num_epochs, model, optimizer, loss_fn, scheduler=None, epoch=0, regret=10.0, grudge=0, pride=0.0, updates=500):\n",
    "    \"\"\"\n",
    "    An entire training session.\n",
    "    \"\"\"\n",
    "    upper = epoch+num_epochs\n",
    "    for epoch in range(epoch, upper):\n",
    "        # Start epoch\n",
    "        print(f\"Epoch {epoch+1} begin: {dt.now()}.\")\n",
    "        start = time()\n",
    "\n",
    "        # Train the model\n",
    "        train(model, train_loader, optimizer, loss_fn, updates)\n",
    "        print('Completed training after {:.2f} seconds.'.format((time() - start)))\n",
    "        check_point = time()\n",
    "\n",
    "        # Validate the model\n",
    "        val_loss = validate(model, val_loader, loss_fn)\n",
    "        print('Completed validation after {:.2f} seconds.'.format((time() - check_point)))\n",
    "        check_point = time()\n",
    "\n",
    "        # Test the model\n",
    "        acc = accuracy(model, test_loader)\n",
    "        print('Completed testing after {:.2f} seconds.'.format((time() - check_point)))\n",
    "\n",
    "        # Update learning rate\n",
    "        if scheduler is not None:\n",
    "            scheduler.step(val_loss)\n",
    "\n",
    "        # Output an update\n",
    "        print('Total epoch time: {:.2f} seconds.'.format((time() - start)))\n",
    "        print('Epoch [{}/{}]'.format(epoch+1, upper))\n",
    "        check_point = time()\n",
    "\n",
    "        # Update emotional state\n",
    "        if pride < acc:\n",
    "            pride = acc\n",
    "            print(\"Check-point!\")\n",
    "            torch.save(model.state_dict(), \"./checkpoint-2.pth\")\n",
    "        grudge = 0 if val_loss <= regret else grudge + 1\n",
    "        regret = val_loss\n",
    "        if 6 < grudge:\n",
    "            print(\"Overfitting!\")\n",
    "            torch.save(model.state_dict(), \"./endpoint-2.pth\")\n",
    "            break\n",
    "        print(\"####################################################################################################\")\n",
    "    return epoch+1, regret, grudge, pride"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b64bdded-ce24-45ce-b181-c14c7cbf419b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    Sourced from \"Focal Loss for Dense Object Detection\" (2017)\n",
    "    \"\"\"\n",
    "    def __init__(self, gamma=0, alpha=None, size_average=True):\n",
    "        super().__init__()\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha\n",
    "        self.size_average = size_average        \n",
    "        if isinstance(alpha, list):\n",
    "            self.alpha = torch.Tensor(alpha).to(device)\n",
    "        if isinstance(alpha, (float, int)):\n",
    "            self.alpha = torch.Tensor([alpha, 1-alpha]).to(device)\n",
    "\n",
    "    def forward(self, outputs, labels):\n",
    "        if 2 < outputs.dim():\n",
    "            outputs = outputs.view(outputs.size(0), outputs.size(1), -1)\n",
    "            outputs = outputs.transpose(1, 2)\n",
    "            outputs = outputs.contiguous().view(-1, outputs.size(2))\n",
    "        labels = labels.view(-1, 1)\n",
    "\n",
    "        logpt = F.log_softmax(outputs, dim=1)  # Change to include dimension\n",
    "        logpt = logpt.gather(1, labels)\n",
    "        logpt = logpt.view(-1)\n",
    "        pt = Variable(logpt.data.exp())\n",
    "\n",
    "        if self.alpha is not None:\n",
    "            if self.alpha.type() != outputs.data.type():\n",
    "                self.alpha = self.alpha.type_as(outputs.data)\n",
    "            at = self.alpha.gather(0, labels.data.view(-1))\n",
    "            logpt *= Variable(at)\n",
    "\n",
    "        loss = -1 * (1-pt)**self.gamma * logpt\n",
    "        if self.size_average:\n",
    "            return loss.mean()\n",
    "        return loss.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "16d0ace4-606a-42f2-a650-45313353acbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3726"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del model\n",
    "del optimizer\n",
    "del scheduler\n",
    "\n",
    "import gc\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "dde65578",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 begin: 2025-05-13 11:46:29.935880.\n",
      "Batch 256, Loss: 4.464, Accuracy: 3.02%\n",
      "Batch 512, Loss: 4.324, Accuracy: 4.50%\n",
      "Batch 768, Loss: 4.215, Accuracy: 5.81%\n",
      "Batch 1024, Loss: 4.138, Accuracy: 6.87%\n",
      "Batch 1280, Loss: 4.088, Accuracy: 7.50%\n",
      "Completed training after 281.83 seconds.\n",
      "Val Loss: 4.140, Val Accuracy: 7.10%\n",
      "Completed validation after 12.19 seconds.\n",
      "Accuracy: 7.23%\n",
      "Completed testing after 58.60 seconds.\n",
      "Total epoch time: 352.62 seconds.\n",
      "Epoch [1/100]\n",
      "Check-point!\n",
      "####################################################################################################\n",
      "Epoch 2 begin: 2025-05-13 11:52:23.603738.\n",
      "Batch 256, Loss: 4.008, Accuracy: 8.61%\n",
      "Batch 512, Loss: 3.959, Accuracy: 9.05%\n",
      "Batch 768, Loss: 3.926, Accuracy: 9.44%\n",
      "Batch 1024, Loss: 3.861, Accuracy: 10.77%\n",
      "Batch 1280, Loss: 3.803, Accuracy: 11.54%\n",
      "Completed training after 281.30 seconds.\n",
      "Val Loss: 4.182, Val Accuracy: 7.36%\n",
      "Completed validation after 12.16 seconds.\n",
      "Accuracy: 8.58%\n",
      "Completed testing after 58.62 seconds.\n",
      "Total epoch time: 352.08 seconds.\n",
      "Epoch [2/100]\n",
      "Check-point!\n",
      "####################################################################################################\n",
      "Epoch 3 begin: 2025-05-13 11:58:16.645488.\n",
      "Batch 256, Loss: 3.749, Accuracy: 12.88%\n",
      "Batch 512, Loss: 3.685, Accuracy: 13.87%\n",
      "Batch 768, Loss: 3.671, Accuracy: 15.17%\n",
      "Batch 1024, Loss: 3.616, Accuracy: 14.50%\n",
      "Batch 1280, Loss: 3.538, Accuracy: 16.89%\n",
      "Completed training after 281.20 seconds.\n",
      "Val Loss: 4.720, Val Accuracy: 7.19%\n",
      "Completed validation after 12.20 seconds.\n",
      "Accuracy: 7.25%\n",
      "Completed testing after 58.60 seconds.\n",
      "Total epoch time: 352.00 seconds.\n",
      "Epoch [3/100]\n",
      "####################################################################################################\n",
      "Epoch 4 begin: 2025-05-13 12:04:08.647724.\n",
      "Batch 256, Loss: 3.462, Accuracy: 18.25%\n",
      "Batch 512, Loss: 3.420, Accuracy: 17.85%\n",
      "Batch 768, Loss: 3.375, Accuracy: 19.03%\n",
      "Batch 1024, Loss: 3.335, Accuracy: 19.93%\n",
      "Batch 1280, Loss: 3.316, Accuracy: 20.53%\n",
      "Completed training after 281.37 seconds.\n",
      "Val Loss: 3.666, Val Accuracy: 15.97%\n",
      "Completed validation after 12.17 seconds.\n",
      "Accuracy: 17.68%\n",
      "Completed testing after 59.44 seconds.\n",
      "Total epoch time: 352.97 seconds.\n",
      "Epoch [4/100]\n",
      "Check-point!\n",
      "####################################################################################################\n",
      "Epoch 5 begin: 2025-05-13 12:10:02.588211.\n",
      "Batch 256, Loss: 3.215, Accuracy: 22.61%\n",
      "Batch 512, Loss: 3.195, Accuracy: 23.18%\n",
      "Batch 768, Loss: 3.195, Accuracy: 22.44%\n",
      "Batch 1024, Loss: 3.168, Accuracy: 22.68%\n",
      "Batch 1280, Loss: 3.126, Accuracy: 24.39%\n",
      "Completed training after 281.65 seconds.\n",
      "Val Loss: 3.202, Val Accuracy: 23.89%\n",
      "Completed validation after 12.19 seconds.\n",
      "Accuracy: 25.98%\n",
      "Completed testing after 58.62 seconds.\n",
      "Total epoch time: 352.46 seconds.\n",
      "Epoch [5/100]\n",
      "Check-point!\n",
      "####################################################################################################\n",
      "Epoch 6 begin: 2025-05-13 12:15:56.009590.\n",
      "Batch 256, Loss: 3.039, Accuracy: 26.00%\n",
      "Batch 512, Loss: 2.986, Accuracy: 27.53%\n",
      "Batch 768, Loss: 2.978, Accuracy: 26.70%\n",
      "Batch 1024, Loss: 2.955, Accuracy: 27.03%\n",
      "Batch 1280, Loss: 2.966, Accuracy: 27.10%\n",
      "Completed training after 281.82 seconds.\n",
      "Val Loss: 3.089, Val Accuracy: 24.17%\n",
      "Completed validation after 12.17 seconds.\n",
      "Accuracy: 27.71%\n",
      "Completed testing after 58.62 seconds.\n",
      "Total epoch time: 352.61 seconds.\n",
      "Epoch [6/100]\n",
      "Check-point!\n",
      "####################################################################################################\n",
      "Epoch 7 begin: 2025-05-13 12:21:49.575561.\n",
      "Batch 256, Loss: 2.827, Accuracy: 29.79%\n",
      "Batch 512, Loss: 2.804, Accuracy: 31.19%\n",
      "Batch 768, Loss: 2.784, Accuracy: 30.62%\n",
      "Batch 1024, Loss: 2.756, Accuracy: 32.01%\n",
      "Batch 1280, Loss: 2.810, Accuracy: 30.77%\n",
      "Completed training after 281.84 seconds.\n",
      "Val Loss: 3.084, Val Accuracy: 26.35%\n",
      "Completed validation after 12.32 seconds.\n",
      "Accuracy: 28.64%\n",
      "Completed testing after 58.71 seconds.\n",
      "Total epoch time: 352.87 seconds.\n",
      "Epoch [7/100]\n",
      "Check-point!\n",
      "####################################################################################################\n",
      "Epoch 8 begin: 2025-05-13 12:27:43.408441.\n",
      "Batch 256, Loss: 2.649, Accuracy: 33.84%\n",
      "Batch 512, Loss: 2.611, Accuracy: 34.51%\n",
      "Batch 768, Loss: 2.638, Accuracy: 34.07%\n",
      "Batch 1024, Loss: 2.619, Accuracy: 34.97%\n",
      "Batch 1280, Loss: 2.601, Accuracy: 35.00%\n",
      "Completed training after 282.70 seconds.\n",
      "Val Loss: 2.862, Val Accuracy: 30.70%\n",
      "Completed validation after 12.30 seconds.\n",
      "Accuracy: 33.40%\n",
      "Completed testing after 58.93 seconds.\n",
      "Total epoch time: 353.93 seconds.\n",
      "Epoch [8/100]\n",
      "Check-point!\n",
      "####################################################################################################\n",
      "Epoch 9 begin: 2025-05-13 12:33:38.294749.\n",
      "Batch 256, Loss: 2.476, Accuracy: 37.41%\n",
      "Batch 512, Loss: 2.448, Accuracy: 38.29%\n",
      "Batch 768, Loss: 2.457, Accuracy: 38.04%\n",
      "Batch 1024, Loss: 2.492, Accuracy: 37.35%\n",
      "Batch 1280, Loss: 2.443, Accuracy: 38.87%\n",
      "Completed training after 284.19 seconds.\n",
      "Val Loss: 2.641, Val Accuracy: 34.75%\n",
      "Completed validation after 12.27 seconds.\n",
      "Accuracy: 38.73%\n",
      "Completed testing after 59.25 seconds.\n",
      "Total epoch time: 355.71 seconds.\n",
      "Epoch [9/100]\n",
      "Check-point!\n",
      "####################################################################################################\n",
      "Epoch 10 begin: 2025-05-13 12:39:34.981353.\n",
      "Batch 256, Loss: 2.321, Accuracy: 40.56%\n",
      "Batch 512, Loss: 2.318, Accuracy: 41.31%\n",
      "Batch 768, Loss: 2.333, Accuracy: 40.70%\n",
      "Batch 1024, Loss: 2.349, Accuracy: 39.39%\n",
      "Batch 1280, Loss: 2.317, Accuracy: 40.72%\n",
      "Completed training after 284.80 seconds.\n",
      "Val Loss: 2.642, Val Accuracy: 34.79%\n",
      "Completed validation after 12.23 seconds.\n",
      "Accuracy: 38.29%\n",
      "Completed testing after 58.78 seconds.\n",
      "Total epoch time: 355.81 seconds.\n",
      "Epoch [10/100]\n",
      "####################################################################################################\n",
      "Epoch 11 begin: 2025-05-13 12:45:30.793849.\n",
      "Batch 256, Loss: 2.157, Accuracy: 44.67%\n",
      "Batch 512, Loss: 2.158, Accuracy: 44.62%\n",
      "Batch 768, Loss: 2.203, Accuracy: 43.95%\n",
      "Batch 1024, Loss: 2.170, Accuracy: 44.30%\n",
      "Batch 1280, Loss: 2.188, Accuracy: 43.90%\n",
      "Completed training after 284.00 seconds.\n",
      "Val Loss: 2.590, Val Accuracy: 37.17%\n",
      "Completed validation after 12.21 seconds.\n",
      "Accuracy: 41.13%\n",
      "Completed testing after 60.06 seconds.\n",
      "Total epoch time: 356.27 seconds.\n",
      "Epoch [11/100]\n",
      "Check-point!\n",
      "####################################################################################################\n",
      "Epoch 12 begin: 2025-05-13 12:51:28.018964.\n",
      "Batch 256, Loss: 2.038, Accuracy: 47.69%\n",
      "Batch 512, Loss: 2.028, Accuracy: 48.47%\n",
      "Batch 768, Loss: 2.037, Accuracy: 47.45%\n",
      "Batch 1024, Loss: 2.068, Accuracy: 46.58%\n",
      "Batch 1280, Loss: 2.038, Accuracy: 48.01%\n",
      "Completed training after 281.73 seconds.\n",
      "Val Loss: 2.727, Val Accuracy: 35.31%\n",
      "Completed validation after 12.19 seconds.\n",
      "Accuracy: 39.64%\n",
      "Completed testing after 58.68 seconds.\n",
      "Total epoch time: 352.60 seconds.\n",
      "Epoch [12/100]\n",
      "####################################################################################################\n",
      "Epoch 13 begin: 2025-05-13 12:57:20.617146.\n",
      "Batch 256, Loss: 1.932, Accuracy: 50.06%\n",
      "Batch 512, Loss: 1.906, Accuracy: 51.22%\n",
      "Batch 768, Loss: 1.920, Accuracy: 50.72%\n",
      "Batch 1024, Loss: 1.919, Accuracy: 50.24%\n",
      "Batch 1280, Loss: 1.901, Accuracy: 49.99%\n",
      "Completed training after 281.05 seconds.\n",
      "Val Loss: 2.573, Val Accuracy: 37.81%\n",
      "Completed validation after 12.20 seconds.\n",
      "Accuracy: 41.63%\n",
      "Completed testing after 58.62 seconds.\n",
      "Total epoch time: 351.87 seconds.\n",
      "Epoch [13/100]\n",
      "Check-point!\n",
      "####################################################################################################\n",
      "Epoch 14 begin: 2025-05-13 13:03:13.456709.\n",
      "Batch 256, Loss: 1.718, Accuracy: 54.72%\n",
      "Batch 512, Loss: 1.770, Accuracy: 53.55%\n",
      "Batch 768, Loss: 1.772, Accuracy: 52.89%\n",
      "Batch 1024, Loss: 1.860, Accuracy: 51.35%\n",
      "Batch 1280, Loss: 1.832, Accuracy: 52.54%\n",
      "Completed training after 281.71 seconds.\n",
      "Val Loss: 2.706, Val Accuracy: 37.67%\n",
      "Completed validation after 12.17 seconds.\n",
      "Accuracy: 40.86%\n",
      "Completed testing after 58.71 seconds.\n",
      "Total epoch time: 352.59 seconds.\n",
      "Epoch [14/100]\n",
      "####################################################################################################\n",
      "Epoch 15 begin: 2025-05-13 13:09:06.050987.\n",
      "Batch 256, Loss: 1.612, Accuracy: 57.13%\n",
      "Batch 512, Loss: 1.652, Accuracy: 55.68%\n",
      "Batch 768, Loss: 1.699, Accuracy: 55.15%\n",
      "Batch 1024, Loss: 1.706, Accuracy: 54.77%\n",
      "Batch 1280, Loss: 1.699, Accuracy: 55.18%\n",
      "Completed training after 281.04 seconds.\n",
      "Val Loss: 2.398, Val Accuracy: 41.91%\n",
      "Completed validation after 12.21 seconds.\n",
      "Accuracy: 45.73%\n",
      "Completed testing after 58.65 seconds.\n",
      "Total epoch time: 351.91 seconds.\n",
      "Epoch [15/100]\n",
      "Check-point!\n",
      "####################################################################################################\n",
      "Epoch 16 begin: 2025-05-13 13:14:58.922028.\n",
      "Batch 256, Loss: 1.493, Accuracy: 60.78%\n",
      "Batch 512, Loss: 1.535, Accuracy: 59.20%\n",
      "Batch 768, Loss: 1.590, Accuracy: 57.68%\n",
      "Batch 1024, Loss: 1.611, Accuracy: 57.39%\n",
      "Batch 1280, Loss: 1.601, Accuracy: 57.46%\n",
      "Completed training after 281.38 seconds.\n",
      "Val Loss: 2.593, Val Accuracy: 40.52%\n",
      "Completed validation after 12.18 seconds.\n",
      "Accuracy: 44.27%\n",
      "Completed testing after 58.66 seconds.\n",
      "Total epoch time: 352.22 seconds.\n",
      "Epoch [16/100]\n",
      "####################################################################################################\n",
      "Epoch 17 begin: 2025-05-13 13:20:51.142381.\n",
      "Batch 256, Loss: 1.410, Accuracy: 62.13%\n",
      "Batch 512, Loss: 1.451, Accuracy: 61.02%\n",
      "Batch 768, Loss: 1.453, Accuracy: 61.30%\n",
      "Batch 1024, Loss: 1.460, Accuracy: 60.79%\n",
      "Batch 1280, Loss: 1.515, Accuracy: 59.28%\n",
      "Completed training after 281.03 seconds.\n",
      "Val Loss: 2.736, Val Accuracy: 38.53%\n",
      "Completed validation after 12.19 seconds.\n",
      "Accuracy: 41.37%\n",
      "Completed testing after 58.64 seconds.\n",
      "Total epoch time: 351.86 seconds.\n",
      "Epoch [17/100]\n",
      "####################################################################################################\n",
      "Epoch 18 begin: 2025-05-13 13:26:43.000786.\n",
      "Batch 256, Loss: 1.314, Accuracy: 64.61%\n",
      "Batch 512, Loss: 1.310, Accuracy: 64.37%\n",
      "Batch 768, Loss: 1.350, Accuracy: 63.84%\n",
      "Batch 1024, Loss: 1.405, Accuracy: 61.65%\n",
      "Batch 1280, Loss: 1.438, Accuracy: 61.44%\n",
      "Completed training after 281.37 seconds.\n",
      "Val Loss: 2.573, Val Accuracy: 42.20%\n",
      "Completed validation after 12.20 seconds.\n",
      "Accuracy: 45.66%\n",
      "Completed testing after 58.64 seconds.\n",
      "Total epoch time: 352.20 seconds.\n",
      "Epoch [18/100]\n",
      "####################################################################################################\n",
      "Epoch 19 begin: 2025-05-13 13:32:35.203290.\n",
      "Batch 256, Loss: 1.196, Accuracy: 67.15%\n",
      "Batch 512, Loss: 1.181, Accuracy: 68.36%\n",
      "Batch 768, Loss: 1.263, Accuracy: 65.39%\n",
      "Batch 1024, Loss: 1.303, Accuracy: 64.98%\n",
      "Batch 1280, Loss: 1.291, Accuracy: 64.76%\n",
      "Completed training after 281.12 seconds.\n",
      "Val Loss: 2.499, Val Accuracy: 43.07%\n",
      "Completed validation after 12.21 seconds.\n",
      "Accuracy: 46.42%\n",
      "Completed testing after 58.63 seconds.\n",
      "Total epoch time: 351.96 seconds.\n",
      "Epoch [19/100]\n",
      "Check-point!\n",
      "####################################################################################################\n",
      "Epoch 20 begin: 2025-05-13 13:38:28.125878.\n",
      "Batch 256, Loss: 1.108, Accuracy: 69.90%\n",
      "Batch 512, Loss: 1.109, Accuracy: 69.86%\n",
      "Batch 768, Loss: 1.201, Accuracy: 67.42%\n",
      "Batch 1024, Loss: 1.205, Accuracy: 66.88%\n",
      "Batch 1280, Loss: 1.223, Accuracy: 66.93%\n",
      "Completed training after 281.26 seconds.\n",
      "Val Loss: 2.527, Val Accuracy: 42.44%\n",
      "Completed validation after 12.17 seconds.\n",
      "Accuracy: 46.37%\n",
      "Completed testing after 58.74 seconds.\n",
      "Total epoch time: 352.17 seconds.\n",
      "Epoch [20/100]\n",
      "####################################################################################################\n",
      "Epoch 21 begin: 2025-05-13 13:44:20.295782.\n",
      "Batch 256, Loss: 0.853, Accuracy: 77.31%\n",
      "Batch 512, Loss: 0.759, Accuracy: 80.16%\n",
      "Batch 768, Loss: 0.711, Accuracy: 81.09%\n",
      "Batch 1024, Loss: 0.679, Accuracy: 81.95%\n",
      "Batch 1280, Loss: 0.706, Accuracy: 81.60%\n",
      "Completed training after 281.05 seconds.\n",
      "Val Loss: 2.193, Val Accuracy: 50.74%\n",
      "Completed validation after 12.21 seconds.\n",
      "Accuracy: 54.67%\n",
      "Completed testing after 58.64 seconds.\n",
      "Total epoch time: 351.90 seconds.\n",
      "Epoch [21/100]\n",
      "Check-point!\n",
      "####################################################################################################\n",
      "Epoch 22 begin: 2025-05-13 13:50:13.152058.\n",
      "Batch 256, Loss: 0.639, Accuracy: 83.25%\n",
      "Batch 512, Loss: 0.647, Accuracy: 83.08%\n",
      "Batch 768, Loss: 0.650, Accuracy: 82.87%\n",
      "Batch 1024, Loss: 0.640, Accuracy: 83.61%\n",
      "Batch 1280, Loss: 0.628, Accuracy: 83.78%\n",
      "Completed training after 281.07 seconds.\n",
      "Val Loss: 2.221, Val Accuracy: 50.94%\n",
      "Completed validation after 12.22 seconds.\n",
      "Accuracy: 54.74%\n",
      "Completed testing after 58.74 seconds.\n",
      "Total epoch time: 352.03 seconds.\n",
      "Epoch [22/100]\n",
      "Check-point!\n",
      "####################################################################################################\n",
      "Epoch 23 begin: 2025-05-13 13:56:06.156080.\n",
      "Batch 256, Loss: 0.625, Accuracy: 83.50%\n",
      "Batch 512, Loss: 0.578, Accuracy: 85.02%\n",
      "Batch 768, Loss: 0.591, Accuracy: 84.68%\n",
      "Batch 1024, Loss: 0.584, Accuracy: 84.91%\n",
      "Batch 1280, Loss: 0.589, Accuracy: 84.84%\n",
      "Completed training after 281.37 seconds.\n",
      "Val Loss: 2.213, Val Accuracy: 51.03%\n",
      "Completed validation after 12.21 seconds.\n",
      "Accuracy: 54.87%\n",
      "Completed testing after 58.71 seconds.\n",
      "Total epoch time: 352.29 seconds.\n",
      "Epoch [23/100]\n",
      "Check-point!\n",
      "####################################################################################################\n",
      "Epoch 24 begin: 2025-05-13 14:01:59.423228.\n",
      "Batch 256, Loss: 0.539, Accuracy: 86.10%\n",
      "Batch 512, Loss: 0.565, Accuracy: 85.60%\n",
      "Batch 768, Loss: 0.557, Accuracy: 85.22%\n",
      "Batch 1024, Loss: 0.556, Accuracy: 85.44%\n",
      "Batch 1280, Loss: 0.585, Accuracy: 85.11%\n",
      "Completed training after 281.43 seconds.\n",
      "Val Loss: 2.247, Val Accuracy: 50.81%\n",
      "Completed validation after 12.21 seconds.\n",
      "Accuracy: 54.83%\n",
      "Completed testing after 58.72 seconds.\n",
      "Total epoch time: 352.37 seconds.\n",
      "Epoch [24/100]\n",
      "####################################################################################################\n",
      "Epoch 25 begin: 2025-05-13 14:07:51.790999.\n",
      "Batch 256, Loss: 0.530, Accuracy: 86.38%\n",
      "Batch 512, Loss: 0.531, Accuracy: 86.60%\n",
      "Batch 768, Loss: 0.550, Accuracy: 85.78%\n",
      "Batch 1024, Loss: 0.527, Accuracy: 85.91%\n",
      "Batch 1280, Loss: 0.556, Accuracy: 85.68%\n",
      "Completed training after 281.39 seconds.\n",
      "Val Loss: 2.209, Val Accuracy: 51.20%\n",
      "Completed validation after 12.18 seconds.\n",
      "Accuracy: 55.02%\n",
      "Completed testing after 58.66 seconds.\n",
      "Total epoch time: 352.23 seconds.\n",
      "Epoch [25/100]\n",
      "Check-point!\n",
      "####################################################################################################\n",
      "Epoch 26 begin: 2025-05-13 14:13:44.974761.\n",
      "Batch 256, Loss: 0.512, Accuracy: 87.00%\n",
      "Batch 512, Loss: 0.517, Accuracy: 86.84%\n",
      "Batch 768, Loss: 0.513, Accuracy: 86.27%\n",
      "Batch 1024, Loss: 0.526, Accuracy: 86.39%\n",
      "Batch 1280, Loss: 0.496, Accuracy: 87.26%\n",
      "Completed training after 281.35 seconds.\n",
      "Val Loss: 2.255, Val Accuracy: 51.16%\n",
      "Completed validation after 12.17 seconds.\n",
      "Accuracy: 54.76%\n",
      "Completed testing after 58.56 seconds.\n",
      "Total epoch time: 352.09 seconds.\n",
      "Epoch [26/100]\n",
      "####################################################################################################\n",
      "Epoch 27 begin: 2025-05-13 14:19:37.060859.\n",
      "Batch 256, Loss: 0.497, Accuracy: 87.37%\n",
      "Batch 512, Loss: 0.493, Accuracy: 87.66%\n",
      "Batch 768, Loss: 0.497, Accuracy: 87.43%\n",
      "Batch 1024, Loss: 0.498, Accuracy: 87.61%\n",
      "Batch 1280, Loss: 0.463, Accuracy: 88.07%\n",
      "Completed training after 281.12 seconds.\n",
      "Val Loss: 2.275, Val Accuracy: 51.29%\n",
      "Completed validation after 12.22 seconds.\n",
      "Accuracy: 55.20%\n",
      "Completed testing after 58.77 seconds.\n",
      "Total epoch time: 352.11 seconds.\n",
      "Epoch [27/100]\n",
      "Check-point!\n",
      "####################################################################################################\n",
      "Epoch 28 begin: 2025-05-13 14:25:30.138402.\n",
      "Batch 256, Loss: 0.475, Accuracy: 87.66%\n",
      "Batch 512, Loss: 0.495, Accuracy: 87.56%\n",
      "Batch 768, Loss: 0.464, Accuracy: 87.96%\n",
      "Batch 1024, Loss: 0.491, Accuracy: 87.81%\n",
      "Batch 1280, Loss: 0.509, Accuracy: 87.06%\n",
      "Completed training after 281.07 seconds.\n",
      "Val Loss: 2.279, Val Accuracy: 51.84%\n",
      "Completed validation after 12.18 seconds.\n",
      "Accuracy: 55.09%\n",
      "Completed testing after 58.67 seconds.\n",
      "Total epoch time: 351.92 seconds.\n",
      "Epoch [28/100]\n",
      "####################################################################################################\n",
      "Epoch 29 begin: 2025-05-13 14:31:22.061377.\n",
      "Batch 256, Loss: 0.496, Accuracy: 87.59%\n",
      "Batch 512, Loss: 0.522, Accuracy: 86.72%\n",
      "Batch 768, Loss: 0.482, Accuracy: 87.78%\n",
      "Batch 1024, Loss: 0.473, Accuracy: 88.05%\n",
      "Batch 1280, Loss: 0.476, Accuracy: 88.10%\n",
      "Completed training after 281.07 seconds.\n",
      "Val Loss: 2.275, Val Accuracy: 51.01%\n",
      "Completed validation after 12.19 seconds.\n",
      "Accuracy: 55.29%\n",
      "Completed testing after 58.70 seconds.\n",
      "Total epoch time: 351.96 seconds.\n",
      "Epoch [29/100]\n",
      "Check-point!\n",
      "####################################################################################################\n",
      "Epoch 30 begin: 2025-05-13 14:37:14.975169.\n",
      "Batch 256, Loss: 0.485, Accuracy: 87.61%\n",
      "Batch 512, Loss: 0.490, Accuracy: 87.49%\n",
      "Batch 768, Loss: 0.474, Accuracy: 87.98%\n",
      "Batch 1024, Loss: 0.489, Accuracy: 88.09%\n",
      "Batch 1280, Loss: 0.489, Accuracy: 87.63%\n",
      "Completed training after 281.45 seconds.\n",
      "Val Loss: 2.264, Val Accuracy: 51.07%\n",
      "Completed validation after 12.18 seconds.\n",
      "Accuracy: 55.27%\n",
      "Completed testing after 58.63 seconds.\n",
      "Total epoch time: 352.25 seconds.\n",
      "Epoch [30/100]\n",
      "####################################################################################################\n",
      "Epoch 31 begin: 2025-05-13 14:43:07.229582.\n",
      "Batch 256, Loss: 0.468, Accuracy: 87.99%\n",
      "Batch 512, Loss: 0.489, Accuracy: 87.62%\n",
      "Batch 768, Loss: 0.470, Accuracy: 88.27%\n",
      "Batch 1024, Loss: 0.475, Accuracy: 87.88%\n",
      "Batch 1280, Loss: 0.497, Accuracy: 87.33%\n",
      "Completed training after 281.40 seconds.\n",
      "Val Loss: 2.252, Val Accuracy: 51.40%\n",
      "Completed validation after 12.23 seconds.\n",
      "Accuracy: 55.26%\n",
      "Completed testing after 58.77 seconds.\n",
      "Total epoch time: 352.40 seconds.\n",
      "Epoch [31/100]\n",
      "####################################################################################################\n",
      "Epoch 32 begin: 2025-05-13 14:48:59.629818.\n",
      "Batch 256, Loss: 0.466, Accuracy: 88.29%\n",
      "Batch 512, Loss: 0.457, Accuracy: 88.67%\n",
      "Batch 768, Loss: 0.463, Accuracy: 88.16%\n",
      "Batch 1024, Loss: 0.504, Accuracy: 87.33%\n",
      "Batch 1280, Loss: 0.481, Accuracy: 87.68%\n",
      "Completed training after 281.37 seconds.\n",
      "Val Loss: 2.277, Val Accuracy: 51.44%\n",
      "Completed validation after 12.20 seconds.\n",
      "Accuracy: 55.30%\n",
      "Completed testing after 58.68 seconds.\n",
      "Total epoch time: 352.25 seconds.\n",
      "Epoch [32/100]\n",
      "Check-point!\n",
      "####################################################################################################\n",
      "Epoch 33 begin: 2025-05-13 14:54:52.841608.\n",
      "Batch 256, Loss: 0.481, Accuracy: 87.67%\n",
      "Batch 512, Loss: 0.485, Accuracy: 87.67%\n",
      "Batch 768, Loss: 0.479, Accuracy: 87.85%\n",
      "Batch 1024, Loss: 0.495, Accuracy: 87.67%\n",
      "Batch 1280, Loss: 0.475, Accuracy: 88.33%\n",
      "Completed training after 281.41 seconds.\n",
      "Val Loss: 2.269, Val Accuracy: 51.77%\n",
      "Completed validation after 12.19 seconds.\n",
      "Accuracy: 55.36%\n",
      "Completed testing after 58.76 seconds.\n",
      "Total epoch time: 352.36 seconds.\n",
      "Epoch [33/100]\n",
      "Check-point!\n",
      "####################################################################################################\n",
      "Epoch 34 begin: 2025-05-13 15:00:46.164176.\n",
      "Batch 256, Loss: 0.477, Accuracy: 88.15%\n",
      "Batch 512, Loss: 0.502, Accuracy: 87.52%\n",
      "Batch 768, Loss: 0.462, Accuracy: 88.49%\n",
      "Batch 1024, Loss: 0.452, Accuracy: 88.73%\n",
      "Batch 1280, Loss: 0.447, Accuracy: 88.37%\n",
      "Completed training after 281.28 seconds.\n",
      "Val Loss: 2.271, Val Accuracy: 51.51%\n",
      "Completed validation after 12.20 seconds.\n",
      "Accuracy: 55.25%\n",
      "Completed testing after 58.72 seconds.\n",
      "Total epoch time: 352.20 seconds.\n",
      "Epoch [34/100]\n",
      "####################################################################################################\n",
      "Epoch 35 begin: 2025-05-13 15:06:38.364143.\n",
      "Batch 256, Loss: 0.481, Accuracy: 88.06%\n",
      "Batch 512, Loss: 0.461, Accuracy: 88.26%\n",
      "Batch 768, Loss: 0.466, Accuracy: 88.09%\n",
      "Batch 1024, Loss: 0.475, Accuracy: 88.04%\n",
      "Batch 1280, Loss: 0.471, Accuracy: 87.50%\n",
      "Completed training after 281.47 seconds.\n",
      "Val Loss: 2.289, Val Accuracy: 50.63%\n",
      "Completed validation after 12.19 seconds.\n",
      "Accuracy: 55.22%\n",
      "Completed testing after 58.64 seconds.\n",
      "Total epoch time: 352.30 seconds.\n",
      "Epoch [35/100]\n",
      "####################################################################################################\n",
      "Epoch 36 begin: 2025-05-13 15:12:30.662425.\n",
      "Batch 256, Loss: 0.460, Accuracy: 87.96%\n",
      "Batch 512, Loss: 0.476, Accuracy: 87.94%\n",
      "Batch 768, Loss: 0.471, Accuracy: 88.06%\n",
      "Batch 1024, Loss: 0.494, Accuracy: 87.63%\n",
      "Batch 1280, Loss: 0.463, Accuracy: 88.17%\n",
      "Completed training after 281.41 seconds.\n",
      "Val Loss: 2.288, Val Accuracy: 50.79%\n",
      "Completed validation after 12.21 seconds.\n",
      "Accuracy: 55.23%\n",
      "Completed testing after 58.69 seconds.\n",
      "Total epoch time: 352.31 seconds.\n",
      "Epoch [36/100]\n",
      "####################################################################################################\n",
      "Epoch 37 begin: 2025-05-13 15:18:22.967611.\n",
      "Batch 256, Loss: 0.470, Accuracy: 87.99%\n",
      "Batch 512, Loss: 0.467, Accuracy: 87.93%\n",
      "Batch 768, Loss: 0.467, Accuracy: 88.43%\n",
      "Batch 1024, Loss: 0.469, Accuracy: 88.07%\n",
      "Batch 1280, Loss: 0.492, Accuracy: 87.74%\n",
      "Completed training after 281.07 seconds.\n",
      "Val Loss: 2.281, Val Accuracy: 51.49%\n",
      "Completed validation after 12.22 seconds.\n",
      "Accuracy: 55.27%\n",
      "Completed testing after 58.71 seconds.\n",
      "Total epoch time: 351.99 seconds.\n",
      "Epoch [37/100]\n",
      "####################################################################################################\n",
      "Epoch 38 begin: 2025-05-13 15:24:14.961624.\n",
      "Batch 256, Loss: 0.488, Accuracy: 87.82%\n",
      "Batch 512, Loss: 0.484, Accuracy: 87.96%\n",
      "Batch 768, Loss: 0.463, Accuracy: 88.39%\n",
      "Batch 1024, Loss: 0.467, Accuracy: 88.16%\n",
      "Batch 1280, Loss: 0.475, Accuracy: 87.98%\n",
      "Completed training after 281.52 seconds.\n",
      "Val Loss: 2.322, Val Accuracy: 51.29%\n",
      "Completed validation after 12.22 seconds.\n",
      "Accuracy: 55.38%\n",
      "Completed testing after 58.81 seconds.\n",
      "Total epoch time: 352.55 seconds.\n",
      "Epoch [38/100]\n",
      "Check-point!\n",
      "####################################################################################################\n",
      "Epoch 39 begin: 2025-05-13 15:30:08.480483.\n",
      "Batch 256, Loss: 0.460, Accuracy: 88.73%\n",
      "Batch 512, Loss: 0.473, Accuracy: 87.98%\n",
      "Batch 768, Loss: 0.493, Accuracy: 87.40%\n",
      "Batch 1024, Loss: 0.468, Accuracy: 88.23%\n",
      "Batch 1280, Loss: 0.494, Accuracy: 87.50%\n",
      "Completed training after 281.11 seconds.\n",
      "Val Loss: 2.278, Val Accuracy: 51.31%\n",
      "Completed validation after 12.22 seconds.\n",
      "Accuracy: 55.31%\n",
      "Completed testing after 58.72 seconds.\n",
      "Total epoch time: 352.05 seconds.\n",
      "Epoch [39/100]\n",
      "####################################################################################################\n",
      "Epoch 40 begin: 2025-05-13 15:36:00.532213.\n",
      "Batch 256, Loss: 0.459, Accuracy: 88.27%\n",
      "Batch 512, Loss: 0.476, Accuracy: 87.93%\n",
      "Batch 768, Loss: 0.465, Accuracy: 87.92%\n",
      "Batch 1024, Loss: 0.482, Accuracy: 87.77%\n",
      "Batch 1280, Loss: 0.489, Accuracy: 87.48%\n",
      "Completed training after 281.49 seconds.\n",
      "Val Loss: 2.262, Val Accuracy: 51.42%\n",
      "Completed validation after 12.25 seconds.\n",
      "Accuracy: 55.37%\n",
      "Completed testing after 58.80 seconds.\n",
      "Total epoch time: 352.54 seconds.\n",
      "Epoch [40/100]\n",
      "####################################################################################################\n",
      "Epoch 41 begin: 2025-05-13 15:41:53.069999.\n",
      "Batch 256, Loss: 0.478, Accuracy: 87.88%\n",
      "Batch 512, Loss: 0.474, Accuracy: 87.66%\n",
      "Batch 768, Loss: 0.479, Accuracy: 88.09%\n",
      "Batch 1024, Loss: 0.497, Accuracy: 87.62%\n",
      "Batch 1280, Loss: 0.465, Accuracy: 87.82%\n",
      "Completed training after 281.09 seconds.\n",
      "Val Loss: 2.275, Val Accuracy: 50.72%\n",
      "Completed validation after 12.22 seconds.\n",
      "Accuracy: 55.12%\n",
      "Completed testing after 58.71 seconds.\n",
      "Total epoch time: 352.03 seconds.\n",
      "Epoch [41/100]\n",
      "####################################################################################################\n",
      "Epoch 42 begin: 2025-05-13 15:47:45.096655.\n",
      "Batch 256, Loss: 0.471, Accuracy: 88.23%\n",
      "Batch 512, Loss: 0.489, Accuracy: 87.43%\n",
      "Batch 768, Loss: 0.457, Accuracy: 88.24%\n",
      "Batch 1024, Loss: 0.451, Accuracy: 88.31%\n",
      "Batch 1280, Loss: 0.465, Accuracy: 88.23%\n",
      "Completed training after 281.38 seconds.\n",
      "Val Loss: 2.242, Val Accuracy: 51.44%\n",
      "Completed validation after 12.25 seconds.\n",
      "Accuracy: 55.54%\n",
      "Completed testing after 58.72 seconds.\n",
      "Total epoch time: 352.35 seconds.\n",
      "Epoch [42/100]\n",
      "Check-point!\n",
      "####################################################################################################\n",
      "Epoch 43 begin: 2025-05-13 15:53:38.404322.\n",
      "Batch 256, Loss: 0.475, Accuracy: 87.81%\n",
      "Batch 512, Loss: 0.487, Accuracy: 87.44%\n",
      "Batch 768, Loss: 0.442, Accuracy: 88.75%\n",
      "Batch 1024, Loss: 0.472, Accuracy: 88.39%\n",
      "Batch 1280, Loss: 0.476, Accuracy: 87.76%\n",
      "Completed training after 281.52 seconds.\n",
      "Val Loss: 2.255, Val Accuracy: 50.98%\n",
      "Completed validation after 12.24 seconds.\n",
      "Accuracy: 55.41%\n",
      "Completed testing after 58.78 seconds.\n",
      "Total epoch time: 352.55 seconds.\n",
      "Epoch [43/100]\n",
      "####################################################################################################\n",
      "Epoch 44 begin: 2025-05-13 15:59:30.952326.\n",
      "Batch 256, Loss: 0.466, Accuracy: 88.37%\n",
      "Batch 512, Loss: 0.490, Accuracy: 87.93%\n",
      "Batch 768, Loss: 0.478, Accuracy: 87.74%\n",
      "Batch 1024, Loss: 0.456, Accuracy: 88.38%\n",
      "Batch 1280, Loss: 0.445, Accuracy: 88.77%\n",
      "Completed training after 281.44 seconds.\n",
      "Val Loss: 2.259, Val Accuracy: 51.01%\n",
      "Completed validation after 12.20 seconds.\n",
      "Accuracy: 55.39%\n",
      "Completed testing after 58.80 seconds.\n",
      "Total epoch time: 352.44 seconds.\n",
      "Epoch [44/100]\n",
      "####################################################################################################\n",
      "Epoch 45 begin: 2025-05-13 16:05:23.392341.\n",
      "Batch 256, Loss: 0.461, Accuracy: 88.39%\n",
      "Batch 512, Loss: 0.466, Accuracy: 87.79%\n",
      "Batch 768, Loss: 0.463, Accuracy: 88.38%\n",
      "Batch 1024, Loss: 0.469, Accuracy: 88.06%\n",
      "Batch 1280, Loss: 0.466, Accuracy: 88.27%\n",
      "Completed training after 281.45 seconds.\n",
      "Val Loss: 2.271, Val Accuracy: 51.60%\n",
      "Completed validation after 12.22 seconds.\n",
      "Accuracy: 55.35%\n",
      "Completed testing after 58.71 seconds.\n",
      "Total epoch time: 352.39 seconds.\n",
      "Epoch [45/100]\n",
      "####################################################################################################\n",
      "Epoch 46 begin: 2025-05-13 16:11:15.780079.\n",
      "Batch 256, Loss: 0.487, Accuracy: 87.59%\n",
      "Batch 512, Loss: 0.467, Accuracy: 88.18%\n",
      "Batch 768, Loss: 0.470, Accuracy: 87.84%\n",
      "Batch 1024, Loss: 0.471, Accuracy: 88.12%\n",
      "Batch 1280, Loss: 0.463, Accuracy: 88.29%\n",
      "Completed training after 281.53 seconds.\n",
      "Val Loss: 2.267, Val Accuracy: 51.16%\n",
      "Completed validation after 12.22 seconds.\n",
      "Accuracy: 55.57%\n",
      "Completed testing after 58.80 seconds.\n",
      "Total epoch time: 352.54 seconds.\n",
      "Epoch [46/100]\n",
      "Check-point!\n",
      "####################################################################################################\n",
      "Epoch 47 begin: 2025-05-13 16:17:09.286599.\n",
      "Batch 256, Loss: 0.479, Accuracy: 87.99%\n",
      "Batch 512, Loss: 0.468, Accuracy: 88.22%\n",
      "Batch 768, Loss: 0.473, Accuracy: 87.92%\n",
      "Batch 1024, Loss: 0.456, Accuracy: 88.66%\n",
      "Batch 1280, Loss: 0.480, Accuracy: 88.20%\n",
      "Completed training after 281.53 seconds.\n",
      "Val Loss: 2.232, Val Accuracy: 51.92%\n",
      "Completed validation after 12.22 seconds.\n",
      "Accuracy: 55.34%\n",
      "Completed testing after 58.81 seconds.\n",
      "Total epoch time: 352.56 seconds.\n",
      "Epoch [47/100]\n",
      "####################################################################################################\n",
      "Epoch 48 begin: 2025-05-13 16:23:01.842996.\n",
      "Batch 256, Loss: 0.469, Accuracy: 88.39%\n",
      "Batch 512, Loss: 0.469, Accuracy: 88.04%\n",
      "Batch 768, Loss: 0.468, Accuracy: 87.99%\n",
      "Batch 1024, Loss: 0.462, Accuracy: 88.09%\n",
      "Batch 1280, Loss: 0.485, Accuracy: 87.57%\n",
      "Completed training after 281.14 seconds.\n",
      "Val Loss: 2.250, Val Accuracy: 52.08%\n",
      "Completed validation after 12.24 seconds.\n",
      "Accuracy: 55.60%\n",
      "Completed testing after 58.86 seconds.\n",
      "Total epoch time: 352.25 seconds.\n",
      "Epoch [48/100]\n",
      "Check-point!\n",
      "####################################################################################################\n",
      "Epoch 49 begin: 2025-05-13 16:28:55.045610.\n",
      "Batch 256, Loss: 0.493, Accuracy: 87.68%\n",
      "Batch 512, Loss: 0.466, Accuracy: 88.16%\n",
      "Batch 768, Loss: 0.480, Accuracy: 87.90%\n",
      "Batch 1024, Loss: 0.476, Accuracy: 88.12%\n",
      "Batch 1280, Loss: 0.480, Accuracy: 87.83%\n",
      "Completed training after 281.48 seconds.\n",
      "Val Loss: 2.304, Val Accuracy: 51.29%\n",
      "Completed validation after 12.20 seconds.\n",
      "Accuracy: 55.32%\n",
      "Completed testing after 58.82 seconds.\n",
      "Total epoch time: 352.50 seconds.\n",
      "Epoch [49/100]\n",
      "####################################################################################################\n",
      "Epoch 50 begin: 2025-05-13 16:34:47.543133.\n",
      "Batch 256, Loss: 0.456, Accuracy: 88.77%\n",
      "Batch 512, Loss: 0.472, Accuracy: 88.01%\n",
      "Batch 768, Loss: 0.477, Accuracy: 88.23%\n",
      "Batch 1024, Loss: 0.490, Accuracy: 87.37%\n",
      "Batch 1280, Loss: 0.460, Accuracy: 88.24%\n",
      "Completed training after 281.50 seconds.\n",
      "Val Loss: 2.307, Val Accuracy: 51.62%\n",
      "Completed validation after 12.21 seconds.\n",
      "Accuracy: 55.45%\n",
      "Completed testing after 58.81 seconds.\n",
      "Total epoch time: 352.52 seconds.\n",
      "Epoch [50/100]\n",
      "####################################################################################################\n",
      "Epoch 51 begin: 2025-05-13 16:40:40.058218.\n",
      "Batch 256, Loss: 0.442, Accuracy: 88.98%\n",
      "Batch 512, Loss: 0.486, Accuracy: 87.62%\n",
      "Batch 768, Loss: 0.479, Accuracy: 87.89%\n",
      "Batch 1024, Loss: 0.454, Accuracy: 88.34%\n",
      "Batch 1280, Loss: 0.475, Accuracy: 87.90%\n",
      "Completed training after 281.22 seconds.\n",
      "Val Loss: 2.227, Val Accuracy: 51.77%\n",
      "Completed validation after 12.24 seconds.\n",
      "Accuracy: 55.42%\n",
      "Completed testing after 58.82 seconds.\n",
      "Total epoch time: 352.28 seconds.\n",
      "Epoch [51/100]\n",
      "####################################################################################################\n",
      "Epoch 52 begin: 2025-05-13 16:46:32.335183.\n",
      "Batch 256, Loss: 0.472, Accuracy: 88.07%\n",
      "Batch 512, Loss: 0.461, Accuracy: 88.46%\n",
      "Batch 768, Loss: 0.467, Accuracy: 88.02%\n",
      "Batch 1024, Loss: 0.473, Accuracy: 88.04%\n",
      "Batch 1280, Loss: 0.462, Accuracy: 88.67%\n",
      "Completed training after 281.51 seconds.\n",
      "Val Loss: 2.260, Val Accuracy: 51.14%\n",
      "Completed validation after 12.23 seconds.\n",
      "Accuracy: 55.19%\n",
      "Completed testing after 58.74 seconds.\n",
      "Total epoch time: 352.47 seconds.\n",
      "Epoch [52/100]\n",
      "####################################################################################################\n",
      "Epoch 53 begin: 2025-05-13 16:52:24.808523.\n",
      "Batch 256, Loss: 0.480, Accuracy: 88.24%\n",
      "Batch 512, Loss: 0.488, Accuracy: 87.72%\n",
      "Batch 768, Loss: 0.463, Accuracy: 88.20%\n",
      "Batch 1024, Loss: 0.479, Accuracy: 87.99%\n",
      "Batch 1280, Loss: 0.491, Accuracy: 87.52%\n",
      "Completed training after 281.47 seconds.\n",
      "Val Loss: 2.262, Val Accuracy: 50.98%\n",
      "Completed validation after 12.25 seconds.\n",
      "Accuracy: 55.34%\n",
      "Completed testing after 58.89 seconds.\n",
      "Total epoch time: 352.61 seconds.\n",
      "Epoch [53/100]\n",
      "####################################################################################################\n",
      "Epoch 54 begin: 2025-05-13 16:58:17.419706.\n",
      "Batch 256, Loss: 0.477, Accuracy: 88.09%\n",
      "Batch 512, Loss: 0.473, Accuracy: 87.90%\n",
      "Batch 768, Loss: 0.480, Accuracy: 87.81%\n",
      "Batch 1024, Loss: 0.474, Accuracy: 88.04%\n",
      "Batch 1280, Loss: 0.493, Accuracy: 87.37%\n",
      "Completed training after 281.60 seconds.\n",
      "Val Loss: 2.289, Val Accuracy: 50.72%\n",
      "Completed validation after 12.24 seconds.\n",
      "Accuracy: 55.18%\n",
      "Completed testing after 58.95 seconds.\n",
      "Total epoch time: 352.79 seconds.\n",
      "Epoch [54/100]\n",
      "####################################################################################################\n",
      "Epoch 55 begin: 2025-05-13 17:04:10.207503.\n",
      "Batch 256, Loss: 0.450, Accuracy: 88.66%\n",
      "Batch 512, Loss: 0.475, Accuracy: 88.05%\n",
      "Batch 768, Loss: 0.489, Accuracy: 87.74%\n",
      "Batch 1024, Loss: 0.456, Accuracy: 88.38%\n",
      "Batch 1280, Loss: 0.458, Accuracy: 88.26%\n",
      "Completed training after 281.52 seconds.\n",
      "Val Loss: 2.245, Val Accuracy: 52.16%\n",
      "Completed validation after 12.25 seconds.\n",
      "Accuracy: 55.26%\n",
      "Completed testing after 58.94 seconds.\n",
      "Total epoch time: 352.70 seconds.\n",
      "Epoch [55/100]\n",
      "####################################################################################################\n",
      "Epoch 56 begin: 2025-05-13 17:10:02.909730.\n",
      "Batch 256, Loss: 0.452, Accuracy: 88.76%\n",
      "Batch 512, Loss: 0.481, Accuracy: 87.77%\n",
      "Batch 768, Loss: 0.455, Accuracy: 88.65%\n",
      "Batch 1024, Loss: 0.467, Accuracy: 87.81%\n",
      "Batch 1280, Loss: 0.474, Accuracy: 88.15%\n",
      "Completed training after 281.59 seconds.\n",
      "Val Loss: 2.241, Val Accuracy: 52.01%\n",
      "Completed validation after 12.23 seconds.\n",
      "Accuracy: 55.31%\n",
      "Completed testing after 58.86 seconds.\n",
      "Total epoch time: 352.67 seconds.\n",
      "Epoch [56/100]\n",
      "####################################################################################################\n",
      "Epoch 57 begin: 2025-05-13 17:15:55.584641.\n",
      "Batch 256, Loss: 0.485, Accuracy: 87.72%\n",
      "Batch 512, Loss: 0.458, Accuracy: 88.59%\n",
      "Batch 768, Loss: 0.459, Accuracy: 88.55%\n",
      "Batch 1024, Loss: 0.484, Accuracy: 88.07%\n",
      "Batch 1280, Loss: 0.488, Accuracy: 87.73%\n",
      "Completed training after 281.56 seconds.\n",
      "Val Loss: 2.272, Val Accuracy: 51.14%\n",
      "Completed validation after 12.23 seconds.\n",
      "Accuracy: 55.20%\n",
      "Completed testing after 58.81 seconds.\n",
      "Total epoch time: 352.60 seconds.\n",
      "Epoch [57/100]\n",
      "####################################################################################################\n",
      "Epoch 58 begin: 2025-05-13 17:21:48.185259.\n",
      "Batch 256, Loss: 0.467, Accuracy: 88.12%\n",
      "Batch 512, Loss: 0.475, Accuracy: 88.26%\n",
      "Batch 768, Loss: 0.472, Accuracy: 88.44%\n",
      "Batch 1024, Loss: 0.483, Accuracy: 88.05%\n",
      "Batch 1280, Loss: 0.494, Accuracy: 87.67%\n",
      "Completed training after 281.52 seconds.\n",
      "Val Loss: 2.266, Val Accuracy: 51.51%\n",
      "Completed validation after 12.24 seconds.\n",
      "Accuracy: 55.27%\n",
      "Completed testing after 58.93 seconds.\n",
      "Total epoch time: 352.70 seconds.\n",
      "Epoch [58/100]\n",
      "####################################################################################################\n",
      "Epoch 59 begin: 2025-05-13 17:27:40.884142.\n",
      "Batch 256, Loss: 0.476, Accuracy: 87.65%\n",
      "Batch 512, Loss: 0.491, Accuracy: 87.61%\n",
      "Batch 768, Loss: 0.479, Accuracy: 87.99%\n",
      "Batch 1024, Loss: 0.456, Accuracy: 88.01%\n",
      "Batch 1280, Loss: 0.484, Accuracy: 87.68%\n",
      "Completed training after 281.58 seconds.\n",
      "Val Loss: 2.272, Val Accuracy: 51.81%\n",
      "Completed validation after 12.26 seconds.\n",
      "Accuracy: 55.38%\n",
      "Completed testing after 58.88 seconds.\n",
      "Total epoch time: 352.73 seconds.\n",
      "Epoch [59/100]\n",
      "####################################################################################################\n",
      "Epoch 60 begin: 2025-05-13 17:33:33.612803.\n",
      "Batch 256, Loss: 0.466, Accuracy: 88.11%\n",
      "Batch 512, Loss: 0.475, Accuracy: 88.29%\n",
      "Batch 768, Loss: 0.475, Accuracy: 87.93%\n",
      "Batch 1024, Loss: 0.475, Accuracy: 88.16%\n",
      "Batch 1280, Loss: 0.464, Accuracy: 88.24%\n",
      "Completed training after 281.57 seconds.\n",
      "Val Loss: 2.256, Val Accuracy: 52.03%\n",
      "Completed validation after 12.23 seconds.\n",
      "Accuracy: 55.38%\n",
      "Completed testing after 58.93 seconds.\n",
      "Total epoch time: 352.73 seconds.\n",
      "Epoch [60/100]\n",
      "####################################################################################################\n",
      "Epoch 61 begin: 2025-05-13 17:39:26.339199.\n",
      "Batch 256, Loss: 0.474, Accuracy: 88.17%\n",
      "Batch 512, Loss: 0.483, Accuracy: 87.56%\n",
      "Batch 768, Loss: 0.492, Accuracy: 87.44%\n",
      "Batch 1024, Loss: 0.473, Accuracy: 88.09%\n",
      "Batch 1280, Loss: 0.494, Accuracy: 87.96%\n",
      "Completed training after 281.52 seconds.\n",
      "Val Loss: 2.248, Val Accuracy: 51.22%\n",
      "Completed validation after 12.22 seconds.\n",
      "Accuracy: 55.33%\n",
      "Completed testing after 58.86 seconds.\n",
      "Total epoch time: 352.61 seconds.\n",
      "Epoch [61/100]\n",
      "####################################################################################################\n",
      "Epoch 62 begin: 2025-05-13 17:45:18.945432.\n",
      "Batch 256, Loss: 0.482, Accuracy: 87.59%\n",
      "Batch 512, Loss: 0.479, Accuracy: 88.07%\n",
      "Batch 768, Loss: 0.484, Accuracy: 87.83%\n",
      "Batch 1024, Loss: 0.467, Accuracy: 88.53%\n",
      "Batch 1280, Loss: 0.479, Accuracy: 87.61%\n",
      "Completed training after 281.62 seconds.\n",
      "Val Loss: 2.272, Val Accuracy: 51.46%\n",
      "Completed validation after 12.24 seconds.\n",
      "Accuracy: 55.32%\n",
      "Completed testing after 58.97 seconds.\n",
      "Total epoch time: 352.83 seconds.\n",
      "Epoch [62/100]\n",
      "####################################################################################################\n",
      "Epoch 63 begin: 2025-05-13 17:51:11.776731.\n",
      "Batch 256, Loss: 0.469, Accuracy: 88.17%\n",
      "Batch 512, Loss: 0.502, Accuracy: 87.35%\n",
      "Batch 768, Loss: 0.465, Accuracy: 88.20%\n",
      "Batch 1024, Loss: 0.483, Accuracy: 87.90%\n",
      "Batch 1280, Loss: 0.491, Accuracy: 87.93%\n",
      "Completed training after 281.55 seconds.\n",
      "Val Loss: 2.273, Val Accuracy: 51.60%\n",
      "Completed validation after 12.26 seconds.\n",
      "Accuracy: 55.27%\n",
      "Completed testing after 58.84 seconds.\n",
      "Total epoch time: 352.64 seconds.\n",
      "Epoch [63/100]\n",
      "####################################################################################################\n",
      "Epoch 64 begin: 2025-05-13 17:57:04.418578.\n",
      "Batch 256, Loss: 0.477, Accuracy: 87.92%\n",
      "Batch 512, Loss: 0.484, Accuracy: 87.82%\n",
      "Batch 768, Loss: 0.482, Accuracy: 87.59%\n",
      "Batch 1024, Loss: 0.472, Accuracy: 87.89%\n",
      "Batch 1280, Loss: 0.466, Accuracy: 88.18%\n",
      "Completed training after 281.54 seconds.\n",
      "Val Loss: 2.238, Val Accuracy: 52.27%\n",
      "Completed validation after 12.31 seconds.\n",
      "Accuracy: 55.64%\n",
      "Completed testing after 58.97 seconds.\n",
      "Total epoch time: 352.81 seconds.\n",
      "Epoch [64/100]\n",
      "Check-point!\n",
      "####################################################################################################\n",
      "Epoch 65 begin: 2025-05-13 18:02:58.185188.\n",
      "Batch 256, Loss: 0.467, Accuracy: 87.93%\n",
      "Batch 512, Loss: 0.477, Accuracy: 87.73%\n",
      "Batch 768, Loss: 0.470, Accuracy: 87.98%\n",
      "Batch 1024, Loss: 0.488, Accuracy: 87.67%\n",
      "Batch 1280, Loss: 0.501, Accuracy: 87.05%\n",
      "Completed training after 281.56 seconds.\n",
      "Val Loss: 2.268, Val Accuracy: 51.31%\n",
      "Completed validation after 12.26 seconds.\n",
      "Accuracy: 55.33%\n",
      "Completed testing after 58.88 seconds.\n",
      "Total epoch time: 352.70 seconds.\n",
      "Epoch [65/100]\n",
      "####################################################################################################\n",
      "Epoch 66 begin: 2025-05-13 18:08:50.884534.\n",
      "Batch 256, Loss: 0.470, Accuracy: 88.21%\n",
      "Batch 512, Loss: 0.479, Accuracy: 88.31%\n",
      "Batch 768, Loss: 0.479, Accuracy: 87.79%\n",
      "Batch 1024, Loss: 0.475, Accuracy: 87.79%\n",
      "Batch 1280, Loss: 0.488, Accuracy: 87.55%\n",
      "Completed training after 281.24 seconds.\n",
      "Val Loss: 2.313, Val Accuracy: 50.76%\n",
      "Completed validation after 12.23 seconds.\n",
      "Accuracy: 55.10%\n",
      "Completed testing after 58.86 seconds.\n",
      "Total epoch time: 352.33 seconds.\n",
      "Epoch [66/100]\n",
      "####################################################################################################\n",
      "Epoch 67 begin: 2025-05-13 18:14:43.209710.\n",
      "Batch 256, Loss: 0.475, Accuracy: 88.09%\n",
      "Batch 512, Loss: 0.465, Accuracy: 88.28%\n",
      "Batch 768, Loss: 0.472, Accuracy: 88.32%\n",
      "Batch 1024, Loss: 0.473, Accuracy: 87.82%\n",
      "Batch 1280, Loss: 0.495, Accuracy: 87.45%\n",
      "Completed training after 281.61 seconds.\n",
      "Val Loss: 2.244, Val Accuracy: 52.10%\n",
      "Completed validation after 12.25 seconds.\n",
      "Accuracy: 55.42%\n",
      "Completed testing after 58.92 seconds.\n",
      "Total epoch time: 352.78 seconds.\n",
      "Epoch [67/100]\n",
      "####################################################################################################\n",
      "Epoch 68 begin: 2025-05-13 18:20:35.991926.\n",
      "Batch 256, Loss: 0.479, Accuracy: 88.11%\n",
      "Batch 512, Loss: 0.472, Accuracy: 87.96%\n",
      "Batch 768, Loss: 0.472, Accuracy: 87.78%\n",
      "Batch 1024, Loss: 0.494, Accuracy: 87.52%\n",
      "Batch 1280, Loss: 0.490, Accuracy: 87.38%\n",
      "Completed training after 281.61 seconds.\n",
      "Val Loss: 2.263, Val Accuracy: 51.66%\n",
      "Completed validation after 12.23 seconds.\n",
      "Accuracy: 55.34%\n",
      "Completed testing after 58.88 seconds.\n",
      "Total epoch time: 352.73 seconds.\n",
      "Epoch [68/100]\n",
      "####################################################################################################\n",
      "Epoch 69 begin: 2025-05-13 18:26:28.720372.\n",
      "Batch 256, Loss: 0.475, Accuracy: 87.98%\n",
      "Batch 512, Loss: 0.472, Accuracy: 87.90%\n",
      "Batch 768, Loss: 0.476, Accuracy: 87.79%\n",
      "Batch 1024, Loss: 0.461, Accuracy: 88.28%\n",
      "Batch 1280, Loss: 0.464, Accuracy: 88.01%\n",
      "Completed training after 281.55 seconds.\n",
      "Val Loss: 2.262, Val Accuracy: 51.22%\n",
      "Completed validation after 12.25 seconds.\n",
      "Accuracy: 55.31%\n",
      "Completed testing after 58.99 seconds.\n",
      "Total epoch time: 352.79 seconds.\n",
      "Epoch [69/100]\n",
      "####################################################################################################\n",
      "Epoch 70 begin: 2025-05-13 18:32:21.506363.\n",
      "Batch 256, Loss: 0.461, Accuracy: 88.64%\n",
      "Batch 512, Loss: 0.479, Accuracy: 87.94%\n",
      "Batch 768, Loss: 0.482, Accuracy: 87.78%\n",
      "Batch 1024, Loss: 0.484, Accuracy: 87.67%\n",
      "Batch 1280, Loss: 0.477, Accuracy: 87.98%\n",
      "Completed training after 281.62 seconds.\n",
      "Val Loss: 2.258, Val Accuracy: 51.81%\n",
      "Completed validation after 12.25 seconds.\n",
      "Accuracy: 55.28%\n",
      "Completed testing after 58.98 seconds.\n",
      "Total epoch time: 352.85 seconds.\n",
      "Epoch [70/100]\n",
      "####################################################################################################\n",
      "Epoch 71 begin: 2025-05-13 18:38:14.356247.\n",
      "Batch 256, Loss: 0.461, Accuracy: 88.24%\n",
      "Batch 512, Loss: 0.443, Accuracy: 88.93%\n",
      "Batch 768, Loss: 0.467, Accuracy: 88.43%\n",
      "Batch 1024, Loss: 0.478, Accuracy: 87.88%\n",
      "Batch 1280, Loss: 0.463, Accuracy: 88.15%\n",
      "Completed training after 281.28 seconds.\n",
      "Val Loss: 2.275, Val Accuracy: 50.59%\n",
      "Completed validation after 12.23 seconds.\n",
      "Accuracy: 55.39%\n",
      "Completed testing after 58.97 seconds.\n",
      "Total epoch time: 352.48 seconds.\n",
      "Epoch [71/100]\n",
      "####################################################################################################\n",
      "Epoch 72 begin: 2025-05-13 18:44:06.835465.\n",
      "Batch 256, Loss: 0.491, Accuracy: 87.99%\n",
      "Batch 512, Loss: 0.483, Accuracy: 88.01%\n",
      "Batch 768, Loss: 0.457, Accuracy: 88.88%\n",
      "Batch 1024, Loss: 0.451, Accuracy: 88.35%\n",
      "Batch 1280, Loss: 0.475, Accuracy: 87.92%\n",
      "Completed training after 281.59 seconds.\n",
      "Val Loss: 2.279, Val Accuracy: 51.35%\n",
      "Completed validation after 12.26 seconds.\n",
      "Accuracy: 55.54%\n",
      "Completed testing after 58.95 seconds.\n",
      "Total epoch time: 352.81 seconds.\n",
      "Epoch [72/100]\n",
      "####################################################################################################\n",
      "Epoch 73 begin: 2025-05-13 18:49:59.643269.\n",
      "Batch 256, Loss: 0.467, Accuracy: 87.83%\n",
      "Batch 512, Loss: 0.486, Accuracy: 87.84%\n",
      "Batch 768, Loss: 0.495, Accuracy: 87.39%\n",
      "Batch 1024, Loss: 0.478, Accuracy: 87.89%\n",
      "Batch 1280, Loss: 0.479, Accuracy: 87.98%\n",
      "Completed training after 281.59 seconds.\n",
      "Val Loss: 2.279, Val Accuracy: 51.18%\n",
      "Completed validation after 12.27 seconds.\n",
      "Accuracy: 55.34%\n",
      "Completed testing after 58.85 seconds.\n",
      "Total epoch time: 352.71 seconds.\n",
      "Epoch [73/100]\n",
      "####################################################################################################\n",
      "Epoch 74 begin: 2025-05-13 18:55:52.355516.\n",
      "Batch 256, Loss: 0.486, Accuracy: 87.45%\n",
      "Batch 512, Loss: 0.484, Accuracy: 87.79%\n",
      "Batch 768, Loss: 0.467, Accuracy: 87.93%\n",
      "Batch 1024, Loss: 0.489, Accuracy: 87.41%\n",
      "Batch 1280, Loss: 0.472, Accuracy: 87.90%\n",
      "Completed training after 281.57 seconds.\n",
      "Val Loss: 2.259, Val Accuracy: 51.18%\n",
      "Completed validation after 12.23 seconds.\n",
      "Accuracy: 55.30%\n",
      "Completed testing after 58.94 seconds.\n",
      "Total epoch time: 352.74 seconds.\n",
      "Epoch [74/100]\n",
      "####################################################################################################\n",
      "Epoch 75 begin: 2025-05-13 19:01:45.095996.\n",
      "Batch 256, Loss: 0.470, Accuracy: 88.02%\n",
      "Batch 512, Loss: 0.469, Accuracy: 88.43%\n",
      "Batch 768, Loss: 0.460, Accuracy: 88.22%\n",
      "Batch 1024, Loss: 0.479, Accuracy: 87.72%\n",
      "Batch 1280, Loss: 0.493, Accuracy: 87.49%\n",
      "Completed training after 281.30 seconds.\n",
      "Val Loss: 2.294, Val Accuracy: 50.79%\n",
      "Completed validation after 12.24 seconds.\n",
      "Accuracy: 55.26%\n",
      "Completed testing after 58.96 seconds.\n",
      "Total epoch time: 352.50 seconds.\n",
      "Epoch [75/100]\n",
      "####################################################################################################\n",
      "Epoch 76 begin: 2025-05-13 19:07:37.592018.\n",
      "Batch 256, Loss: 0.465, Accuracy: 88.10%\n",
      "Batch 512, Loss: 0.470, Accuracy: 88.22%\n",
      "Batch 768, Loss: 0.451, Accuracy: 88.60%\n",
      "Batch 1024, Loss: 0.461, Accuracy: 88.37%\n",
      "Batch 1280, Loss: 0.484, Accuracy: 88.21%\n",
      "Completed training after 281.66 seconds.\n",
      "Val Loss: 2.269, Val Accuracy: 51.57%\n",
      "Completed validation after 12.26 seconds.\n",
      "Accuracy: 55.20%\n",
      "Completed testing after 59.00 seconds.\n",
      "Total epoch time: 352.91 seconds.\n",
      "Epoch [76/100]\n",
      "####################################################################################################\n",
      "Epoch 77 begin: 2025-05-13 19:13:30.502522.\n",
      "Batch 256, Loss: 0.467, Accuracy: 88.00%\n",
      "Batch 512, Loss: 0.471, Accuracy: 87.95%\n",
      "Batch 768, Loss: 0.480, Accuracy: 87.78%\n",
      "Batch 1024, Loss: 0.483, Accuracy: 87.55%\n",
      "Batch 1280, Loss: 0.477, Accuracy: 87.90%\n",
      "Completed training after 281.65 seconds.\n",
      "Val Loss: 2.242, Val Accuracy: 51.62%\n",
      "Completed validation after 12.22 seconds.\n",
      "Accuracy: 55.36%\n",
      "Completed testing after 58.95 seconds.\n",
      "Total epoch time: 352.82 seconds.\n",
      "Epoch [77/100]\n",
      "####################################################################################################\n",
      "Epoch 78 begin: 2025-05-13 19:19:23.320260.\n",
      "Batch 256, Loss: 0.454, Accuracy: 88.82%\n",
      "Batch 512, Loss: 0.466, Accuracy: 88.16%\n",
      "Batch 768, Loss: 0.476, Accuracy: 88.12%\n",
      "Batch 1024, Loss: 0.465, Accuracy: 88.13%\n",
      "Batch 1280, Loss: 0.464, Accuracy: 88.34%\n",
      "Completed training after 281.36 seconds.\n",
      "Val Loss: 2.261, Val Accuracy: 51.99%\n",
      "Completed validation after 12.28 seconds.\n",
      "Accuracy: 55.45%\n",
      "Completed testing after 59.01 seconds.\n",
      "Total epoch time: 352.65 seconds.\n",
      "Epoch [78/100]\n",
      "####################################################################################################\n",
      "Epoch 79 begin: 2025-05-13 19:25:15.970780.\n",
      "Batch 256, Loss: 0.463, Accuracy: 88.22%\n",
      "Batch 512, Loss: 0.473, Accuracy: 88.68%\n",
      "Batch 768, Loss: 0.470, Accuracy: 88.07%\n",
      "Batch 1024, Loss: 0.472, Accuracy: 87.87%\n",
      "Batch 1280, Loss: 0.467, Accuracy: 88.05%\n",
      "Completed training after 281.61 seconds.\n",
      "Val Loss: 2.263, Val Accuracy: 51.29%\n",
      "Completed validation after 12.27 seconds.\n",
      "Accuracy: 55.42%\n",
      "Completed testing after 58.90 seconds.\n",
      "Total epoch time: 352.78 seconds.\n",
      "Epoch [79/100]\n",
      "####################################################################################################\n",
      "Epoch 80 begin: 2025-05-13 19:31:08.748860.\n",
      "Batch 256, Loss: 0.442, Accuracy: 88.93%\n",
      "Batch 512, Loss: 0.489, Accuracy: 87.57%\n",
      "Batch 768, Loss: 0.487, Accuracy: 87.82%\n",
      "Batch 1024, Loss: 0.470, Accuracy: 88.09%\n",
      "Batch 1280, Loss: 0.461, Accuracy: 88.09%\n",
      "Completed training after 281.32 seconds.\n",
      "Val Loss: 2.238, Val Accuracy: 51.64%\n",
      "Completed validation after 12.23 seconds.\n",
      "Accuracy: 55.52%\n",
      "Completed testing after 58.91 seconds.\n",
      "Total epoch time: 352.47 seconds.\n",
      "Epoch [80/100]\n",
      "####################################################################################################\n",
      "Epoch 81 begin: 2025-05-13 19:37:01.216488.\n",
      "Batch 256, Loss: 0.454, Accuracy: 88.45%\n",
      "Batch 512, Loss: 0.465, Accuracy: 88.49%\n",
      "Batch 768, Loss: 0.499, Accuracy: 87.39%\n",
      "Batch 1024, Loss: 0.479, Accuracy: 87.98%\n",
      "Batch 1280, Loss: 0.479, Accuracy: 87.87%\n",
      "Completed training after 281.61 seconds.\n",
      "Val Loss: 2.288, Val Accuracy: 50.76%\n",
      "Completed validation after 12.24 seconds.\n",
      "Accuracy: 55.07%\n",
      "Completed testing after 58.96 seconds.\n",
      "Total epoch time: 352.81 seconds.\n",
      "Epoch [81/100]\n",
      "####################################################################################################\n",
      "Epoch 82 begin: 2025-05-13 19:42:54.025925.\n",
      "Batch 256, Loss: 0.463, Accuracy: 88.20%\n",
      "Batch 512, Loss: 0.459, Accuracy: 88.48%\n",
      "Batch 768, Loss: 0.473, Accuracy: 88.34%\n",
      "Batch 1024, Loss: 0.465, Accuracy: 88.16%\n",
      "Batch 1280, Loss: 0.470, Accuracy: 88.27%\n",
      "Completed training after 281.60 seconds.\n",
      "Val Loss: 2.288, Val Accuracy: 50.85%\n",
      "Completed validation after 12.24 seconds.\n",
      "Accuracy: 55.16%\n",
      "Completed testing after 59.00 seconds.\n",
      "Total epoch time: 352.84 seconds.\n",
      "Epoch [82/100]\n",
      "####################################################################################################\n",
      "Epoch 83 begin: 2025-05-13 19:48:46.861937.\n",
      "Batch 256, Loss: 0.493, Accuracy: 87.79%\n",
      "Batch 512, Loss: 0.465, Accuracy: 88.48%\n",
      "Batch 768, Loss: 0.478, Accuracy: 87.89%\n",
      "Batch 1024, Loss: 0.466, Accuracy: 88.34%\n",
      "Batch 1280, Loss: 0.462, Accuracy: 88.17%\n",
      "Completed training after 281.70 seconds.\n",
      "Val Loss: 2.279, Val Accuracy: 51.35%\n",
      "Completed validation after 12.26 seconds.\n",
      "Accuracy: 55.26%\n",
      "Completed testing after 58.97 seconds.\n",
      "Total epoch time: 352.93 seconds.\n",
      "Epoch [83/100]\n",
      "####################################################################################################\n",
      "Epoch 84 begin: 2025-05-13 19:54:39.796783.\n",
      "Batch 256, Loss: 0.480, Accuracy: 87.61%\n",
      "Batch 512, Loss: 0.504, Accuracy: 87.12%\n",
      "Batch 768, Loss: 0.464, Accuracy: 88.51%\n",
      "Batch 1024, Loss: 0.478, Accuracy: 87.66%\n",
      "Batch 1280, Loss: 0.488, Accuracy: 87.81%\n",
      "Completed training after 281.60 seconds.\n",
      "Val Loss: 2.266, Val Accuracy: 51.49%\n",
      "Completed validation after 12.25 seconds.\n",
      "Accuracy: 55.33%\n",
      "Completed testing after 58.98 seconds.\n",
      "Total epoch time: 352.84 seconds.\n",
      "Epoch [84/100]\n",
      "####################################################################################################\n",
      "Epoch 85 begin: 2025-05-13 20:00:32.636532.\n",
      "Batch 256, Loss: 0.455, Accuracy: 88.32%\n",
      "Batch 512, Loss: 0.484, Accuracy: 87.78%\n",
      "Batch 768, Loss: 0.472, Accuracy: 88.04%\n",
      "Batch 1024, Loss: 0.476, Accuracy: 87.94%\n",
      "Batch 1280, Loss: 0.467, Accuracy: 88.04%\n",
      "Completed training after 281.60 seconds.\n",
      "Val Loss: 2.257, Val Accuracy: 51.09%\n",
      "Completed validation after 12.24 seconds.\n",
      "Accuracy: 55.41%\n",
      "Completed testing after 59.01 seconds.\n",
      "Total epoch time: 352.86 seconds.\n",
      "Epoch [85/100]\n",
      "####################################################################################################\n",
      "Epoch 86 begin: 2025-05-13 20:06:25.493828.\n",
      "Batch 256, Loss: 0.457, Accuracy: 88.11%\n",
      "Batch 512, Loss: 0.492, Accuracy: 87.46%\n",
      "Batch 768, Loss: 0.472, Accuracy: 88.05%\n",
      "Batch 1024, Loss: 0.494, Accuracy: 87.40%\n",
      "Batch 1280, Loss: 0.466, Accuracy: 88.22%\n",
      "Completed training after 281.65 seconds.\n",
      "Val Loss: 2.307, Val Accuracy: 51.66%\n",
      "Completed validation after 12.27 seconds.\n",
      "Accuracy: 55.33%\n",
      "Completed testing after 59.00 seconds.\n",
      "Total epoch time: 352.92 seconds.\n",
      "Epoch [86/100]\n",
      "####################################################################################################\n",
      "Epoch 87 begin: 2025-05-13 20:12:18.411168.\n",
      "Batch 256, Loss: 0.472, Accuracy: 88.09%\n",
      "Batch 512, Loss: 0.489, Accuracy: 88.04%\n",
      "Batch 768, Loss: 0.472, Accuracy: 87.84%\n",
      "Batch 1024, Loss: 0.467, Accuracy: 88.49%\n",
      "Batch 1280, Loss: 0.475, Accuracy: 87.79%\n",
      "Completed training after 281.35 seconds.\n",
      "Val Loss: 2.266, Val Accuracy: 51.07%\n",
      "Completed validation after 12.25 seconds.\n",
      "Accuracy: 55.11%\n",
      "Completed testing after 58.99 seconds.\n",
      "Total epoch time: 352.58 seconds.\n",
      "Epoch [87/100]\n",
      "####################################################################################################\n",
      "Epoch 88 begin: 2025-05-13 20:18:10.995526.\n",
      "Batch 256, Loss: 0.474, Accuracy: 87.94%\n",
      "Batch 512, Loss: 0.489, Accuracy: 87.59%\n",
      "Batch 768, Loss: 0.472, Accuracy: 87.94%\n",
      "Batch 1024, Loss: 0.513, Accuracy: 87.28%\n",
      "Batch 1280, Loss: 0.467, Accuracy: 88.00%\n",
      "Completed training after 281.41 seconds.\n",
      "Val Loss: 2.285, Val Accuracy: 50.59%\n",
      "Completed validation after 12.26 seconds.\n",
      "Accuracy: 55.04%\n",
      "Completed testing after 58.97 seconds.\n",
      "Total epoch time: 352.65 seconds.\n",
      "Epoch [88/100]\n",
      "####################################################################################################\n",
      "Epoch 89 begin: 2025-05-13 20:24:03.643251.\n",
      "Batch 256, Loss: 0.486, Accuracy: 87.76%\n",
      "Batch 512, Loss: 0.487, Accuracy: 87.34%\n",
      "Batch 768, Loss: 0.471, Accuracy: 88.50%\n",
      "Batch 1024, Loss: 0.473, Accuracy: 87.93%\n",
      "Batch 1280, Loss: 0.471, Accuracy: 88.50%\n",
      "Completed training after 281.31 seconds.\n",
      "Val Loss: 2.277, Val Accuracy: 50.87%\n",
      "Completed validation after 12.26 seconds.\n",
      "Accuracy: 55.33%\n",
      "Completed testing after 59.00 seconds.\n",
      "Total epoch time: 352.58 seconds.\n",
      "Epoch [89/100]\n",
      "####################################################################################################\n",
      "Epoch 90 begin: 2025-05-13 20:29:56.219546.\n",
      "Batch 256, Loss: 0.461, Accuracy: 88.09%\n",
      "Batch 512, Loss: 0.483, Accuracy: 87.82%\n",
      "Batch 768, Loss: 0.460, Accuracy: 88.42%\n",
      "Batch 1024, Loss: 0.472, Accuracy: 87.93%\n",
      "Batch 1280, Loss: 0.461, Accuracy: 88.60%\n",
      "Completed training after 281.62 seconds.\n",
      "Val Loss: 2.259, Val Accuracy: 51.33%\n",
      "Completed validation after 12.26 seconds.\n",
      "Accuracy: 55.34%\n",
      "Completed testing after 59.00 seconds.\n",
      "Total epoch time: 352.88 seconds.\n",
      "Epoch [90/100]\n",
      "####################################################################################################\n",
      "Epoch 91 begin: 2025-05-13 20:35:49.096085.\n",
      "Batch 256, Loss: 0.478, Accuracy: 87.79%\n",
      "Batch 512, Loss: 0.464, Accuracy: 88.16%\n",
      "Batch 768, Loss: 0.471, Accuracy: 87.78%\n",
      "Batch 1024, Loss: 0.468, Accuracy: 87.93%\n",
      "Batch 1280, Loss: 0.467, Accuracy: 87.82%\n",
      "Completed training after 281.67 seconds.\n",
      "Val Loss: 2.248, Val Accuracy: 51.51%\n",
      "Completed validation after 12.23 seconds.\n",
      "Accuracy: 55.50%\n",
      "Completed testing after 59.01 seconds.\n",
      "Total epoch time: 352.91 seconds.\n",
      "Epoch [91/100]\n",
      "####################################################################################################\n",
      "Epoch 92 begin: 2025-05-13 20:41:42.008250.\n",
      "Batch 256, Loss: 0.497, Accuracy: 87.54%\n",
      "Batch 512, Loss: 0.467, Accuracy: 88.21%\n",
      "Batch 768, Loss: 0.483, Accuracy: 87.50%\n",
      "Batch 1024, Loss: 0.499, Accuracy: 87.18%\n",
      "Batch 1280, Loss: 0.469, Accuracy: 88.22%\n",
      "Completed training after 281.64 seconds.\n",
      "Val Loss: 2.301, Val Accuracy: 50.63%\n",
      "Completed validation after 12.23 seconds.\n",
      "Accuracy: 55.42%\n",
      "Completed testing after 59.02 seconds.\n",
      "Total epoch time: 352.88 seconds.\n",
      "Epoch [92/100]\n",
      "####################################################################################################\n",
      "Epoch 93 begin: 2025-05-13 20:47:34.892477.\n",
      "Batch 256, Loss: 0.465, Accuracy: 87.99%\n",
      "Batch 512, Loss: 0.460, Accuracy: 88.09%\n",
      "Batch 768, Loss: 0.478, Accuracy: 87.89%\n",
      "Batch 1024, Loss: 0.462, Accuracy: 88.18%\n",
      "Batch 1280, Loss: 0.468, Accuracy: 88.21%\n",
      "Completed training after 281.65 seconds.\n",
      "Val Loss: 2.266, Val Accuracy: 50.63%\n",
      "Completed validation after 12.23 seconds.\n",
      "Accuracy: 55.30%\n",
      "Completed testing after 58.96 seconds.\n",
      "Total epoch time: 352.84 seconds.\n",
      "Epoch [93/100]\n",
      "####################################################################################################\n",
      "Epoch 94 begin: 2025-05-13 20:53:27.736043.\n",
      "Batch 256, Loss: 0.487, Accuracy: 87.89%\n",
      "Batch 512, Loss: 0.477, Accuracy: 88.06%\n",
      "Batch 768, Loss: 0.469, Accuracy: 88.27%\n",
      "Batch 1024, Loss: 0.475, Accuracy: 87.93%\n",
      "Batch 1280, Loss: 0.487, Accuracy: 87.62%\n",
      "Completed training after 281.68 seconds.\n",
      "Val Loss: 2.322, Val Accuracy: 50.90%\n",
      "Completed validation after 12.24 seconds.\n",
      "Accuracy: 55.16%\n",
      "Completed testing after 58.98 seconds.\n",
      "Total epoch time: 352.90 seconds.\n",
      "Epoch [94/100]\n",
      "####################################################################################################\n",
      "Epoch 95 begin: 2025-05-13 20:59:20.635939.\n",
      "Batch 256, Loss: 0.478, Accuracy: 87.94%\n",
      "Batch 512, Loss: 0.468, Accuracy: 88.12%\n",
      "Batch 768, Loss: 0.461, Accuracy: 88.53%\n",
      "Batch 1024, Loss: 0.483, Accuracy: 87.84%\n",
      "Batch 1280, Loss: 0.495, Accuracy: 87.44%\n",
      "Completed training after 281.34 seconds.\n",
      "Val Loss: 2.286, Val Accuracy: 50.79%\n",
      "Completed validation after 12.24 seconds.\n",
      "Accuracy: 55.14%\n",
      "Completed testing after 59.04 seconds.\n",
      "Total epoch time: 352.62 seconds.\n",
      "Epoch [95/100]\n",
      "####################################################################################################\n",
      "Epoch 96 begin: 2025-05-13 21:05:13.255642.\n",
      "Batch 256, Loss: 0.463, Accuracy: 88.57%\n",
      "Batch 512, Loss: 0.494, Accuracy: 87.67%\n",
      "Batch 768, Loss: 0.487, Accuracy: 87.82%\n",
      "Batch 1024, Loss: 0.471, Accuracy: 88.24%\n",
      "Batch 1280, Loss: 0.454, Accuracy: 88.67%\n",
      "Completed training after 281.67 seconds.\n",
      "Val Loss: 2.273, Val Accuracy: 51.05%\n",
      "Completed validation after 12.24 seconds.\n",
      "Accuracy: 55.38%\n",
      "Completed testing after 59.10 seconds.\n",
      "Total epoch time: 353.01 seconds.\n",
      "Epoch [96/100]\n",
      "####################################################################################################\n",
      "Epoch 97 begin: 2025-05-13 21:11:06.263858.\n",
      "Batch 256, Loss: 0.476, Accuracy: 88.27%\n",
      "Batch 512, Loss: 0.477, Accuracy: 87.95%\n",
      "Batch 768, Loss: 0.478, Accuracy: 87.55%\n",
      "Batch 1024, Loss: 0.467, Accuracy: 88.21%\n",
      "Batch 1280, Loss: 0.492, Accuracy: 87.37%\n",
      "Completed training after 281.62 seconds.\n",
      "Val Loss: 2.274, Val Accuracy: 51.73%\n",
      "Completed validation after 12.28 seconds.\n",
      "Accuracy: 55.21%\n",
      "Completed testing after 59.04 seconds.\n",
      "Total epoch time: 352.95 seconds.\n",
      "Epoch [97/100]\n",
      "####################################################################################################\n",
      "Epoch 98 begin: 2025-05-13 21:16:59.214678.\n",
      "Batch 256, Loss: 0.465, Accuracy: 88.60%\n",
      "Batch 512, Loss: 0.462, Accuracy: 88.11%\n",
      "Batch 768, Loss: 0.488, Accuracy: 87.67%\n",
      "Batch 1024, Loss: 0.475, Accuracy: 87.93%\n",
      "Batch 1280, Loss: 0.470, Accuracy: 88.62%\n",
      "Completed training after 281.70 seconds.\n",
      "Val Loss: 2.270, Val Accuracy: 51.16%\n",
      "Completed validation after 12.23 seconds.\n",
      "Accuracy: 55.46%\n",
      "Completed testing after 59.03 seconds.\n",
      "Total epoch time: 352.96 seconds.\n",
      "Epoch [98/100]\n",
      "####################################################################################################\n",
      "Epoch 99 begin: 2025-05-13 21:22:52.176384.\n",
      "Batch 256, Loss: 0.466, Accuracy: 88.42%\n",
      "Batch 512, Loss: 0.472, Accuracy: 88.16%\n",
      "Batch 768, Loss: 0.462, Accuracy: 88.54%\n",
      "Batch 1024, Loss: 0.473, Accuracy: 88.09%\n",
      "Batch 1280, Loss: 0.463, Accuracy: 88.65%\n",
      "Completed training after 281.70 seconds.\n",
      "Val Loss: 2.303, Val Accuracy: 51.62%\n",
      "Completed validation after 12.27 seconds.\n",
      "Accuracy: 55.18%\n",
      "Completed testing after 59.03 seconds.\n",
      "Total epoch time: 353.00 seconds.\n",
      "Epoch [99/100]\n",
      "####################################################################################################\n",
      "Epoch 100 begin: 2025-05-13 21:28:45.173896.\n",
      "Batch 256, Loss: 0.456, Accuracy: 88.45%\n",
      "Batch 512, Loss: 0.477, Accuracy: 88.04%\n",
      "Batch 768, Loss: 0.461, Accuracy: 88.37%\n",
      "Batch 1024, Loss: 0.478, Accuracy: 87.60%\n",
      "Batch 1280, Loss: 0.490, Accuracy: 87.87%\n",
      "Completed training after 281.52 seconds.\n",
      "Val Loss: 2.279, Val Accuracy: 51.42%\n",
      "Completed validation after 12.24 seconds.\n",
      "Accuracy: 55.36%\n",
      "Completed testing after 59.04 seconds.\n",
      "Total epoch time: 352.80 seconds.\n",
      "Epoch [100/100]\n",
      "####################################################################################################\n"
     ]
    }
   ],
   "source": [
    "### TRAINING ###\n",
    "\n",
    "# Allow repeatability\n",
    "np.random.seed(random_seed)\n",
    "torch.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed_all(random_seed)\n",
    "\n",
    "# Create model object and connect it to the corresponding processing\n",
    "model = ResNet().to(device)\n",
    "\n",
    "# Define loss and optimizer\n",
    "loss_fn = nn.CrossEntropyLoss()  # loss_fn = FocalLoss(gamma=1.5)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
    "scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, patience=4)\n",
    "\n",
    "# Define mental state and start\n",
    "epoch, regret, grudge, pride, updates = 0, 10.0, 0, 0.0, 256\n",
    "epoch, regret, grudge, pride = run_epochs(num_epochs, model, optimizer, loss_fn, scheduler, epoch, regret, grudge, pride, updates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1c8b0bea-7537-4bcd-acd8-dc2a5b30e212",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(ResNet(\n",
       "   (layer1): Sequential(\n",
       "     (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
       "     (1): SELU()\n",
       "     (2): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "   )\n",
       "   (layer2): Sequential(\n",
       "     (0): Block(\n",
       "       (layer): Sequential(\n",
       "         (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "         (1): SELU()\n",
       "         (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "         (4): SELU()\n",
       "         (5): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "         (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       )\n",
       "       (p_layer): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "     )\n",
       "     (1): Block(\n",
       "       (layer): Sequential(\n",
       "         (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "         (1): SELU()\n",
       "         (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "         (4): SELU()\n",
       "         (5): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "         (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       )\n",
       "     )\n",
       "     (2): Block(\n",
       "       (layer): Sequential(\n",
       "         (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "         (1): SELU()\n",
       "         (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "         (4): SELU()\n",
       "         (5): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "         (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (layer3): Sequential(\n",
       "     (0): Block(\n",
       "       (layer): Sequential(\n",
       "         (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "         (1): SELU()\n",
       "         (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "         (4): SELU()\n",
       "         (5): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "         (6): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       )\n",
       "       (p_layer): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2))\n",
       "     )\n",
       "     (1): Block(\n",
       "       (layer): Sequential(\n",
       "         (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "         (1): SELU()\n",
       "         (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "         (4): SELU()\n",
       "         (5): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "         (6): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       )\n",
       "     )\n",
       "     (2): Block(\n",
       "       (layer): Sequential(\n",
       "         (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "         (1): SELU()\n",
       "         (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "         (4): SELU()\n",
       "         (5): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "         (6): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       )\n",
       "     )\n",
       "     (3): Block(\n",
       "       (layer): Sequential(\n",
       "         (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "         (1): SELU()\n",
       "         (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "         (4): SELU()\n",
       "         (5): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "         (6): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (layer4): Sequential(\n",
       "     (0): Block(\n",
       "       (layer): Sequential(\n",
       "         (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "         (1): SELU()\n",
       "         (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "         (4): SELU()\n",
       "         (5): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "         (6): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       )\n",
       "       (p_layer): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2))\n",
       "     )\n",
       "     (1): Block(\n",
       "       (layer): Sequential(\n",
       "         (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "         (1): SELU()\n",
       "         (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "         (4): SELU()\n",
       "         (5): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "         (6): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       )\n",
       "     )\n",
       "     (2): Block(\n",
       "       (layer): Sequential(\n",
       "         (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "         (1): SELU()\n",
       "         (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "         (4): SELU()\n",
       "         (5): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "         (6): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       )\n",
       "     )\n",
       "     (3): Block(\n",
       "       (layer): Sequential(\n",
       "         (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "         (1): SELU()\n",
       "         (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "         (4): SELU()\n",
       "         (5): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "         (6): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       )\n",
       "     )\n",
       "     (4): Block(\n",
       "       (layer): Sequential(\n",
       "         (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "         (1): SELU()\n",
       "         (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "         (4): SELU()\n",
       "         (5): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "         (6): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       )\n",
       "     )\n",
       "     (5): Block(\n",
       "       (layer): Sequential(\n",
       "         (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "         (1): SELU()\n",
       "         (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "         (4): SELU()\n",
       "         (5): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "         (6): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (layer5): Sequential(\n",
       "     (0): Block(\n",
       "       (layer): Sequential(\n",
       "         (0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "         (1): SELU()\n",
       "         (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "         (4): SELU()\n",
       "         (5): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
       "         (6): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       )\n",
       "       (p_layer): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2))\n",
       "     )\n",
       "     (1): Block(\n",
       "       (layer): Sequential(\n",
       "         (0): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "         (1): SELU()\n",
       "         (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "         (4): SELU()\n",
       "         (5): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
       "         (6): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       )\n",
       "     )\n",
       "     (2): Block(\n",
       "       (layer): Sequential(\n",
       "         (0): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "         (1): SELU()\n",
       "         (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "         (4): SELU()\n",
       "         (5): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
       "         (6): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (layer6): Sequential(\n",
       "     (0): AvgPool2d(kernel_size=8, stride=8, padding=0)\n",
       "     (1): Flatten(start_dim=1, end_dim=-1)\n",
       "     (2): Dropout(p=0.25, inplace=False)\n",
       "     (3): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "     (4): ReLU()\n",
       "     (5): Dropout(p=0.25, inplace=False)\n",
       "     (6): Linear(in_features=1024, out_features=91, bias=True)\n",
       "   )\n",
       " ),\n",
       " 13,\n",
       " 32,\n",
       " 0.01,\n",
       " 0.75,\n",
       " CrossEntropyLoss(),\n",
       " SGD (\n",
       " Parameter Group 0\n",
       "     dampening: 0\n",
       "     differentiable: False\n",
       "     foreach: None\n",
       "     fused: None\n",
       "     lr: 1.0000000000000004e-08\n",
       "     maximize: False\n",
       "     momentum: 0.75\n",
       "     nesterov: False\n",
       "     weight_decay: 0\n",
       " ),\n",
       " <torch.optim.lr_scheduler.ReduceLROnPlateau at 0x7fdfed909c90>)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model, random_seed, batch_size, lr, momentum, loss_fn, optimizer, scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "bf0d9782",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 101 begin: 2025-05-13 21:34:38.056422.\n",
      "Batch 256, Loss: 0.473, Accuracy: 88.22%\n",
      "Batch 512, Loss: 0.482, Accuracy: 87.83%\n",
      "Batch 768, Loss: 0.460, Accuracy: 88.46%\n",
      "Batch 1024, Loss: 0.460, Accuracy: 88.17%\n",
      "Batch 1280, Loss: 0.494, Accuracy: 87.43%\n",
      "Completed training after 281.69 seconds.\n",
      "Val Loss: 2.257, Val Accuracy: 51.64%\n",
      "Completed validation after 12.23 seconds.\n",
      "Accuracy: 55.53%\n",
      "Completed testing after 58.99 seconds.\n",
      "Total epoch time: 352.91 seconds.\n",
      "Epoch [101/200]\n",
      "####################################################################################################\n",
      "Epoch 102 begin: 2025-05-13 21:40:30.965559.\n",
      "Batch 256, Loss: 0.476, Accuracy: 88.26%\n",
      "Batch 512, Loss: 0.451, Accuracy: 88.38%\n",
      "Batch 768, Loss: 0.487, Accuracy: 87.46%\n",
      "Batch 1024, Loss: 0.455, Accuracy: 88.55%\n",
      "Batch 1280, Loss: 0.490, Accuracy: 87.48%\n",
      "Completed training after 281.66 seconds.\n",
      "Val Loss: 2.225, Val Accuracy: 52.03%\n",
      "Completed validation after 12.24 seconds.\n",
      "Accuracy: 55.30%\n",
      "Completed testing after 59.01 seconds.\n",
      "Total epoch time: 352.91 seconds.\n",
      "Epoch [102/200]\n",
      "####################################################################################################\n",
      "Epoch 103 begin: 2025-05-13 21:46:23.873460.\n",
      "Batch 256, Loss: 0.462, Accuracy: 88.24%\n",
      "Batch 512, Loss: 0.481, Accuracy: 87.95%\n",
      "Batch 768, Loss: 0.462, Accuracy: 87.92%\n",
      "Batch 1024, Loss: 0.478, Accuracy: 88.37%\n",
      "Batch 1280, Loss: 0.482, Accuracy: 87.81%\n",
      "Completed training after 281.67 seconds.\n",
      "Val Loss: 2.278, Val Accuracy: 51.01%\n",
      "Completed validation after 12.25 seconds.\n",
      "Accuracy: 55.53%\n",
      "Completed testing after 59.07 seconds.\n",
      "Total epoch time: 352.98 seconds.\n",
      "Epoch [103/200]\n",
      "####################################################################################################\n",
      "Epoch 104 begin: 2025-05-13 21:52:16.856325.\n",
      "Batch 256, Loss: 0.487, Accuracy: 87.81%\n",
      "Batch 512, Loss: 0.481, Accuracy: 87.78%\n",
      "Batch 768, Loss: 0.463, Accuracy: 88.54%\n",
      "Batch 1024, Loss: 0.459, Accuracy: 88.35%\n",
      "Batch 1280, Loss: 0.457, Accuracy: 88.40%\n",
      "Completed training after 281.70 seconds.\n",
      "Val Loss: 2.270, Val Accuracy: 51.44%\n",
      "Completed validation after 12.22 seconds.\n",
      "Accuracy: 55.17%\n",
      "Completed testing after 59.04 seconds.\n",
      "Total epoch time: 352.96 seconds.\n",
      "Epoch [104/200]\n",
      "####################################################################################################\n",
      "Epoch 105 begin: 2025-05-13 21:58:09.821176.\n",
      "Batch 256, Loss: 0.477, Accuracy: 87.81%\n",
      "Batch 512, Loss: 0.486, Accuracy: 88.05%\n",
      "Batch 768, Loss: 0.469, Accuracy: 88.02%\n",
      "Batch 1024, Loss: 0.494, Accuracy: 87.65%\n",
      "Batch 1280, Loss: 0.500, Accuracy: 87.39%\n",
      "Completed training after 281.70 seconds.\n",
      "Val Loss: 2.269, Val Accuracy: 51.49%\n",
      "Completed validation after 12.24 seconds.\n",
      "Accuracy: 55.26%\n",
      "Completed testing after 59.07 seconds.\n",
      "Total epoch time: 353.00 seconds.\n",
      "Epoch [105/200]\n",
      "####################################################################################################\n",
      "Epoch 106 begin: 2025-05-13 22:04:02.824211.\n",
      "Batch 256, Loss: 0.473, Accuracy: 87.73%\n",
      "Batch 512, Loss: 0.467, Accuracy: 88.13%\n",
      "Batch 768, Loss: 0.478, Accuracy: 87.92%\n",
      "Batch 1024, Loss: 0.469, Accuracy: 88.20%\n",
      "Batch 1280, Loss: 0.450, Accuracy: 88.89%\n",
      "Completed training after 281.69 seconds.\n",
      "Val Loss: 2.244, Val Accuracy: 51.73%\n",
      "Completed validation after 12.24 seconds.\n",
      "Accuracy: 55.51%\n",
      "Completed testing after 58.99 seconds.\n",
      "Total epoch time: 352.92 seconds.\n",
      "Epoch [106/200]\n",
      "####################################################################################################\n",
      "Epoch 107 begin: 2025-05-13 22:09:55.740338.\n",
      "Batch 256, Loss: 0.460, Accuracy: 88.22%\n",
      "Batch 512, Loss: 0.479, Accuracy: 88.12%\n",
      "Batch 768, Loss: 0.494, Accuracy: 87.57%\n",
      "Batch 1024, Loss: 0.482, Accuracy: 88.10%\n",
      "Batch 1280, Loss: 0.459, Accuracy: 88.06%\n",
      "Completed training after 281.74 seconds.\n",
      "Val Loss: 2.269, Val Accuracy: 51.62%\n",
      "Completed validation after 12.28 seconds.\n",
      "Accuracy: 55.32%\n",
      "Completed testing after 59.04 seconds.\n",
      "Total epoch time: 353.06 seconds.\n",
      "Epoch [107/200]\n",
      "####################################################################################################\n",
      "Epoch 108 begin: 2025-05-13 22:15:48.803743.\n",
      "Batch 256, Loss: 0.489, Accuracy: 87.76%\n",
      "Batch 512, Loss: 0.477, Accuracy: 88.06%\n",
      "Batch 768, Loss: 0.476, Accuracy: 88.00%\n",
      "Batch 1024, Loss: 0.471, Accuracy: 88.26%\n",
      "Batch 1280, Loss: 0.465, Accuracy: 88.37%\n",
      "Completed training after 281.57 seconds.\n",
      "Val Loss: 2.260, Val Accuracy: 51.03%\n",
      "Completed validation after 12.26 seconds.\n",
      "Accuracy: 55.52%\n",
      "Completed testing after 59.06 seconds.\n",
      "Total epoch time: 352.90 seconds.\n",
      "Epoch [108/200]\n",
      "####################################################################################################\n",
      "Epoch 109 begin: 2025-05-13 22:21:41.701813.\n",
      "Batch 256, Loss: 0.463, Accuracy: 88.20%\n",
      "Batch 512, Loss: 0.473, Accuracy: 88.12%\n",
      "Batch 768, Loss: 0.470, Accuracy: 87.96%\n",
      "Batch 1024, Loss: 0.458, Accuracy: 88.22%\n",
      "Batch 1280, Loss: 0.489, Accuracy: 87.55%\n",
      "Completed training after 281.63 seconds.\n",
      "Val Loss: 2.302, Val Accuracy: 51.99%\n",
      "Completed validation after 12.23 seconds.\n",
      "Accuracy: 55.45%\n",
      "Completed testing after 59.01 seconds.\n",
      "Total epoch time: 352.87 seconds.\n",
      "Epoch [109/200]\n",
      "####################################################################################################\n",
      "Epoch 110 begin: 2025-05-13 22:27:34.569744.\n",
      "Batch 256, Loss: 0.481, Accuracy: 87.73%\n",
      "Batch 512, Loss: 0.483, Accuracy: 87.99%\n",
      "Batch 768, Loss: 0.481, Accuracy: 87.89%\n",
      "Batch 1024, Loss: 0.485, Accuracy: 87.84%\n",
      "Batch 1280, Loss: 0.501, Accuracy: 87.39%\n",
      "Completed training after 281.59 seconds.\n",
      "Val Loss: 2.268, Val Accuracy: 51.22%\n",
      "Completed validation after 12.22 seconds.\n",
      "Accuracy: 55.27%\n",
      "Completed testing after 59.05 seconds.\n",
      "Total epoch time: 352.87 seconds.\n",
      "Epoch [110/200]\n",
      "####################################################################################################\n",
      "Epoch 111 begin: 2025-05-13 22:33:27.436018.\n",
      "Batch 256, Loss: 0.471, Accuracy: 88.11%\n",
      "Batch 512, Loss: 0.486, Accuracy: 87.72%\n",
      "Batch 768, Loss: 0.470, Accuracy: 88.32%\n",
      "Batch 1024, Loss: 0.468, Accuracy: 88.34%\n",
      "Batch 1280, Loss: 0.492, Accuracy: 87.76%\n",
      "Completed training after 281.22 seconds.\n",
      "Val Loss: 2.253, Val Accuracy: 51.49%\n",
      "Completed validation after 12.23 seconds.\n",
      "Accuracy: 55.11%\n",
      "Completed testing after 58.98 seconds.\n",
      "Total epoch time: 352.43 seconds.\n",
      "Epoch [111/200]\n",
      "####################################################################################################\n",
      "Epoch 112 begin: 2025-05-13 22:39:19.861684.\n",
      "Batch 256, Loss: 0.464, Accuracy: 88.17%\n",
      "Batch 512, Loss: 0.477, Accuracy: 87.88%\n",
      "Batch 768, Loss: 0.479, Accuracy: 87.96%\n",
      "Batch 1024, Loss: 0.462, Accuracy: 88.38%\n",
      "Batch 1280, Loss: 0.478, Accuracy: 88.17%\n",
      "Completed training after 281.60 seconds.\n",
      "Val Loss: 2.277, Val Accuracy: 51.38%\n",
      "Completed validation after 12.21 seconds.\n",
      "Accuracy: 55.40%\n",
      "Completed testing after 58.96 seconds.\n",
      "Total epoch time: 352.76 seconds.\n",
      "Epoch [112/200]\n",
      "####################################################################################################\n",
      "Epoch 113 begin: 2025-05-13 22:45:12.624339.\n",
      "Batch 256, Loss: 0.498, Accuracy: 87.48%\n",
      "Batch 512, Loss: 0.450, Accuracy: 88.61%\n",
      "Batch 768, Loss: 0.482, Accuracy: 87.92%\n",
      "Batch 1024, Loss: 0.484, Accuracy: 87.54%\n",
      "Batch 1280, Loss: 0.496, Accuracy: 87.62%\n",
      "Completed training after 281.51 seconds.\n",
      "Val Loss: 2.254, Val Accuracy: 52.08%\n",
      "Completed validation after 12.21 seconds.\n",
      "Accuracy: 55.22%\n",
      "Completed testing after 58.95 seconds.\n",
      "Total epoch time: 352.67 seconds.\n",
      "Epoch [113/200]\n",
      "####################################################################################################\n",
      "Epoch 114 begin: 2025-05-13 22:51:05.291781.\n",
      "Batch 256, Loss: 0.483, Accuracy: 87.67%\n",
      "Batch 512, Loss: 0.487, Accuracy: 87.70%\n",
      "Batch 768, Loss: 0.450, Accuracy: 89.01%\n",
      "Batch 1024, Loss: 0.476, Accuracy: 87.39%\n",
      "Batch 1280, Loss: 0.466, Accuracy: 88.11%\n",
      "Completed training after 281.54 seconds.\n",
      "Val Loss: 2.260, Val Accuracy: 51.42%\n",
      "Completed validation after 12.23 seconds.\n",
      "Accuracy: 55.37%\n",
      "Completed testing after 59.02 seconds.\n",
      "Total epoch time: 352.79 seconds.\n",
      "Epoch [114/200]\n",
      "####################################################################################################\n",
      "Epoch 115 begin: 2025-05-13 22:56:58.083727.\n",
      "Batch 256, Loss: 0.490, Accuracy: 87.34%\n",
      "Batch 512, Loss: 0.485, Accuracy: 87.34%\n",
      "Batch 768, Loss: 0.465, Accuracy: 88.16%\n",
      "Batch 1024, Loss: 0.468, Accuracy: 88.18%\n",
      "Batch 1280, Loss: 0.461, Accuracy: 88.27%\n",
      "Completed training after 281.64 seconds.\n",
      "Val Loss: 2.303, Val Accuracy: 50.92%\n",
      "Completed validation after 12.27 seconds.\n",
      "Accuracy: 55.31%\n",
      "Completed testing after 58.99 seconds.\n",
      "Total epoch time: 352.91 seconds.\n",
      "Epoch [115/200]\n",
      "####################################################################################################\n",
      "Epoch 116 begin: 2025-05-13 23:02:50.990109.\n",
      "Batch 256, Loss: 0.453, Accuracy: 88.77%\n",
      "Batch 512, Loss: 0.484, Accuracy: 87.68%\n",
      "Batch 768, Loss: 0.498, Accuracy: 87.32%\n",
      "Batch 1024, Loss: 0.471, Accuracy: 87.95%\n",
      "Batch 1280, Loss: 0.469, Accuracy: 88.29%\n",
      "Completed training after 281.55 seconds.\n",
      "Val Loss: 2.253, Val Accuracy: 51.90%\n",
      "Completed validation after 12.23 seconds.\n",
      "Accuracy: 55.50%\n",
      "Completed testing after 59.01 seconds.\n",
      "Total epoch time: 352.80 seconds.\n",
      "Epoch [116/200]\n",
      "####################################################################################################\n",
      "Epoch 117 begin: 2025-05-13 23:08:43.786398.\n",
      "Batch 256, Loss: 0.444, Accuracy: 88.66%\n",
      "Batch 512, Loss: 0.469, Accuracy: 88.05%\n",
      "Batch 768, Loss: 0.488, Accuracy: 87.54%\n",
      "Batch 1024, Loss: 0.492, Accuracy: 87.77%\n",
      "Batch 1280, Loss: 0.475, Accuracy: 88.12%\n",
      "Completed training after 281.56 seconds.\n",
      "Val Loss: 2.267, Val Accuracy: 51.27%\n",
      "Completed validation after 12.22 seconds.\n",
      "Accuracy: 55.31%\n",
      "Completed testing after 58.95 seconds.\n",
      "Total epoch time: 352.72 seconds.\n",
      "Epoch [117/200]\n",
      "####################################################################################################\n",
      "Epoch 118 begin: 2025-05-13 23:14:36.509743.\n",
      "Batch 256, Loss: 0.481, Accuracy: 87.54%\n",
      "Batch 512, Loss: 0.479, Accuracy: 87.99%\n",
      "Batch 768, Loss: 0.479, Accuracy: 88.04%\n",
      "Batch 1024, Loss: 0.487, Accuracy: 88.15%\n",
      "Batch 1280, Loss: 0.460, Accuracy: 88.54%\n",
      "Completed training after 281.58 seconds.\n",
      "Val Loss: 2.285, Val Accuracy: 51.49%\n",
      "Completed validation after 12.22 seconds.\n",
      "Accuracy: 55.02%\n",
      "Completed testing after 59.09 seconds.\n",
      "Total epoch time: 352.89 seconds.\n",
      "Epoch [118/200]\n",
      "####################################################################################################\n",
      "Epoch 119 begin: 2025-05-13 23:20:29.398132.\n",
      "Batch 256, Loss: 0.444, Accuracy: 88.71%\n",
      "Batch 512, Loss: 0.484, Accuracy: 87.83%\n",
      "Batch 768, Loss: 0.464, Accuracy: 88.01%\n",
      "Batch 1024, Loss: 0.490, Accuracy: 87.40%\n",
      "Batch 1280, Loss: 0.476, Accuracy: 87.81%\n",
      "Completed training after 281.52 seconds.\n",
      "Val Loss: 2.304, Val Accuracy: 51.60%\n",
      "Completed validation after 12.25 seconds.\n",
      "Accuracy: 55.21%\n",
      "Completed testing after 59.03 seconds.\n",
      "Total epoch time: 352.81 seconds.\n",
      "Epoch [119/200]\n",
      "####################################################################################################\n",
      "Epoch 120 begin: 2025-05-13 23:26:22.204300.\n",
      "Batch 256, Loss: 0.479, Accuracy: 87.90%\n",
      "Batch 512, Loss: 0.485, Accuracy: 87.85%\n",
      "Batch 768, Loss: 0.464, Accuracy: 88.37%\n",
      "Batch 1024, Loss: 0.475, Accuracy: 88.32%\n",
      "Batch 1280, Loss: 0.478, Accuracy: 87.49%\n",
      "Completed training after 281.59 seconds.\n",
      "Val Loss: 2.278, Val Accuracy: 51.14%\n",
      "Completed validation after 12.23 seconds.\n",
      "Accuracy: 55.23%\n",
      "Completed testing after 58.99 seconds.\n",
      "Total epoch time: 352.82 seconds.\n",
      "Epoch [120/200]\n",
      "####################################################################################################\n",
      "Epoch 121 begin: 2025-05-13 23:32:15.019971.\n",
      "Batch 256, Loss: 0.468, Accuracy: 88.20%\n",
      "Batch 512, Loss: 0.470, Accuracy: 87.99%\n",
      "Batch 768, Loss: 0.485, Accuracy: 88.23%\n",
      "Batch 1024, Loss: 0.463, Accuracy: 88.48%\n",
      "Batch 1280, Loss: 0.473, Accuracy: 87.74%\n",
      "Completed training after 281.57 seconds.\n",
      "Val Loss: 2.294, Val Accuracy: 51.33%\n",
      "Completed validation after 12.24 seconds.\n",
      "Accuracy: 55.23%\n",
      "Completed testing after 59.05 seconds.\n",
      "Total epoch time: 352.87 seconds.\n",
      "Epoch [121/200]\n",
      "####################################################################################################\n",
      "Epoch 122 begin: 2025-05-13 23:38:07.885636.\n",
      "Batch 256, Loss: 0.468, Accuracy: 88.11%\n",
      "Batch 512, Loss: 0.479, Accuracy: 87.79%\n",
      "Batch 768, Loss: 0.495, Accuracy: 87.61%\n",
      "Batch 1024, Loss: 0.486, Accuracy: 87.94%\n",
      "Batch 1280, Loss: 0.460, Accuracy: 88.43%\n",
      "Completed training after 281.21 seconds.\n",
      "Val Loss: 2.276, Val Accuracy: 50.98%\n",
      "Completed validation after 12.25 seconds.\n",
      "Accuracy: 55.14%\n",
      "Completed testing after 59.05 seconds.\n",
      "Total epoch time: 352.51 seconds.\n",
      "Epoch [122/200]\n",
      "####################################################################################################\n",
      "Epoch 123 begin: 2025-05-13 23:44:00.398162.\n",
      "Batch 256, Loss: 0.477, Accuracy: 87.72%\n",
      "Batch 512, Loss: 0.476, Accuracy: 88.44%\n",
      "Batch 768, Loss: 0.493, Accuracy: 87.62%\n",
      "Batch 1024, Loss: 0.496, Accuracy: 87.61%\n",
      "Batch 1280, Loss: 0.442, Accuracy: 88.65%\n",
      "Completed training after 281.58 seconds.\n",
      "Val Loss: 2.272, Val Accuracy: 51.27%\n",
      "Completed validation after 12.22 seconds.\n",
      "Accuracy: 55.40%\n",
      "Completed testing after 59.01 seconds.\n",
      "Total epoch time: 352.82 seconds.\n",
      "Epoch [123/200]\n",
      "####################################################################################################\n",
      "Epoch 124 begin: 2025-05-13 23:49:53.221276.\n",
      "Batch 256, Loss: 0.477, Accuracy: 87.78%\n",
      "Batch 512, Loss: 0.463, Accuracy: 88.48%\n",
      "Batch 768, Loss: 0.485, Accuracy: 87.52%\n",
      "Batch 1024, Loss: 0.482, Accuracy: 87.92%\n",
      "Batch 1280, Loss: 0.457, Accuracy: 88.02%\n",
      "Completed training after 281.54 seconds.\n",
      "Val Loss: 2.249, Val Accuracy: 51.53%\n",
      "Completed validation after 12.23 seconds.\n",
      "Accuracy: 55.19%\n",
      "Completed testing after 59.00 seconds.\n",
      "Total epoch time: 352.76 seconds.\n",
      "Epoch [124/200]\n",
      "####################################################################################################\n",
      "Epoch 125 begin: 2025-05-13 23:55:45.980681.\n",
      "Batch 256, Loss: 0.470, Accuracy: 88.22%\n",
      "Batch 512, Loss: 0.466, Accuracy: 88.18%\n",
      "Batch 768, Loss: 0.482, Accuracy: 87.76%\n",
      "Batch 1024, Loss: 0.487, Accuracy: 88.07%\n",
      "Batch 1280, Loss: 0.476, Accuracy: 87.93%\n",
      "Completed training after 281.55 seconds.\n",
      "Val Loss: 2.278, Val Accuracy: 51.81%\n",
      "Completed validation after 12.25 seconds.\n",
      "Accuracy: 55.23%\n",
      "Completed testing after 59.01 seconds.\n",
      "Total epoch time: 352.81 seconds.\n",
      "Epoch [125/200]\n",
      "####################################################################################################\n",
      "Epoch 126 begin: 2025-05-14 00:01:38.786782.\n",
      "Batch 256, Loss: 0.473, Accuracy: 88.15%\n",
      "Batch 512, Loss: 0.477, Accuracy: 87.98%\n",
      "Batch 768, Loss: 0.466, Accuracy: 87.94%\n",
      "Batch 1024, Loss: 0.466, Accuracy: 88.00%\n",
      "Batch 1280, Loss: 0.464, Accuracy: 88.38%\n",
      "Completed training after 281.22 seconds.\n",
      "Val Loss: 2.264, Val Accuracy: 51.44%\n",
      "Completed validation after 12.26 seconds.\n",
      "Accuracy: 55.43%\n",
      "Completed testing after 58.93 seconds.\n",
      "Total epoch time: 352.41 seconds.\n",
      "Epoch [126/200]\n",
      "####################################################################################################\n",
      "Epoch 127 begin: 2025-05-14 00:07:31.196082.\n",
      "Batch 256, Loss: 0.475, Accuracy: 88.01%\n",
      "Batch 512, Loss: 0.482, Accuracy: 87.39%\n",
      "Batch 768, Loss: 0.500, Accuracy: 87.48%\n",
      "Batch 1024, Loss: 0.466, Accuracy: 88.12%\n",
      "Batch 1280, Loss: 0.477, Accuracy: 88.09%\n",
      "Completed training after 281.53 seconds.\n",
      "Val Loss: 2.232, Val Accuracy: 51.40%\n",
      "Completed validation after 12.24 seconds.\n",
      "Accuracy: 55.20%\n",
      "Completed testing after 58.93 seconds.\n",
      "Total epoch time: 352.69 seconds.\n",
      "Epoch [127/200]\n",
      "####################################################################################################\n",
      "Epoch 128 begin: 2025-05-14 00:13:23.889243.\n",
      "Batch 256, Loss: 0.466, Accuracy: 88.48%\n",
      "Batch 512, Loss: 0.486, Accuracy: 87.63%\n",
      "Batch 768, Loss: 0.460, Accuracy: 88.35%\n",
      "Batch 1024, Loss: 0.486, Accuracy: 87.84%\n",
      "Batch 1280, Loss: 0.482, Accuracy: 87.56%\n",
      "Completed training after 281.54 seconds.\n",
      "Val Loss: 2.228, Val Accuracy: 52.08%\n",
      "Completed validation after 12.24 seconds.\n",
      "Accuracy: 55.51%\n",
      "Completed testing after 58.99 seconds.\n",
      "Total epoch time: 352.78 seconds.\n",
      "Epoch [128/200]\n",
      "####################################################################################################\n",
      "Epoch 129 begin: 2025-05-14 00:19:16.670129.\n",
      "Batch 256, Loss: 0.480, Accuracy: 88.12%\n",
      "Batch 512, Loss: 0.481, Accuracy: 87.52%\n",
      "Batch 768, Loss: 0.481, Accuracy: 87.76%\n",
      "Batch 1024, Loss: 0.491, Accuracy: 87.51%\n",
      "Batch 1280, Loss: 0.467, Accuracy: 88.37%\n",
      "Completed training after 281.51 seconds.\n",
      "Val Loss: 2.238, Val Accuracy: 51.01%\n",
      "Completed validation after 12.23 seconds.\n",
      "Accuracy: 55.25%\n",
      "Completed testing after 58.93 seconds.\n",
      "Total epoch time: 352.67 seconds.\n",
      "Epoch [129/200]\n",
      "####################################################################################################\n",
      "Epoch 130 begin: 2025-05-14 00:25:09.337302.\n",
      "Batch 256, Loss: 0.489, Accuracy: 87.52%\n",
      "Batch 512, Loss: 0.487, Accuracy: 88.09%\n",
      "Batch 768, Loss: 0.477, Accuracy: 87.85%\n",
      "Batch 1024, Loss: 0.467, Accuracy: 88.35%\n",
      "Batch 1280, Loss: 0.481, Accuracy: 87.93%\n",
      "Completed training after 281.57 seconds.\n",
      "Val Loss: 2.250, Val Accuracy: 51.16%\n",
      "Completed validation after 12.25 seconds.\n",
      "Accuracy: 55.40%\n",
      "Completed testing after 59.00 seconds.\n",
      "Total epoch time: 352.82 seconds.\n",
      "Epoch [130/200]\n",
      "####################################################################################################\n",
      "Epoch 131 begin: 2025-05-14 00:31:02.160997.\n",
      "Batch 256, Loss: 0.485, Accuracy: 87.65%\n",
      "Batch 512, Loss: 0.456, Accuracy: 88.32%\n",
      "Batch 768, Loss: 0.467, Accuracy: 88.35%\n",
      "Batch 1024, Loss: 0.477, Accuracy: 88.16%\n",
      "Batch 1280, Loss: 0.482, Accuracy: 87.77%\n",
      "Completed training after 281.23 seconds.\n",
      "Val Loss: 2.243, Val Accuracy: 51.97%\n",
      "Completed validation after 12.26 seconds.\n",
      "Accuracy: 55.53%\n",
      "Completed testing after 59.06 seconds.\n",
      "Total epoch time: 352.55 seconds.\n",
      "Epoch [131/200]\n",
      "####################################################################################################\n",
      "Epoch 132 begin: 2025-05-14 00:36:54.706389.\n",
      "Batch 256, Loss: 0.467, Accuracy: 87.99%\n",
      "Batch 512, Loss: 0.461, Accuracy: 88.56%\n",
      "Batch 768, Loss: 0.478, Accuracy: 87.41%\n",
      "Batch 1024, Loss: 0.491, Accuracy: 87.65%\n",
      "Batch 1280, Loss: 0.467, Accuracy: 88.33%\n",
      "Completed training after 281.52 seconds.\n",
      "Val Loss: 2.298, Val Accuracy: 51.31%\n",
      "Completed validation after 12.27 seconds.\n",
      "Accuracy: 55.28%\n",
      "Completed testing after 58.98 seconds.\n",
      "Total epoch time: 352.76 seconds.\n",
      "Epoch [132/200]\n",
      "####################################################################################################\n",
      "Epoch 133 begin: 2025-05-14 00:42:47.470070.\n",
      "Batch 256, Loss: 0.475, Accuracy: 88.12%\n",
      "Batch 512, Loss: 0.479, Accuracy: 87.56%\n",
      "Batch 768, Loss: 0.478, Accuracy: 87.87%\n",
      "Batch 1024, Loss: 0.467, Accuracy: 87.99%\n",
      "Batch 1280, Loss: 0.494, Accuracy: 87.13%\n",
      "Completed training after 281.47 seconds.\n",
      "Val Loss: 2.283, Val Accuracy: 51.22%\n",
      "Completed validation after 12.26 seconds.\n",
      "Accuracy: 55.23%\n",
      "Completed testing after 58.96 seconds.\n",
      "Total epoch time: 352.69 seconds.\n",
      "Epoch [133/200]\n",
      "####################################################################################################\n",
      "Epoch 134 begin: 2025-05-14 00:48:40.156569.\n",
      "Batch 256, Loss: 0.486, Accuracy: 87.85%\n",
      "Batch 512, Loss: 0.486, Accuracy: 87.74%\n",
      "Batch 768, Loss: 0.469, Accuracy: 87.92%\n",
      "Batch 1024, Loss: 0.468, Accuracy: 88.34%\n",
      "Batch 1280, Loss: 0.473, Accuracy: 87.70%\n",
      "Completed training after 281.24 seconds.\n",
      "Val Loss: 2.275, Val Accuracy: 50.24%\n",
      "Completed validation after 12.24 seconds.\n",
      "Accuracy: 55.52%\n",
      "Completed testing after 59.02 seconds.\n",
      "Total epoch time: 352.50 seconds.\n",
      "Epoch [134/200]\n",
      "####################################################################################################\n",
      "Epoch 135 begin: 2025-05-14 00:54:32.657146.\n",
      "Batch 256, Loss: 0.465, Accuracy: 88.18%\n",
      "Batch 512, Loss: 0.489, Accuracy: 87.76%\n",
      "Batch 768, Loss: 0.477, Accuracy: 87.89%\n",
      "Batch 1024, Loss: 0.469, Accuracy: 88.35%\n",
      "Batch 1280, Loss: 0.478, Accuracy: 87.98%\n",
      "Completed training after 281.56 seconds.\n",
      "Val Loss: 2.251, Val Accuracy: 51.68%\n",
      "Completed validation after 12.23 seconds.\n",
      "Accuracy: 55.47%\n",
      "Completed testing after 58.95 seconds.\n",
      "Total epoch time: 352.74 seconds.\n",
      "Epoch [135/200]\n",
      "####################################################################################################\n",
      "Epoch 136 begin: 2025-05-14 01:00:25.399999.\n",
      "Batch 256, Loss: 0.476, Accuracy: 88.06%\n",
      "Batch 512, Loss: 0.462, Accuracy: 88.46%\n",
      "Batch 768, Loss: 0.479, Accuracy: 88.23%\n",
      "Batch 1024, Loss: 0.466, Accuracy: 88.15%\n",
      "Batch 1280, Loss: 0.481, Accuracy: 87.77%\n",
      "Completed training after 281.58 seconds.\n",
      "Val Loss: 2.263, Val Accuracy: 51.49%\n",
      "Completed validation after 12.26 seconds.\n",
      "Accuracy: 55.25%\n",
      "Completed testing after 58.99 seconds.\n",
      "Total epoch time: 352.83 seconds.\n",
      "Epoch [136/200]\n",
      "####################################################################################################\n",
      "Epoch 137 begin: 2025-05-14 01:06:18.226295.\n",
      "Batch 256, Loss: 0.479, Accuracy: 87.87%\n",
      "Batch 512, Loss: 0.487, Accuracy: 87.78%\n",
      "Batch 768, Loss: 0.471, Accuracy: 88.04%\n",
      "Batch 1024, Loss: 0.458, Accuracy: 88.43%\n",
      "Batch 1280, Loss: 0.457, Accuracy: 88.35%\n",
      "Completed training after 281.23 seconds.\n",
      "Val Loss: 2.255, Val Accuracy: 51.16%\n",
      "Completed validation after 12.27 seconds.\n",
      "Accuracy: 55.37%\n",
      "Completed testing after 59.03 seconds.\n",
      "Total epoch time: 352.53 seconds.\n",
      "Epoch [137/200]\n",
      "####################################################################################################\n",
      "Epoch 138 begin: 2025-05-14 01:12:10.757848.\n",
      "Batch 256, Loss: 0.474, Accuracy: 88.44%\n",
      "Batch 512, Loss: 0.460, Accuracy: 88.22%\n",
      "Batch 768, Loss: 0.444, Accuracy: 88.87%\n",
      "Batch 1024, Loss: 0.468, Accuracy: 88.10%\n",
      "Batch 1280, Loss: 0.500, Accuracy: 87.38%\n",
      "Completed training after 281.51 seconds.\n",
      "Val Loss: 2.250, Val Accuracy: 51.64%\n",
      "Completed validation after 12.20 seconds.\n",
      "Accuracy: 55.30%\n",
      "Completed testing after 58.96 seconds.\n",
      "Total epoch time: 352.67 seconds.\n",
      "Epoch [138/200]\n",
      "####################################################################################################\n",
      "Epoch 139 begin: 2025-05-14 01:18:03.426043.\n",
      "Batch 256, Loss: 0.496, Accuracy: 87.37%\n",
      "Batch 512, Loss: 0.484, Accuracy: 87.71%\n",
      "Batch 768, Loss: 0.492, Accuracy: 87.08%\n",
      "Batch 1024, Loss: 0.486, Accuracy: 87.92%\n",
      "Batch 1280, Loss: 0.491, Accuracy: 87.24%\n",
      "Completed training after 281.27 seconds.\n",
      "Val Loss: 2.251, Val Accuracy: 51.70%\n",
      "Completed validation after 12.25 seconds.\n",
      "Accuracy: 55.25%\n",
      "Completed testing after 59.02 seconds.\n",
      "Total epoch time: 352.54 seconds.\n",
      "Epoch [139/200]\n",
      "####################################################################################################\n",
      "Epoch 140 begin: 2025-05-14 01:23:55.965672.\n",
      "Batch 256, Loss: 0.497, Accuracy: 87.50%\n",
      "Batch 512, Loss: 0.472, Accuracy: 88.00%\n",
      "Batch 768, Loss: 0.482, Accuracy: 87.82%\n",
      "Batch 1024, Loss: 0.479, Accuracy: 88.10%\n",
      "Batch 1280, Loss: 0.481, Accuracy: 88.12%\n",
      "Completed training after 281.21 seconds.\n",
      "Val Loss: 2.273, Val Accuracy: 51.68%\n",
      "Completed validation after 12.20 seconds.\n",
      "Accuracy: 55.37%\n",
      "Completed testing after 58.98 seconds.\n",
      "Total epoch time: 352.39 seconds.\n",
      "Epoch [140/200]\n",
      "####################################################################################################\n",
      "Epoch 141 begin: 2025-05-14 01:29:48.356650.\n",
      "Batch 256, Loss: 0.479, Accuracy: 87.71%\n",
      "Batch 512, Loss: 0.483, Accuracy: 87.55%\n",
      "Batch 768, Loss: 0.459, Accuracy: 88.44%\n",
      "Batch 1024, Loss: 0.482, Accuracy: 88.12%\n",
      "Batch 1280, Loss: 0.467, Accuracy: 88.37%\n",
      "Completed training after 281.50 seconds.\n",
      "Val Loss: 2.291, Val Accuracy: 51.46%\n",
      "Completed validation after 12.26 seconds.\n",
      "Accuracy: 55.36%\n",
      "Completed testing after 59.03 seconds.\n",
      "Total epoch time: 352.79 seconds.\n",
      "Epoch [141/200]\n",
      "####################################################################################################\n",
      "Epoch 142 begin: 2025-05-14 01:35:41.147616.\n",
      "Batch 256, Loss: 0.468, Accuracy: 88.17%\n",
      "Batch 512, Loss: 0.486, Accuracy: 87.67%\n",
      "Batch 768, Loss: 0.470, Accuracy: 87.93%\n",
      "Batch 1024, Loss: 0.473, Accuracy: 87.90%\n",
      "Batch 1280, Loss: 0.467, Accuracy: 88.17%\n",
      "Completed training after 281.24 seconds.\n",
      "Val Loss: 2.257, Val Accuracy: 51.81%\n",
      "Completed validation after 12.22 seconds.\n",
      "Accuracy: 55.44%\n",
      "Completed testing after 58.88 seconds.\n",
      "Total epoch time: 352.33 seconds.\n",
      "Epoch [142/200]\n",
      "####################################################################################################\n",
      "Epoch 143 begin: 2025-05-14 01:41:33.479347.\n",
      "Batch 256, Loss: 0.506, Accuracy: 87.23%\n",
      "Batch 512, Loss: 0.476, Accuracy: 88.24%\n",
      "Batch 768, Loss: 0.478, Accuracy: 88.50%\n",
      "Batch 1024, Loss: 0.487, Accuracy: 87.93%\n",
      "Batch 1280, Loss: 0.494, Accuracy: 87.66%\n",
      "Completed training after 281.20 seconds.\n",
      "Val Loss: 2.296, Val Accuracy: 51.25%\n",
      "Completed validation after 12.22 seconds.\n",
      "Accuracy: 55.32%\n",
      "Completed testing after 58.98 seconds.\n",
      "Total epoch time: 352.40 seconds.\n",
      "Epoch [143/200]\n",
      "####################################################################################################\n",
      "Epoch 144 begin: 2025-05-14 01:47:25.880270.\n",
      "Batch 256, Loss: 0.479, Accuracy: 87.79%\n",
      "Batch 512, Loss: 0.485, Accuracy: 87.76%\n",
      "Batch 768, Loss: 0.487, Accuracy: 87.77%\n",
      "Batch 1024, Loss: 0.473, Accuracy: 87.78%\n",
      "Batch 1280, Loss: 0.487, Accuracy: 87.78%\n",
      "Completed training after 281.25 seconds.\n",
      "Val Loss: 2.292, Val Accuracy: 51.16%\n",
      "Completed validation after 12.21 seconds.\n",
      "Accuracy: 55.24%\n",
      "Completed testing after 58.95 seconds.\n",
      "Total epoch time: 352.41 seconds.\n",
      "Epoch [144/200]\n",
      "####################################################################################################\n",
      "Epoch 145 begin: 2025-05-14 01:53:18.285804.\n",
      "Batch 256, Loss: 0.470, Accuracy: 88.32%\n",
      "Batch 512, Loss: 0.471, Accuracy: 88.40%\n",
      "Batch 768, Loss: 0.465, Accuracy: 88.35%\n",
      "Batch 1024, Loss: 0.463, Accuracy: 88.27%\n",
      "Batch 1280, Loss: 0.491, Accuracy: 87.61%\n",
      "Completed training after 281.18 seconds.\n",
      "Val Loss: 2.268, Val Accuracy: 51.35%\n",
      "Completed validation after 12.25 seconds.\n",
      "Accuracy: 55.22%\n",
      "Completed testing after 59.03 seconds.\n",
      "Total epoch time: 352.46 seconds.\n",
      "Epoch [145/200]\n",
      "####################################################################################################\n",
      "Epoch 146 begin: 2025-05-14 01:59:10.748041.\n",
      "Batch 256, Loss: 0.478, Accuracy: 87.82%\n",
      "Batch 512, Loss: 0.476, Accuracy: 88.01%\n",
      "Batch 768, Loss: 0.467, Accuracy: 88.31%\n",
      "Batch 1024, Loss: 0.468, Accuracy: 88.09%\n",
      "Batch 1280, Loss: 0.475, Accuracy: 87.92%\n",
      "Completed training after 281.54 seconds.\n",
      "Val Loss: 2.274, Val Accuracy: 51.55%\n",
      "Completed validation after 12.23 seconds.\n",
      "Accuracy: 55.34%\n",
      "Completed testing after 59.05 seconds.\n",
      "Total epoch time: 352.82 seconds.\n",
      "Epoch [146/200]\n",
      "####################################################################################################\n",
      "Epoch 147 begin: 2025-05-14 02:05:03.567028.\n",
      "Batch 256, Loss: 0.477, Accuracy: 87.89%\n",
      "Batch 512, Loss: 0.507, Accuracy: 87.40%\n",
      "Batch 768, Loss: 0.481, Accuracy: 87.62%\n",
      "Batch 1024, Loss: 0.475, Accuracy: 87.87%\n",
      "Batch 1280, Loss: 0.470, Accuracy: 88.31%\n",
      "Completed training after 281.69 seconds.\n",
      "Val Loss: 2.280, Val Accuracy: 51.20%\n",
      "Completed validation after 12.25 seconds.\n",
      "Accuracy: 55.27%\n",
      "Completed testing after 59.02 seconds.\n",
      "Total epoch time: 352.95 seconds.\n",
      "Epoch [147/200]\n",
      "####################################################################################################\n",
      "Epoch 148 begin: 2025-05-14 02:10:56.516732.\n",
      "Batch 256, Loss: 0.458, Accuracy: 88.57%\n",
      "Batch 512, Loss: 0.485, Accuracy: 87.70%\n",
      "Batch 768, Loss: 0.473, Accuracy: 87.79%\n",
      "Batch 1024, Loss: 0.476, Accuracy: 88.04%\n",
      "Batch 1280, Loss: 0.479, Accuracy: 87.72%\n",
      "Completed training after 281.18 seconds.\n",
      "Val Loss: 2.287, Val Accuracy: 51.46%\n",
      "Completed validation after 12.26 seconds.\n",
      "Accuracy: 55.38%\n",
      "Completed testing after 58.98 seconds.\n",
      "Total epoch time: 352.42 seconds.\n",
      "Epoch [148/200]\n",
      "####################################################################################################\n",
      "Epoch 149 begin: 2025-05-14 02:16:48.939958.\n",
      "Batch 256, Loss: 0.485, Accuracy: 87.29%\n",
      "Batch 512, Loss: 0.477, Accuracy: 87.79%\n",
      "Batch 768, Loss: 0.479, Accuracy: 87.85%\n",
      "Batch 1024, Loss: 0.468, Accuracy: 88.38%\n",
      "Batch 1280, Loss: 0.461, Accuracy: 88.07%\n",
      "Completed training after 281.54 seconds.\n",
      "Val Loss: 2.279, Val Accuracy: 51.03%\n",
      "Completed validation after 12.23 seconds.\n",
      "Accuracy: 55.30%\n",
      "Completed testing after 59.00 seconds.\n",
      "Total epoch time: 352.77 seconds.\n",
      "Epoch [149/200]\n",
      "####################################################################################################\n",
      "Epoch 150 begin: 2025-05-14 02:22:41.709290.\n",
      "Batch 256, Loss: 0.483, Accuracy: 87.83%\n",
      "Batch 512, Loss: 0.475, Accuracy: 87.92%\n",
      "Batch 768, Loss: 0.468, Accuracy: 87.94%\n",
      "Batch 1024, Loss: 0.491, Accuracy: 87.98%\n",
      "Batch 1280, Loss: 0.468, Accuracy: 87.88%\n",
      "Completed training after 281.23 seconds.\n",
      "Val Loss: 2.290, Val Accuracy: 51.40%\n",
      "Completed validation after 12.22 seconds.\n",
      "Accuracy: 55.13%\n",
      "Completed testing after 59.00 seconds.\n",
      "Total epoch time: 352.44 seconds.\n",
      "Epoch [150/200]\n",
      "####################################################################################################\n",
      "Epoch 151 begin: 2025-05-14 02:28:34.153453.\n",
      "Batch 256, Loss: 0.483, Accuracy: 87.90%\n",
      "Batch 512, Loss: 0.474, Accuracy: 87.92%\n",
      "Batch 768, Loss: 0.486, Accuracy: 87.72%\n",
      "Batch 1024, Loss: 0.475, Accuracy: 88.00%\n",
      "Batch 1280, Loss: 0.487, Accuracy: 87.61%\n",
      "Completed training after 281.22 seconds.\n",
      "Val Loss: 2.268, Val Accuracy: 50.72%\n",
      "Completed validation after 12.27 seconds.\n",
      "Accuracy: 55.30%\n",
      "Completed testing after 58.96 seconds.\n",
      "Total epoch time: 352.45 seconds.\n",
      "Epoch [151/200]\n",
      "####################################################################################################\n",
      "Epoch 152 begin: 2025-05-14 02:34:26.604575.\n",
      "Batch 256, Loss: 0.472, Accuracy: 88.34%\n",
      "Batch 512, Loss: 0.486, Accuracy: 87.77%\n",
      "Batch 768, Loss: 0.479, Accuracy: 87.85%\n",
      "Batch 1024, Loss: 0.474, Accuracy: 87.68%\n",
      "Batch 1280, Loss: 0.466, Accuracy: 87.83%\n",
      "Completed training after 281.57 seconds.\n",
      "Val Loss: 2.286, Val Accuracy: 51.25%\n",
      "Completed validation after 12.25 seconds.\n",
      "Accuracy: 55.35%\n",
      "Completed testing after 58.92 seconds.\n",
      "Total epoch time: 352.74 seconds.\n",
      "Epoch [152/200]\n",
      "####################################################################################################\n",
      "Epoch 153 begin: 2025-05-14 02:40:19.340516.\n",
      "Batch 256, Loss: 0.460, Accuracy: 88.12%\n",
      "Batch 512, Loss: 0.486, Accuracy: 87.72%\n",
      "Batch 768, Loss: 0.474, Accuracy: 87.96%\n",
      "Batch 1024, Loss: 0.473, Accuracy: 88.23%\n",
      "Batch 1280, Loss: 0.478, Accuracy: 87.88%\n",
      "Completed training after 281.47 seconds.\n",
      "Val Loss: 2.280, Val Accuracy: 51.20%\n",
      "Completed validation after 12.23 seconds.\n",
      "Accuracy: 55.37%\n",
      "Completed testing after 58.89 seconds.\n",
      "Total epoch time: 352.59 seconds.\n",
      "Epoch [153/200]\n",
      "####################################################################################################\n",
      "Epoch 154 begin: 2025-05-14 02:46:11.926209.\n",
      "Batch 256, Loss: 0.482, Accuracy: 87.82%\n",
      "Batch 512, Loss: 0.479, Accuracy: 87.79%\n",
      "Batch 768, Loss: 0.483, Accuracy: 87.63%\n",
      "Batch 1024, Loss: 0.483, Accuracy: 87.45%\n",
      "Batch 1280, Loss: 0.472, Accuracy: 88.12%\n",
      "Completed training after 281.51 seconds.\n",
      "Val Loss: 2.209, Val Accuracy: 51.73%\n",
      "Completed validation after 12.23 seconds.\n",
      "Accuracy: 55.23%\n",
      "Completed testing after 58.92 seconds.\n",
      "Total epoch time: 352.66 seconds.\n",
      "Epoch [154/200]\n",
      "####################################################################################################\n",
      "Epoch 155 begin: 2025-05-14 02:52:04.584507.\n",
      "Batch 256, Loss: 0.492, Accuracy: 87.54%\n",
      "Batch 512, Loss: 0.486, Accuracy: 87.61%\n",
      "Batch 768, Loss: 0.479, Accuracy: 88.11%\n",
      "Batch 1024, Loss: 0.472, Accuracy: 87.72%\n",
      "Batch 1280, Loss: 0.452, Accuracy: 88.51%\n",
      "Completed training after 281.57 seconds.\n",
      "Val Loss: 2.287, Val Accuracy: 51.40%\n",
      "Completed validation after 12.24 seconds.\n",
      "Accuracy: 55.33%\n",
      "Completed testing after 59.01 seconds.\n",
      "Total epoch time: 352.81 seconds.\n",
      "Epoch [155/200]\n",
      "####################################################################################################\n",
      "Epoch 156 begin: 2025-05-14 02:57:57.396302.\n",
      "Batch 256, Loss: 0.484, Accuracy: 87.99%\n",
      "Batch 512, Loss: 0.460, Accuracy: 88.34%\n",
      "Batch 768, Loss: 0.488, Accuracy: 87.33%\n",
      "Batch 1024, Loss: 0.469, Accuracy: 87.82%\n",
      "Batch 1280, Loss: 0.454, Accuracy: 88.61%\n",
      "Completed training after 281.53 seconds.\n",
      "Val Loss: 2.256, Val Accuracy: 51.40%\n",
      "Completed validation after 12.22 seconds.\n",
      "Accuracy: 55.08%\n",
      "Completed testing after 58.98 seconds.\n",
      "Total epoch time: 352.73 seconds.\n",
      "Epoch [156/200]\n",
      "####################################################################################################\n",
      "Epoch 157 begin: 2025-05-14 03:03:50.125861.\n",
      "Batch 256, Loss: 0.460, Accuracy: 88.12%\n",
      "Batch 512, Loss: 0.479, Accuracy: 87.82%\n",
      "Batch 768, Loss: 0.479, Accuracy: 88.04%\n",
      "Batch 1024, Loss: 0.461, Accuracy: 87.95%\n",
      "Batch 1280, Loss: 0.481, Accuracy: 87.77%\n",
      "Completed training after 281.51 seconds.\n",
      "Val Loss: 2.249, Val Accuracy: 52.05%\n",
      "Completed validation after 12.25 seconds.\n",
      "Accuracy: 55.67%\n",
      "Completed testing after 58.92 seconds.\n",
      "Total epoch time: 352.69 seconds.\n",
      "Epoch [157/200]\n",
      "Check-point!\n",
      "####################################################################################################\n",
      "Epoch 158 begin: 2025-05-14 03:09:43.781635.\n",
      "Batch 256, Loss: 0.481, Accuracy: 87.66%\n",
      "Batch 512, Loss: 0.483, Accuracy: 87.68%\n",
      "Batch 768, Loss: 0.481, Accuracy: 88.00%\n",
      "Batch 1024, Loss: 0.484, Accuracy: 87.76%\n",
      "Batch 1280, Loss: 0.494, Accuracy: 87.76%\n",
      "Completed training after 281.55 seconds.\n",
      "Val Loss: 2.269, Val Accuracy: 50.94%\n",
      "Completed validation after 12.21 seconds.\n",
      "Accuracy: 55.10%\n",
      "Completed testing after 58.99 seconds.\n",
      "Total epoch time: 352.76 seconds.\n",
      "Epoch [158/200]\n",
      "####################################################################################################\n",
      "Epoch 159 begin: 2025-05-14 03:15:36.538090.\n",
      "Batch 256, Loss: 0.491, Accuracy: 87.46%\n",
      "Batch 512, Loss: 0.462, Accuracy: 88.28%\n",
      "Batch 768, Loss: 0.488, Accuracy: 87.45%\n",
      "Batch 1024, Loss: 0.472, Accuracy: 88.34%\n",
      "Batch 1280, Loss: 0.471, Accuracy: 88.39%\n",
      "Completed training after 281.16 seconds.\n",
      "Val Loss: 2.324, Val Accuracy: 50.70%\n",
      "Completed validation after 12.25 seconds.\n",
      "Accuracy: 55.24%\n",
      "Completed testing after 58.91 seconds.\n",
      "Total epoch time: 352.32 seconds.\n",
      "Epoch [159/200]\n",
      "####################################################################################################\n",
      "Epoch 160 begin: 2025-05-14 03:21:28.857846.\n",
      "Batch 256, Loss: 0.477, Accuracy: 87.70%\n",
      "Batch 512, Loss: 0.494, Accuracy: 87.46%\n",
      "Batch 768, Loss: 0.486, Accuracy: 87.84%\n",
      "Batch 1024, Loss: 0.491, Accuracy: 87.73%\n",
      "Batch 1280, Loss: 0.458, Accuracy: 88.79%\n",
      "Completed training after 281.18 seconds.\n",
      "Val Loss: 2.271, Val Accuracy: 51.20%\n",
      "Completed validation after 12.22 seconds.\n",
      "Accuracy: 55.53%\n",
      "Completed testing after 58.96 seconds.\n",
      "Total epoch time: 352.36 seconds.\n",
      "Epoch [160/200]\n",
      "####################################################################################################\n",
      "Epoch 161 begin: 2025-05-14 03:27:21.221937.\n",
      "Batch 256, Loss: 0.444, Accuracy: 88.68%\n",
      "Batch 512, Loss: 0.464, Accuracy: 87.99%\n",
      "Batch 768, Loss: 0.462, Accuracy: 88.39%\n",
      "Batch 1024, Loss: 0.464, Accuracy: 88.28%\n",
      "Batch 1280, Loss: 0.474, Accuracy: 88.09%\n",
      "Completed training after 281.48 seconds.\n",
      "Val Loss: 2.240, Val Accuracy: 50.92%\n",
      "Completed validation after 12.23 seconds.\n",
      "Accuracy: 55.33%\n",
      "Completed testing after 58.93 seconds.\n",
      "Total epoch time: 352.63 seconds.\n",
      "Epoch [161/200]\n",
      "####################################################################################################\n",
      "Epoch 162 begin: 2025-05-14 03:33:13.854100.\n",
      "Batch 256, Loss: 0.483, Accuracy: 87.67%\n",
      "Batch 512, Loss: 0.449, Accuracy: 88.56%\n",
      "Batch 768, Loss: 0.457, Accuracy: 88.20%\n",
      "Batch 1024, Loss: 0.479, Accuracy: 87.73%\n",
      "Batch 1280, Loss: 0.496, Accuracy: 87.04%\n",
      "Completed training after 281.40 seconds.\n",
      "Val Loss: 2.290, Val Accuracy: 51.07%\n",
      "Completed validation after 12.22 seconds.\n",
      "Accuracy: 55.15%\n",
      "Completed testing after 59.00 seconds.\n",
      "Total epoch time: 352.62 seconds.\n",
      "Epoch [162/200]\n",
      "####################################################################################################\n",
      "Epoch 163 begin: 2025-05-14 03:39:06.478615.\n",
      "Batch 256, Loss: 0.465, Accuracy: 88.11%\n",
      "Batch 512, Loss: 0.463, Accuracy: 88.18%\n",
      "Batch 768, Loss: 0.461, Accuracy: 88.10%\n",
      "Batch 1024, Loss: 0.500, Accuracy: 87.52%\n",
      "Batch 1280, Loss: 0.477, Accuracy: 87.72%\n",
      "Completed training after 281.53 seconds.\n",
      "Val Loss: 2.269, Val Accuracy: 51.70%\n",
      "Completed validation after 12.22 seconds.\n",
      "Accuracy: 55.18%\n",
      "Completed testing after 59.01 seconds.\n",
      "Total epoch time: 352.76 seconds.\n",
      "Epoch [163/200]\n",
      "####################################################################################################\n",
      "Epoch 164 begin: 2025-05-14 03:44:59.238584.\n",
      "Batch 256, Loss: 0.481, Accuracy: 88.28%\n",
      "Batch 512, Loss: 0.472, Accuracy: 87.98%\n",
      "Batch 768, Loss: 0.492, Accuracy: 87.35%\n",
      "Batch 1024, Loss: 0.450, Accuracy: 89.00%\n",
      "Batch 1280, Loss: 0.492, Accuracy: 87.30%\n",
      "Completed training after 281.51 seconds.\n",
      "Val Loss: 2.263, Val Accuracy: 51.31%\n",
      "Completed validation after 12.21 seconds.\n",
      "Accuracy: 55.35%\n",
      "Completed testing after 58.92 seconds.\n",
      "Total epoch time: 352.64 seconds.\n",
      "Epoch [164/200]\n",
      "####################################################################################################\n",
      "Epoch 165 begin: 2025-05-14 03:50:51.880625.\n",
      "Batch 256, Loss: 0.477, Accuracy: 88.09%\n",
      "Batch 512, Loss: 0.498, Accuracy: 87.38%\n",
      "Batch 768, Loss: 0.462, Accuracy: 88.09%\n",
      "Batch 1024, Loss: 0.510, Accuracy: 87.15%\n",
      "Batch 1280, Loss: 0.450, Accuracy: 88.42%\n",
      "Completed training after 281.49 seconds.\n",
      "Val Loss: 2.268, Val Accuracy: 51.35%\n",
      "Completed validation after 12.24 seconds.\n",
      "Accuracy: 55.45%\n",
      "Completed testing after 58.88 seconds.\n",
      "Total epoch time: 352.61 seconds.\n",
      "Epoch [165/200]\n",
      "####################################################################################################\n",
      "Epoch 166 begin: 2025-05-14 03:56:44.491907.\n",
      "Batch 256, Loss: 0.495, Accuracy: 87.56%\n",
      "Batch 512, Loss: 0.481, Accuracy: 87.72%\n",
      "Batch 768, Loss: 0.461, Accuracy: 88.39%\n",
      "Batch 1024, Loss: 0.464, Accuracy: 88.42%\n",
      "Batch 1280, Loss: 0.463, Accuracy: 88.10%\n",
      "Completed training after 281.55 seconds.\n",
      "Val Loss: 2.278, Val Accuracy: 51.42%\n",
      "Completed validation after 12.24 seconds.\n",
      "Accuracy: 55.50%\n",
      "Completed testing after 59.00 seconds.\n",
      "Total epoch time: 352.78 seconds.\n",
      "Epoch [166/200]\n",
      "####################################################################################################\n",
      "Epoch 167 begin: 2025-05-14 04:02:37.276232.\n",
      "Batch 256, Loss: 0.472, Accuracy: 88.02%\n",
      "Batch 512, Loss: 0.480, Accuracy: 87.79%\n",
      "Batch 768, Loss: 0.457, Accuracy: 88.70%\n",
      "Batch 1024, Loss: 0.478, Accuracy: 87.74%\n",
      "Batch 1280, Loss: 0.477, Accuracy: 88.17%\n",
      "Completed training after 281.17 seconds.\n",
      "Val Loss: 2.264, Val Accuracy: 51.92%\n",
      "Completed validation after 12.23 seconds.\n",
      "Accuracy: 55.38%\n",
      "Completed testing after 58.96 seconds.\n",
      "Total epoch time: 352.37 seconds.\n",
      "Epoch [167/200]\n",
      "####################################################################################################\n",
      "Epoch 168 begin: 2025-05-14 04:08:29.645225.\n",
      "Batch 256, Loss: 0.468, Accuracy: 88.31%\n",
      "Batch 512, Loss: 0.480, Accuracy: 87.62%\n",
      "Batch 768, Loss: 0.458, Accuracy: 88.34%\n",
      "Batch 1024, Loss: 0.481, Accuracy: 87.81%\n",
      "Batch 1280, Loss: 0.477, Accuracy: 88.02%\n",
      "Completed training after 281.50 seconds.\n",
      "Val Loss: 2.279, Val Accuracy: 51.33%\n",
      "Completed validation after 12.23 seconds.\n",
      "Accuracy: 55.13%\n",
      "Completed testing after 59.01 seconds.\n",
      "Total epoch time: 352.75 seconds.\n",
      "Epoch [168/200]\n",
      "####################################################################################################\n",
      "Epoch 169 begin: 2025-05-14 04:14:22.391343.\n",
      "Batch 256, Loss: 0.453, Accuracy: 88.45%\n",
      "Batch 512, Loss: 0.492, Accuracy: 87.57%\n",
      "Batch 768, Loss: 0.473, Accuracy: 87.59%\n",
      "Batch 1024, Loss: 0.478, Accuracy: 87.90%\n",
      "Batch 1280, Loss: 0.464, Accuracy: 88.22%\n",
      "Completed training after 281.14 seconds.\n",
      "Val Loss: 2.307, Val Accuracy: 50.70%\n",
      "Completed validation after 12.22 seconds.\n",
      "Accuracy: 55.26%\n",
      "Completed testing after 58.89 seconds.\n",
      "Total epoch time: 352.26 seconds.\n",
      "Epoch [169/200]\n",
      "####################################################################################################\n",
      "Epoch 170 begin: 2025-05-14 04:20:14.652433.\n",
      "Batch 256, Loss: 0.469, Accuracy: 88.44%\n",
      "Batch 512, Loss: 0.466, Accuracy: 88.35%\n",
      "Batch 768, Loss: 0.478, Accuracy: 87.85%\n",
      "Batch 1024, Loss: 0.499, Accuracy: 87.15%\n",
      "Batch 1280, Loss: 0.498, Accuracy: 87.63%\n",
      "Completed training after 281.23 seconds.\n",
      "Val Loss: 2.233, Val Accuracy: 51.86%\n",
      "Completed validation after 12.25 seconds.\n",
      "Accuracy: 55.38%\n",
      "Completed testing after 59.00 seconds.\n",
      "Total epoch time: 352.48 seconds.\n",
      "Epoch [170/200]\n",
      "####################################################################################################\n",
      "Epoch 171 begin: 2025-05-14 04:26:07.129993.\n",
      "Batch 256, Loss: 0.456, Accuracy: 88.24%\n",
      "Batch 512, Loss: 0.487, Accuracy: 88.00%\n",
      "Batch 768, Loss: 0.481, Accuracy: 87.62%\n",
      "Batch 1024, Loss: 0.448, Accuracy: 88.79%\n",
      "Batch 1280, Loss: 0.439, Accuracy: 89.04%\n",
      "Completed training after 281.55 seconds.\n",
      "Val Loss: 2.249, Val Accuracy: 51.86%\n",
      "Completed validation after 12.22 seconds.\n",
      "Accuracy: 55.45%\n",
      "Completed testing after 58.89 seconds.\n",
      "Total epoch time: 352.66 seconds.\n",
      "Epoch [171/200]\n",
      "####################################################################################################\n",
      "Epoch 172 begin: 2025-05-14 04:31:59.786174.\n",
      "Batch 256, Loss: 0.470, Accuracy: 88.23%\n",
      "Batch 512, Loss: 0.478, Accuracy: 88.04%\n",
      "Batch 768, Loss: 0.477, Accuracy: 88.13%\n",
      "Batch 1024, Loss: 0.468, Accuracy: 88.32%\n",
      "Batch 1280, Loss: 0.487, Accuracy: 87.76%\n",
      "Completed training after 281.19 seconds.\n",
      "Val Loss: 2.258, Val Accuracy: 51.25%\n",
      "Completed validation after 12.25 seconds.\n",
      "Accuracy: 55.38%\n",
      "Completed testing after 59.00 seconds.\n",
      "Total epoch time: 352.44 seconds.\n",
      "Epoch [172/200]\n",
      "####################################################################################################\n",
      "Epoch 173 begin: 2025-05-14 04:37:52.228036.\n",
      "Batch 256, Loss: 0.477, Accuracy: 88.17%\n",
      "Batch 512, Loss: 0.465, Accuracy: 88.11%\n",
      "Batch 768, Loss: 0.450, Accuracy: 88.60%\n",
      "Batch 1024, Loss: 0.457, Accuracy: 88.35%\n",
      "Batch 1280, Loss: 0.461, Accuracy: 88.59%\n",
      "Completed training after 281.48 seconds.\n",
      "Val Loss: 2.296, Val Accuracy: 50.85%\n",
      "Completed validation after 12.25 seconds.\n",
      "Accuracy: 55.03%\n",
      "Completed testing after 58.93 seconds.\n",
      "Total epoch time: 352.66 seconds.\n",
      "Epoch [173/200]\n",
      "####################################################################################################\n",
      "Epoch 174 begin: 2025-05-14 04:43:44.892528.\n",
      "Batch 256, Loss: 0.484, Accuracy: 87.55%\n",
      "Batch 512, Loss: 0.464, Accuracy: 88.15%\n",
      "Batch 768, Loss: 0.478, Accuracy: 88.10%\n",
      "Batch 1024, Loss: 0.462, Accuracy: 88.56%\n",
      "Batch 1280, Loss: 0.494, Accuracy: 87.57%\n",
      "Completed training after 281.20 seconds.\n",
      "Val Loss: 2.241, Val Accuracy: 51.18%\n",
      "Completed validation after 12.29 seconds.\n",
      "Accuracy: 55.36%\n",
      "Completed testing after 58.94 seconds.\n",
      "Total epoch time: 352.43 seconds.\n",
      "Epoch [174/200]\n",
      "####################################################################################################\n",
      "Epoch 175 begin: 2025-05-14 04:49:37.325896.\n",
      "Batch 256, Loss: 0.469, Accuracy: 87.98%\n",
      "Batch 512, Loss: 0.485, Accuracy: 87.52%\n",
      "Batch 768, Loss: 0.504, Accuracy: 87.15%\n",
      "Batch 1024, Loss: 0.467, Accuracy: 88.06%\n",
      "Batch 1280, Loss: 0.481, Accuracy: 87.98%\n",
      "Completed training after 281.49 seconds.\n",
      "Val Loss: 2.278, Val Accuracy: 50.96%\n",
      "Completed validation after 12.27 seconds.\n",
      "Accuracy: 55.19%\n",
      "Completed testing after 59.00 seconds.\n",
      "Total epoch time: 352.75 seconds.\n",
      "Epoch [175/200]\n",
      "####################################################################################################\n",
      "Epoch 176 begin: 2025-05-14 04:55:30.078473.\n",
      "Batch 256, Loss: 0.481, Accuracy: 87.66%\n",
      "Batch 512, Loss: 0.466, Accuracy: 88.29%\n",
      "Batch 768, Loss: 0.470, Accuracy: 88.12%\n",
      "Batch 1024, Loss: 0.480, Accuracy: 87.82%\n",
      "Batch 1280, Loss: 0.473, Accuracy: 88.11%\n",
      "Completed training after 281.51 seconds.\n",
      "Val Loss: 2.255, Val Accuracy: 51.40%\n",
      "Completed validation after 12.26 seconds.\n",
      "Accuracy: 55.10%\n",
      "Completed testing after 58.89 seconds.\n",
      "Total epoch time: 352.66 seconds.\n",
      "Epoch [176/200]\n",
      "####################################################################################################\n",
      "Epoch 177 begin: 2025-05-14 05:01:22.740544.\n",
      "Batch 256, Loss: 0.458, Accuracy: 88.62%\n",
      "Batch 512, Loss: 0.482, Accuracy: 87.55%\n",
      "Batch 768, Loss: 0.481, Accuracy: 87.71%\n",
      "Batch 1024, Loss: 0.476, Accuracy: 88.02%\n",
      "Batch 1280, Loss: 0.461, Accuracy: 88.23%\n",
      "Completed training after 281.50 seconds.\n",
      "Val Loss: 2.266, Val Accuracy: 51.49%\n",
      "Completed validation after 12.24 seconds.\n",
      "Accuracy: 55.43%\n",
      "Completed testing after 59.00 seconds.\n",
      "Total epoch time: 352.73 seconds.\n",
      "Epoch [177/200]\n",
      "####################################################################################################\n",
      "Epoch 178 begin: 2025-05-14 05:07:15.473259.\n",
      "Batch 256, Loss: 0.465, Accuracy: 88.40%\n",
      "Batch 512, Loss: 0.476, Accuracy: 87.96%\n",
      "Batch 768, Loss: 0.471, Accuracy: 88.00%\n",
      "Batch 1024, Loss: 0.468, Accuracy: 88.15%\n",
      "Batch 1280, Loss: 0.498, Accuracy: 87.62%\n",
      "Completed training after 281.13 seconds.\n",
      "Val Loss: 2.273, Val Accuracy: 51.09%\n",
      "Completed validation after 12.25 seconds.\n",
      "Accuracy: 55.26%\n",
      "Completed testing after 58.82 seconds.\n",
      "Total epoch time: 352.20 seconds.\n",
      "Epoch [178/200]\n",
      "####################################################################################################\n",
      "Epoch 179 begin: 2025-05-14 05:13:07.669203.\n",
      "Batch 256, Loss: 0.467, Accuracy: 88.24%\n",
      "Batch 512, Loss: 0.476, Accuracy: 88.15%\n",
      "Batch 768, Loss: 0.483, Accuracy: 87.88%\n",
      "Batch 1024, Loss: 0.469, Accuracy: 87.84%\n",
      "Batch 1280, Loss: 0.489, Accuracy: 87.45%\n",
      "Completed training after 281.21 seconds.\n",
      "Val Loss: 2.305, Val Accuracy: 51.03%\n",
      "Completed validation after 12.23 seconds.\n",
      "Accuracy: 55.01%\n",
      "Completed testing after 58.91 seconds.\n",
      "Total epoch time: 352.36 seconds.\n",
      "Epoch [179/200]\n",
      "####################################################################################################\n",
      "Epoch 180 begin: 2025-05-14 05:19:00.024426.\n",
      "Batch 256, Loss: 0.456, Accuracy: 88.62%\n",
      "Batch 512, Loss: 0.468, Accuracy: 88.16%\n",
      "Batch 768, Loss: 0.463, Accuracy: 88.32%\n",
      "Batch 1024, Loss: 0.480, Accuracy: 87.62%\n",
      "Batch 1280, Loss: 0.471, Accuracy: 88.11%\n",
      "Completed training after 281.16 seconds.\n",
      "Val Loss: 2.266, Val Accuracy: 51.70%\n",
      "Completed validation after 12.24 seconds.\n",
      "Accuracy: 55.26%\n",
      "Completed testing after 58.85 seconds.\n",
      "Total epoch time: 352.25 seconds.\n",
      "Epoch [180/200]\n",
      "####################################################################################################\n",
      "Epoch 181 begin: 2025-05-14 05:24:52.271771.\n",
      "Batch 256, Loss: 0.487, Accuracy: 88.05%\n",
      "Batch 512, Loss: 0.485, Accuracy: 87.62%\n",
      "Batch 768, Loss: 0.488, Accuracy: 87.63%\n",
      "Batch 1024, Loss: 0.476, Accuracy: 87.84%\n",
      "Batch 1280, Loss: 0.489, Accuracy: 87.22%\n",
      "Completed training after 281.15 seconds.\n",
      "Val Loss: 2.242, Val Accuracy: 51.97%\n",
      "Completed validation after 12.25 seconds.\n",
      "Accuracy: 55.34%\n",
      "Completed testing after 58.90 seconds.\n",
      "Total epoch time: 352.30 seconds.\n",
      "Epoch [181/200]\n",
      "####################################################################################################\n",
      "Epoch 182 begin: 2025-05-14 05:30:44.576365.\n",
      "Batch 256, Loss: 0.483, Accuracy: 87.79%\n",
      "Batch 512, Loss: 0.468, Accuracy: 87.90%\n",
      "Batch 768, Loss: 0.479, Accuracy: 87.63%\n",
      "Batch 1024, Loss: 0.473, Accuracy: 87.84%\n",
      "Batch 1280, Loss: 0.471, Accuracy: 87.74%\n",
      "Completed training after 281.23 seconds.\n",
      "Val Loss: 2.284, Val Accuracy: 51.29%\n",
      "Completed validation after 12.21 seconds.\n",
      "Accuracy: 55.45%\n",
      "Completed testing after 58.93 seconds.\n",
      "Total epoch time: 352.37 seconds.\n",
      "Epoch [182/200]\n",
      "####################################################################################################\n",
      "Epoch 183 begin: 2025-05-14 05:36:36.944012.\n",
      "Batch 256, Loss: 0.464, Accuracy: 88.33%\n",
      "Batch 512, Loss: 0.461, Accuracy: 88.26%\n",
      "Batch 768, Loss: 0.473, Accuracy: 88.00%\n",
      "Batch 1024, Loss: 0.468, Accuracy: 87.88%\n",
      "Batch 1280, Loss: 0.491, Accuracy: 87.44%\n",
      "Completed training after 281.21 seconds.\n",
      "Val Loss: 2.254, Val Accuracy: 51.55%\n",
      "Completed validation after 12.21 seconds.\n",
      "Accuracy: 55.54%\n",
      "Completed testing after 58.92 seconds.\n",
      "Total epoch time: 352.34 seconds.\n",
      "Epoch [183/200]\n",
      "####################################################################################################\n",
      "Epoch 184 begin: 2025-05-14 05:42:29.288000.\n",
      "Batch 256, Loss: 0.474, Accuracy: 87.88%\n",
      "Batch 512, Loss: 0.459, Accuracy: 88.35%\n",
      "Batch 768, Loss: 0.473, Accuracy: 88.18%\n",
      "Batch 1024, Loss: 0.473, Accuracy: 87.92%\n",
      "Batch 1280, Loss: 0.470, Accuracy: 87.96%\n",
      "Completed training after 281.20 seconds.\n",
      "Val Loss: 2.289, Val Accuracy: 51.46%\n",
      "Completed validation after 12.22 seconds.\n",
      "Accuracy: 55.51%\n",
      "Completed testing after 58.94 seconds.\n",
      "Total epoch time: 352.37 seconds.\n",
      "Epoch [184/200]\n",
      "####################################################################################################\n",
      "Epoch 185 begin: 2025-05-14 05:48:21.655008.\n",
      "Batch 256, Loss: 0.468, Accuracy: 88.10%\n",
      "Batch 512, Loss: 0.483, Accuracy: 88.00%\n",
      "Batch 768, Loss: 0.461, Accuracy: 88.65%\n",
      "Batch 1024, Loss: 0.479, Accuracy: 88.06%\n",
      "Batch 1280, Loss: 0.486, Accuracy: 87.52%\n",
      "Completed training after 281.18 seconds.\n",
      "Val Loss: 2.251, Val Accuracy: 51.29%\n",
      "Completed validation after 12.24 seconds.\n",
      "Accuracy: 55.25%\n",
      "Completed testing after 58.92 seconds.\n",
      "Total epoch time: 352.33 seconds.\n",
      "Epoch [185/200]\n",
      "####################################################################################################\n",
      "Epoch 186 begin: 2025-05-14 05:54:13.989534.\n",
      "Batch 256, Loss: 0.473, Accuracy: 87.89%\n",
      "Batch 512, Loss: 0.481, Accuracy: 87.96%\n",
      "Batch 768, Loss: 0.475, Accuracy: 87.90%\n",
      "Batch 1024, Loss: 0.483, Accuracy: 87.68%\n",
      "Batch 1280, Loss: 0.483, Accuracy: 87.67%\n",
      "Completed training after 281.21 seconds.\n",
      "Val Loss: 2.237, Val Accuracy: 51.55%\n",
      "Completed validation after 12.22 seconds.\n",
      "Accuracy: 55.38%\n",
      "Completed testing after 58.96 seconds.\n",
      "Total epoch time: 352.39 seconds.\n",
      "Epoch [186/200]\n",
      "####################################################################################################\n",
      "Epoch 187 begin: 2025-05-14 06:00:06.379331.\n",
      "Batch 256, Loss: 0.474, Accuracy: 87.92%\n",
      "Batch 512, Loss: 0.477, Accuracy: 88.00%\n",
      "Batch 768, Loss: 0.455, Accuracy: 88.59%\n",
      "Batch 1024, Loss: 0.474, Accuracy: 88.37%\n",
      "Batch 1280, Loss: 0.505, Accuracy: 87.62%\n",
      "Completed training after 281.21 seconds.\n",
      "Val Loss: 2.254, Val Accuracy: 51.35%\n",
      "Completed validation after 12.22 seconds.\n",
      "Accuracy: 55.48%\n",
      "Completed testing after 58.93 seconds.\n",
      "Total epoch time: 352.36 seconds.\n",
      "Epoch [187/200]\n",
      "####################################################################################################\n",
      "Epoch 188 begin: 2025-05-14 06:05:58.741671.\n",
      "Batch 256, Loss: 0.491, Accuracy: 87.76%\n",
      "Batch 512, Loss: 0.473, Accuracy: 88.02%\n",
      "Batch 768, Loss: 0.463, Accuracy: 88.26%\n",
      "Batch 1024, Loss: 0.464, Accuracy: 88.66%\n",
      "Batch 1280, Loss: 0.483, Accuracy: 88.02%\n",
      "Completed training after 281.18 seconds.\n",
      "Val Loss: 2.248, Val Accuracy: 51.88%\n",
      "Completed validation after 12.23 seconds.\n",
      "Accuracy: 55.52%\n",
      "Completed testing after 58.92 seconds.\n",
      "Total epoch time: 352.33 seconds.\n",
      "Epoch [188/200]\n",
      "####################################################################################################\n",
      "Epoch 189 begin: 2025-05-14 06:11:51.072532.\n",
      "Batch 256, Loss: 0.463, Accuracy: 88.13%\n",
      "Batch 512, Loss: 0.471, Accuracy: 88.01%\n",
      "Batch 768, Loss: 0.465, Accuracy: 88.15%\n",
      "Batch 1024, Loss: 0.481, Accuracy: 87.87%\n",
      "Batch 1280, Loss: 0.472, Accuracy: 87.94%\n",
      "Completed training after 281.15 seconds.\n",
      "Val Loss: 2.263, Val Accuracy: 51.51%\n",
      "Completed validation after 12.24 seconds.\n",
      "Accuracy: 55.34%\n",
      "Completed testing after 58.87 seconds.\n",
      "Total epoch time: 352.26 seconds.\n",
      "Epoch [189/200]\n",
      "####################################################################################################\n",
      "Epoch 190 begin: 2025-05-14 06:17:43.330032.\n",
      "Batch 256, Loss: 0.482, Accuracy: 87.78%\n",
      "Batch 512, Loss: 0.476, Accuracy: 88.00%\n",
      "Batch 768, Loss: 0.474, Accuracy: 88.07%\n",
      "Batch 1024, Loss: 0.480, Accuracy: 87.92%\n",
      "Batch 1280, Loss: 0.467, Accuracy: 88.29%\n",
      "Completed training after 281.19 seconds.\n",
      "Val Loss: 2.258, Val Accuracy: 51.16%\n",
      "Completed validation after 12.23 seconds.\n",
      "Accuracy: 55.55%\n",
      "Completed testing after 59.00 seconds.\n",
      "Total epoch time: 352.41 seconds.\n",
      "Epoch [190/200]\n",
      "####################################################################################################\n",
      "Epoch 191 begin: 2025-05-14 06:23:35.744634.\n",
      "Batch 256, Loss: 0.463, Accuracy: 88.21%\n",
      "Batch 512, Loss: 0.485, Accuracy: 87.57%\n",
      "Batch 768, Loss: 0.453, Accuracy: 88.33%\n",
      "Batch 1024, Loss: 0.470, Accuracy: 88.17%\n",
      "Batch 1280, Loss: 0.477, Accuracy: 87.78%\n",
      "Completed training after 281.18 seconds.\n",
      "Val Loss: 2.231, Val Accuracy: 52.03%\n",
      "Completed validation after 12.21 seconds.\n",
      "Accuracy: 55.34%\n",
      "Completed testing after 58.87 seconds.\n",
      "Total epoch time: 352.25 seconds.\n",
      "Epoch [191/200]\n",
      "####################################################################################################\n",
      "Epoch 192 begin: 2025-05-14 06:29:27.996184.\n",
      "Batch 256, Loss: 0.476, Accuracy: 88.05%\n",
      "Batch 512, Loss: 0.462, Accuracy: 88.46%\n",
      "Batch 768, Loss: 0.468, Accuracy: 88.06%\n",
      "Batch 1024, Loss: 0.485, Accuracy: 87.56%\n",
      "Batch 1280, Loss: 0.486, Accuracy: 88.16%\n",
      "Completed training after 281.54 seconds.\n",
      "Val Loss: 2.268, Val Accuracy: 51.55%\n",
      "Completed validation after 12.25 seconds.\n",
      "Accuracy: 55.31%\n",
      "Completed testing after 58.95 seconds.\n",
      "Total epoch time: 352.74 seconds.\n",
      "Epoch [192/200]\n",
      "####################################################################################################\n",
      "Epoch 193 begin: 2025-05-14 06:35:20.734629.\n",
      "Batch 256, Loss: 0.466, Accuracy: 88.53%\n",
      "Batch 512, Loss: 0.483, Accuracy: 87.78%\n",
      "Batch 768, Loss: 0.470, Accuracy: 87.96%\n",
      "Batch 1024, Loss: 0.479, Accuracy: 87.78%\n",
      "Batch 1280, Loss: 0.466, Accuracy: 88.34%\n",
      "Completed training after 281.19 seconds.\n",
      "Val Loss: 2.261, Val Accuracy: 51.81%\n",
      "Completed validation after 12.25 seconds.\n",
      "Accuracy: 55.25%\n",
      "Completed testing after 58.87 seconds.\n",
      "Total epoch time: 352.31 seconds.\n",
      "Epoch [193/200]\n",
      "####################################################################################################\n",
      "Epoch 194 begin: 2025-05-14 06:41:13.042170.\n",
      "Batch 256, Loss: 0.487, Accuracy: 87.65%\n",
      "Batch 512, Loss: 0.464, Accuracy: 88.00%\n",
      "Batch 768, Loss: 0.474, Accuracy: 87.77%\n",
      "Batch 1024, Loss: 0.486, Accuracy: 87.72%\n",
      "Batch 1280, Loss: 0.478, Accuracy: 88.00%\n",
      "Completed training after 281.45 seconds.\n",
      "Val Loss: 2.262, Val Accuracy: 51.49%\n",
      "Completed validation after 12.21 seconds.\n",
      "Accuracy: 55.64%\n",
      "Completed testing after 58.89 seconds.\n",
      "Total epoch time: 352.56 seconds.\n",
      "Epoch [194/200]\n",
      "####################################################################################################\n",
      "Epoch 195 begin: 2025-05-14 06:47:05.601271.\n",
      "Batch 256, Loss: 0.468, Accuracy: 88.48%\n",
      "Batch 512, Loss: 0.488, Accuracy: 87.51%\n",
      "Batch 768, Loss: 0.482, Accuracy: 87.90%\n",
      "Batch 1024, Loss: 0.489, Accuracy: 87.81%\n",
      "Batch 1280, Loss: 0.453, Accuracy: 88.53%\n",
      "Completed training after 281.26 seconds.\n",
      "Val Loss: 2.269, Val Accuracy: 50.98%\n",
      "Completed validation after 12.20 seconds.\n",
      "Accuracy: 55.14%\n",
      "Completed testing after 58.92 seconds.\n",
      "Total epoch time: 352.38 seconds.\n",
      "Epoch [195/200]\n",
      "####################################################################################################\n",
      "Epoch 196 begin: 2025-05-14 06:52:57.977379.\n",
      "Batch 256, Loss: 0.470, Accuracy: 88.28%\n",
      "Batch 512, Loss: 0.487, Accuracy: 87.89%\n",
      "Batch 768, Loss: 0.448, Accuracy: 88.66%\n",
      "Batch 1024, Loss: 0.474, Accuracy: 88.27%\n",
      "Batch 1280, Loss: 0.464, Accuracy: 88.29%\n",
      "Completed training after 281.15 seconds.\n",
      "Val Loss: 2.277, Val Accuracy: 51.09%\n",
      "Completed validation after 12.21 seconds.\n",
      "Accuracy: 55.50%\n",
      "Completed testing after 58.95 seconds.\n",
      "Total epoch time: 352.31 seconds.\n",
      "Epoch [196/200]\n",
      "####################################################################################################\n",
      "Epoch 197 begin: 2025-05-14 06:58:50.291293.\n",
      "Batch 256, Loss: 0.456, Accuracy: 88.39%\n",
      "Batch 512, Loss: 0.476, Accuracy: 88.24%\n",
      "Batch 768, Loss: 0.483, Accuracy: 87.89%\n",
      "Batch 1024, Loss: 0.470, Accuracy: 87.93%\n",
      "Batch 1280, Loss: 0.490, Accuracy: 87.85%\n",
      "Completed training after 281.20 seconds.\n",
      "Val Loss: 2.236, Val Accuracy: 51.07%\n",
      "Completed validation after 12.22 seconds.\n",
      "Accuracy: 55.37%\n",
      "Completed testing after 58.95 seconds.\n",
      "Total epoch time: 352.37 seconds.\n",
      "Epoch [197/200]\n",
      "####################################################################################################\n",
      "Epoch 198 begin: 2025-05-14 07:04:42.659058.\n",
      "Batch 256, Loss: 0.468, Accuracy: 88.07%\n",
      "Batch 512, Loss: 0.475, Accuracy: 88.16%\n",
      "Batch 768, Loss: 0.452, Accuracy: 88.39%\n",
      "Batch 1024, Loss: 0.483, Accuracy: 87.83%\n",
      "Batch 1280, Loss: 0.469, Accuracy: 88.13%\n",
      "Completed training after 281.22 seconds.\n",
      "Val Loss: 2.294, Val Accuracy: 51.64%\n",
      "Completed validation after 12.20 seconds.\n",
      "Accuracy: 55.37%\n",
      "Completed testing after 58.86 seconds.\n",
      "Total epoch time: 352.28 seconds.\n",
      "Epoch [198/200]\n",
      "####################################################################################################\n",
      "Epoch 199 begin: 2025-05-14 07:10:34.943647.\n",
      "Batch 256, Loss: 0.466, Accuracy: 88.15%\n",
      "Batch 512, Loss: 0.471, Accuracy: 87.65%\n",
      "Batch 768, Loss: 0.476, Accuracy: 87.67%\n",
      "Batch 1024, Loss: 0.457, Accuracy: 88.23%\n",
      "Batch 1280, Loss: 0.468, Accuracy: 87.98%\n",
      "Completed training after 281.15 seconds.\n",
      "Val Loss: 2.230, Val Accuracy: 51.35%\n",
      "Completed validation after 12.21 seconds.\n",
      "Accuracy: 55.36%\n",
      "Completed testing after 58.98 seconds.\n",
      "Total epoch time: 352.35 seconds.\n",
      "Epoch [199/200]\n",
      "####################################################################################################\n",
      "Epoch 200 begin: 2025-05-14 07:16:27.291901.\n",
      "Batch 256, Loss: 0.472, Accuracy: 88.28%\n",
      "Batch 512, Loss: 0.467, Accuracy: 87.95%\n",
      "Batch 768, Loss: 0.462, Accuracy: 88.45%\n",
      "Batch 1024, Loss: 0.479, Accuracy: 88.16%\n",
      "Batch 1280, Loss: 0.467, Accuracy: 88.06%\n",
      "Completed training after 281.47 seconds.\n",
      "Val Loss: 2.273, Val Accuracy: 51.73%\n",
      "Completed validation after 12.23 seconds.\n",
      "Accuracy: 55.26%\n",
      "Completed testing after 58.93 seconds.\n",
      "Total epoch time: 352.63 seconds.\n",
      "Epoch [200/200]\n",
      "####################################################################################################\n"
     ]
    }
   ],
   "source": [
    "### FURTHER TRAINING ###\n",
    "epoch, regret, grudge, pride = run_epochs(num_epochs, model, optimizer, loss_fn, scheduler, epoch, regret, grudge, pride, updates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a90ea130",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 begin: 2025-05-12 13:20:32.985275.\n",
      "Batch 500, Loss: 4.511, Accuracy: 0.97%\n",
      "Batch 1000, Loss: 4.511, Accuracy: 1.46%\n",
      "Batch 1500, Loss: 4.511, Accuracy: 1.35%\n",
      "Batch 2000, Loss: 4.511, Accuracy: 1.38%\n",
      "Batch 2500, Loss: 4.511, Accuracy: 1.62%\n",
      "Completed training after 31.92 seconds.\n",
      "Val Loss: 4.511, Val Accuracy: 2.32%\n",
      "Completed validation after 2.02 seconds.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 25\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCompleted validation after \u001b[39m\u001b[38;5;132;01m{:.2f}\u001b[39;00m\u001b[38;5;124m seconds.\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat((time() \u001b[38;5;241m-\u001b[39m check_point)))\n\u001b[1;32m     23\u001b[0m check_point \u001b[38;5;241m=\u001b[39m time()\n\u001b[0;32m---> 25\u001b[0m \u001b[43maccuracy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCompleted testing after \u001b[39m\u001b[38;5;132;01m{:.2f}\u001b[39;00m\u001b[38;5;124m seconds.\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat((time() \u001b[38;5;241m-\u001b[39m check_point)))\n\u001b[1;32m     27\u001b[0m scheduler\u001b[38;5;241m.\u001b[39mstep(val_loss)\n",
      "Cell \u001b[0;32mIn[10], line 69\u001b[0m, in \u001b[0;36maccuracy\u001b[0;34m(model, dataloader)\u001b[0m\n\u001b[1;32m     66\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m     68\u001b[0m running_accuracy \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m---> 69\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28miter\u001b[39m(dataloader):\n\u001b[1;32m     70\u001b[0m     images, labels \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device), data[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n",
      "File \u001b[0;32m~/Desktop/Neural Computing/Py1/lib/python3.10/site-packages/torch/utils/data/dataloader.py:733\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    730\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    731\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    732\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 733\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    734\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    735\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    736\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[1;32m    737\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    738\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[1;32m    739\u001b[0m ):\n",
      "File \u001b[0;32m~/Desktop/Neural Computing/Py1/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1491\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1488\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data, worker_id)\n\u001b[1;32m   1490\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m-> 1491\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1492\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1493\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[1;32m   1494\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/Neural Computing/Py1/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1453\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1449\u001b[0m     \u001b[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[1;32m   1450\u001b[0m     \u001b[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[1;32m   1451\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1452\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m-> 1453\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1454\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[1;32m   1455\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/Desktop/Neural Computing/Py1/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1284\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1271\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_try_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m_utils\u001b[38;5;241m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[1;32m   1272\u001b[0m     \u001b[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[1;32m   1273\u001b[0m     \u001b[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1281\u001b[0m     \u001b[38;5;66;03m# Returns a 2-tuple:\u001b[39;00m\n\u001b[1;32m   1282\u001b[0m     \u001b[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[1;32m   1283\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1284\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1285\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n\u001b[1;32m   1286\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1287\u001b[0m         \u001b[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[1;32m   1288\u001b[0m         \u001b[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[1;32m   1289\u001b[0m         \u001b[38;5;66;03m# worker failures.\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.10/multiprocessing/queues.py:113\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m block:\n\u001b[1;32m    112\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m deadline \u001b[38;5;241m-\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic()\n\u001b[0;32m--> 113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    114\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_poll():\n",
      "File \u001b[0;32m/usr/lib/python3.10/multiprocessing/connection.py:257\u001b[0m, in \u001b[0;36m_ConnectionBase.poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_closed()\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_readable()\n\u001b[0;32m--> 257\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.10/multiprocessing/connection.py:424\u001b[0m, in \u001b[0;36mConnection._poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    423\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_poll\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout):\n\u001b[0;32m--> 424\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    425\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(r)\n",
      "File \u001b[0;32m/usr/lib/python3.10/multiprocessing/connection.py:931\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    928\u001b[0m     deadline \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic() \u001b[38;5;241m+\u001b[39m timeout\n\u001b[1;32m    930\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 931\u001b[0m     ready \u001b[38;5;241m=\u001b[39m \u001b[43mselector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    932\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ready:\n\u001b[1;32m    933\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [key\u001b[38;5;241m.\u001b[39mfileobj \u001b[38;5;28;01mfor\u001b[39;00m (key, events) \u001b[38;5;129;01min\u001b[39;00m ready]\n",
      "File \u001b[0;32m/usr/lib/python3.10/selectors.py:416\u001b[0m, in \u001b[0;36m_PollLikeSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    414\u001b[0m ready \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    415\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 416\u001b[0m     fd_event_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_selector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpoll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n\u001b[1;32m    418\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ready\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Nico's net\n",
    "\n",
    "np.random.seed(random_seed)\n",
    "torch.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed_all(random_seed)\n",
    "\n",
    "model = AlexNet().to(device)\n",
    "loss_fn = nn.CrossEntropyLoss() \n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.38)\n",
    "scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, patience=2)\n",
    "\n",
    "# Train model\n",
    "for epoch in range(20):\n",
    "    print(f\"Epoch {epoch+1} begin: {dt.now()}.\")\n",
    "    start = time()\n",
    "\n",
    "    train(model, train_loader, optimizer, loss_fn, 500)\n",
    "    print('Completed training after {:.2f} seconds.'.format((time() - start)))\n",
    "    check_point = time()\n",
    "\n",
    "    val_loss = validate(model, val_loader, loss_fn)\n",
    "    print('Completed validation after {:.2f} seconds.'.format((time() - check_point)))\n",
    "    check_point = time()\n",
    "\n",
    "    accuracy(model, test_loader)\n",
    "    print('Completed testing after {:.2f} seconds.'.format((time() - check_point)))\n",
    "    scheduler.step(val_loss)\n",
    "\n",
    "    # Output an update\n",
    "    print('Total epoch time: {:.2f} seconds.'.format((time() - start)))\n",
    "    print('Epoch [{}/{}]'.format(epoch+1, 20))\n",
    "    print(\"####################################################################################################\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb476e18bd30968c",
   "metadata": {},
   "source": [
    "# Calculating model performance\n",
    "Load the best version of your model ( which should be produced and saved by previous cells ), calculate and report the test accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1eaa35096547d04",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for ResNet:\n\tMissing key(s) in state_dict: \"layer2.0.layer.0.weight\", \"layer2.0.layer.0.bias\", \"layer2.0.layer.2.weight\", \"layer2.0.layer.2.bias\", \"layer2.0.layer.2.running_mean\", \"layer2.0.layer.2.running_var\", \"layer2.0.layer.3.weight\", \"layer2.0.layer.3.bias\", \"layer2.0.layer.5.weight\", \"layer2.0.layer.5.bias\", \"layer2.0.layer.6.weight\", \"layer2.0.layer.6.bias\", \"layer2.0.layer.6.running_mean\", \"layer2.0.layer.6.running_var\", \"layer2.0.p_layer.weight\", \"layer2.0.p_layer.bias\", \"layer2.1.layer.0.weight\", \"layer2.1.layer.0.bias\", \"layer2.1.layer.2.weight\", \"layer2.1.layer.2.bias\", \"layer2.1.layer.2.running_mean\", \"layer2.1.layer.2.running_var\", \"layer2.1.layer.3.weight\", \"layer2.1.layer.3.bias\", \"layer2.1.layer.5.weight\", \"layer2.1.layer.5.bias\", \"layer2.1.layer.6.weight\", \"layer2.1.layer.6.bias\", \"layer2.1.layer.6.running_mean\", \"layer2.1.layer.6.running_var\", \"layer2.2.layer.0.weight\", \"layer2.2.layer.0.bias\", \"layer2.2.layer.2.weight\", \"layer2.2.layer.2.bias\", \"layer2.2.layer.2.running_mean\", \"layer2.2.layer.2.running_var\", \"layer2.2.layer.3.weight\", \"layer2.2.layer.3.bias\", \"layer2.2.layer.5.weight\", \"layer2.2.layer.5.bias\", \"layer2.2.layer.6.weight\", \"layer2.2.layer.6.bias\", \"layer2.2.layer.6.running_mean\", \"layer2.2.layer.6.running_var\", \"layer3.0.layer.0.weight\", \"layer3.0.layer.0.bias\", \"layer3.0.layer.2.weight\", \"layer3.0.layer.2.bias\", \"layer3.0.layer.2.running_mean\", \"layer3.0.layer.2.running_var\", \"layer3.0.layer.3.weight\", \"layer3.0.layer.3.bias\", \"layer3.0.layer.5.weight\", \"layer3.0.layer.5.bias\", \"layer3.0.layer.6.weight\", \"layer3.0.layer.6.bias\", \"layer3.0.layer.6.running_mean\", \"layer3.0.layer.6.running_var\", \"layer3.1.layer.0.weight\", \"layer3.1.layer.0.bias\", \"layer3.1.layer.2.weight\", \"layer3.1.layer.2.bias\", \"layer3.1.layer.2.running_mean\", \"layer3.1.layer.2.running_var\", \"layer3.1.layer.3.weight\", \"layer3.1.layer.3.bias\", \"layer3.1.layer.5.weight\", \"layer3.1.layer.5.bias\", \"layer3.1.layer.6.weight\", \"layer3.1.layer.6.bias\", \"layer3.1.layer.6.running_mean\", \"layer3.1.layer.6.running_var\", \"layer3.2.layer.0.weight\", \"layer3.2.layer.0.bias\", \"layer3.2.layer.2.weight\", \"layer3.2.layer.2.bias\", \"layer3.2.layer.2.running_mean\", \"layer3.2.layer.2.running_var\", \"layer3.2.layer.3.weight\", \"layer3.2.layer.3.bias\", \"layer3.2.layer.5.weight\", \"layer3.2.layer.5.bias\", \"layer3.2.layer.6.weight\", \"layer3.2.layer.6.bias\", \"layer3.2.layer.6.running_mean\", \"layer3.2.layer.6.running_var\", \"layer3.3.layer.0.weight\", \"layer3.3.layer.0.bias\", \"layer3.3.layer.2.weight\", \"layer3.3.layer.2.bias\", \"layer3.3.layer.2.running_mean\", \"layer3.3.layer.2.running_var\", \"layer3.3.layer.3.weight\", \"layer3.3.layer.3.bias\", \"layer3.3.layer.5.weight\", \"layer3.3.layer.5.bias\", \"layer3.3.layer.6.weight\", \"layer3.3.layer.6.bias\", \"layer3.3.layer.6.running_mean\", \"layer3.3.layer.6.running_var\", \"layer4.0.layer.0.weight\", \"layer4.0.layer.0.bias\", \"layer4.0.layer.2.weight\", \"layer4.0.layer.2.bias\", \"layer4.0.layer.2.running_mean\", \"layer4.0.layer.2.running_var\", \"layer4.0.layer.3.weight\", \"layer4.0.layer.3.bias\", \"layer4.0.layer.5.weight\", \"layer4.0.layer.5.bias\", \"layer4.0.layer.6.weight\", \"layer4.0.layer.6.bias\", \"layer4.0.layer.6.running_mean\", \"layer4.0.layer.6.running_var\", \"layer4.1.layer.0.weight\", \"layer4.1.layer.0.bias\", \"layer4.1.layer.2.weight\", \"layer4.1.layer.2.bias\", \"layer4.1.layer.2.running_mean\", \"layer4.1.layer.2.running_var\", \"layer4.1.layer.3.weight\", \"layer4.1.layer.3.bias\", \"layer4.1.layer.5.weight\", \"layer4.1.layer.5.bias\", \"layer4.1.layer.6.weight\", \"layer4.1.layer.6.bias\", \"layer4.1.layer.6.running_mean\", \"layer4.1.layer.6.running_var\", \"layer4.2.layer.0.weight\", \"layer4.2.layer.0.bias\", \"layer4.2.layer.2.weight\", \"layer4.2.layer.2.bias\", \"layer4.2.layer.2.running_mean\", \"layer4.2.layer.2.running_var\", \"layer4.2.layer.3.weight\", \"layer4.2.layer.3.bias\", \"layer4.2.layer.5.weight\", \"layer4.2.layer.5.bias\", \"layer4.2.layer.6.weight\", \"layer4.2.layer.6.bias\", \"layer4.2.layer.6.running_mean\", \"layer4.2.layer.6.running_var\", \"layer4.3.layer.0.weight\", \"layer4.3.layer.0.bias\", \"layer4.3.layer.2.weight\", \"layer4.3.layer.2.bias\", \"layer4.3.layer.2.running_mean\", \"layer4.3.layer.2.running_var\", \"layer4.3.layer.3.weight\", \"layer4.3.layer.3.bias\", \"layer4.3.layer.5.weight\", \"layer4.3.layer.5.bias\", \"layer4.3.layer.6.weight\", \"layer4.3.layer.6.bias\", \"layer4.3.layer.6.running_mean\", \"layer4.3.layer.6.running_var\", \"layer4.4.layer.0.weight\", \"layer4.4.layer.0.bias\", \"layer4.4.layer.2.weight\", \"layer4.4.layer.2.bias\", \"layer4.4.layer.2.running_mean\", \"layer4.4.layer.2.running_var\", \"layer4.4.layer.3.weight\", \"layer4.4.layer.3.bias\", \"layer4.4.layer.5.weight\", \"layer4.4.layer.5.bias\", \"layer4.4.layer.6.weight\", \"layer4.4.layer.6.bias\", \"layer4.4.layer.6.running_mean\", \"layer4.4.layer.6.running_var\", \"layer4.5.layer.0.weight\", \"layer4.5.layer.0.bias\", \"layer4.5.layer.2.weight\", \"layer4.5.layer.2.bias\", \"layer4.5.layer.2.running_mean\", \"layer4.5.layer.2.running_var\", \"layer4.5.layer.3.weight\", \"layer4.5.layer.3.bias\", \"layer4.5.layer.5.weight\", \"layer4.5.layer.5.bias\", \"layer4.5.layer.6.weight\", \"layer4.5.layer.6.bias\", \"layer4.5.layer.6.running_mean\", \"layer4.5.layer.6.running_var\", \"layer5.0.layer.0.weight\", \"layer5.0.layer.0.bias\", \"layer5.0.layer.2.weight\", \"layer5.0.layer.2.bias\", \"layer5.0.layer.2.running_mean\", \"layer5.0.layer.2.running_var\", \"layer5.0.layer.3.weight\", \"layer5.0.layer.3.bias\", \"layer5.0.layer.5.weight\", \"layer5.0.layer.5.bias\", \"layer5.0.layer.6.weight\", \"layer5.0.layer.6.bias\", \"layer5.0.layer.6.running_mean\", \"layer5.0.layer.6.running_var\", \"layer5.1.layer.0.weight\", \"layer5.1.layer.0.bias\", \"layer5.1.layer.2.weight\", \"layer5.1.layer.2.bias\", \"layer5.1.layer.2.running_mean\", \"layer5.1.layer.2.running_var\", \"layer5.1.layer.3.weight\", \"layer5.1.layer.3.bias\", \"layer5.1.layer.5.weight\", \"layer5.1.layer.5.bias\", \"layer5.1.layer.6.weight\", \"layer5.1.layer.6.bias\", \"layer5.1.layer.6.running_mean\", \"layer5.1.layer.6.running_var\", \"layer5.2.layer.0.weight\", \"layer5.2.layer.0.bias\", \"layer5.2.layer.2.weight\", \"layer5.2.layer.2.bias\", \"layer5.2.layer.2.running_mean\", \"layer5.2.layer.2.running_var\", \"layer5.2.layer.3.weight\", \"layer5.2.layer.3.bias\", \"layer5.2.layer.5.weight\", \"layer5.2.layer.5.bias\", \"layer5.2.layer.6.weight\", \"layer5.2.layer.6.bias\", \"layer5.2.layer.6.running_mean\", \"layer5.2.layer.6.running_var\", \"layer6.6.weight\", \"layer6.6.bias\". \n\tUnexpected key(s) in state_dict: \"layer1.2.weight\", \"layer1.2.bias\", \"layer1.2.running_mean\", \"layer1.2.running_var\", \"layer1.2.num_batches_tracked\", \"layer2.0.layer1.0.weight\", \"layer2.0.layer1.0.bias\", \"layer2.0.layer1.1.weight\", \"layer2.0.layer1.1.bias\", \"layer2.0.layer1.1.running_mean\", \"layer2.0.layer1.1.running_var\", \"layer2.0.layer1.1.num_batches_tracked\", \"layer2.0.layer2.0.weight\", \"layer2.0.layer2.0.bias\", \"layer2.0.layer2.1.weight\", \"layer2.0.layer2.1.bias\", \"layer2.0.layer2.1.running_mean\", \"layer2.0.layer2.1.running_var\", \"layer2.0.layer2.1.num_batches_tracked\", \"layer2.1.layer1.0.weight\", \"layer2.1.layer1.0.bias\", \"layer2.1.layer1.1.weight\", \"layer2.1.layer1.1.bias\", \"layer2.1.layer1.1.running_mean\", \"layer2.1.layer1.1.running_var\", \"layer2.1.layer1.1.num_batches_tracked\", \"layer2.1.layer2.0.weight\", \"layer2.1.layer2.0.bias\", \"layer2.1.layer2.1.weight\", \"layer2.1.layer2.1.bias\", \"layer2.1.layer2.1.running_mean\", \"layer2.1.layer2.1.running_var\", \"layer2.1.layer2.1.num_batches_tracked\", \"layer2.2.layer1.0.weight\", \"layer2.2.layer1.0.bias\", \"layer2.2.layer1.1.weight\", \"layer2.2.layer1.1.bias\", \"layer2.2.layer1.1.running_mean\", \"layer2.2.layer1.1.running_var\", \"layer2.2.layer1.1.num_batches_tracked\", \"layer2.2.layer2.0.weight\", \"layer2.2.layer2.0.bias\", \"layer2.2.layer2.1.weight\", \"layer2.2.layer2.1.bias\", \"layer2.2.layer2.1.running_mean\", \"layer2.2.layer2.1.running_var\", \"layer2.2.layer2.1.num_batches_tracked\", \"layer3.0.layer1.0.weight\", \"layer3.0.layer1.0.bias\", \"layer3.0.layer1.1.weight\", \"layer3.0.layer1.1.bias\", \"layer3.0.layer1.1.running_mean\", \"layer3.0.layer1.1.running_var\", \"layer3.0.layer1.1.num_batches_tracked\", \"layer3.0.layer2.0.weight\", \"layer3.0.layer2.0.bias\", \"layer3.0.layer2.1.weight\", \"layer3.0.layer2.1.bias\", \"layer3.0.layer2.1.running_mean\", \"layer3.0.layer2.1.running_var\", \"layer3.0.layer2.1.num_batches_tracked\", \"layer3.1.layer1.0.weight\", \"layer3.1.layer1.0.bias\", \"layer3.1.layer1.1.weight\", \"layer3.1.layer1.1.bias\", \"layer3.1.layer1.1.running_mean\", \"layer3.1.layer1.1.running_var\", \"layer3.1.layer1.1.num_batches_tracked\", \"layer3.1.layer2.0.weight\", \"layer3.1.layer2.0.bias\", \"layer3.1.layer2.1.weight\", \"layer3.1.layer2.1.bias\", \"layer3.1.layer2.1.running_mean\", \"layer3.1.layer2.1.running_var\", \"layer3.1.layer2.1.num_batches_tracked\", \"layer3.2.layer1.0.weight\", \"layer3.2.layer1.0.bias\", \"layer3.2.layer1.1.weight\", \"layer3.2.layer1.1.bias\", \"layer3.2.layer1.1.running_mean\", \"layer3.2.layer1.1.running_var\", \"layer3.2.layer1.1.num_batches_tracked\", \"layer3.2.layer2.0.weight\", \"layer3.2.layer2.0.bias\", \"layer3.2.layer2.1.weight\", \"layer3.2.layer2.1.bias\", \"layer3.2.layer2.1.running_mean\", \"layer3.2.layer2.1.running_var\", \"layer3.2.layer2.1.num_batches_tracked\", \"layer3.3.layer1.0.weight\", \"layer3.3.layer1.0.bias\", \"layer3.3.layer1.1.weight\", \"layer3.3.layer1.1.bias\", \"layer3.3.layer1.1.running_mean\", \"layer3.3.layer1.1.running_var\", \"layer3.3.layer1.1.num_batches_tracked\", \"layer3.3.layer2.0.weight\", \"layer3.3.layer2.0.bias\", \"layer3.3.layer2.1.weight\", \"layer3.3.layer2.1.bias\", \"layer3.3.layer2.1.running_mean\", \"layer3.3.layer2.1.running_var\", \"layer3.3.layer2.1.num_batches_tracked\", \"layer4.0.layer1.0.weight\", \"layer4.0.layer1.0.bias\", \"layer4.0.layer1.1.weight\", \"layer4.0.layer1.1.bias\", \"layer4.0.layer1.1.running_mean\", \"layer4.0.layer1.1.running_var\", \"layer4.0.layer1.1.num_batches_tracked\", \"layer4.0.layer2.0.weight\", \"layer4.0.layer2.0.bias\", \"layer4.0.layer2.1.weight\", \"layer4.0.layer2.1.bias\", \"layer4.0.layer2.1.running_mean\", \"layer4.0.layer2.1.running_var\", \"layer4.0.layer2.1.num_batches_tracked\", \"layer4.1.layer1.0.weight\", \"layer4.1.layer1.0.bias\", \"layer4.1.layer1.1.weight\", \"layer4.1.layer1.1.bias\", \"layer4.1.layer1.1.running_mean\", \"layer4.1.layer1.1.running_var\", \"layer4.1.layer1.1.num_batches_tracked\", \"layer4.1.layer2.0.weight\", \"layer4.1.layer2.0.bias\", \"layer4.1.layer2.1.weight\", \"layer4.1.layer2.1.bias\", \"layer4.1.layer2.1.running_mean\", \"layer4.1.layer2.1.running_var\", \"layer4.1.layer2.1.num_batches_tracked\", \"layer4.2.layer1.0.weight\", \"layer4.2.layer1.0.bias\", \"layer4.2.layer1.1.weight\", \"layer4.2.layer1.1.bias\", \"layer4.2.layer1.1.running_mean\", \"layer4.2.layer1.1.running_var\", \"layer4.2.layer1.1.num_batches_tracked\", \"layer4.2.layer2.0.weight\", \"layer4.2.layer2.0.bias\", \"layer4.2.layer2.1.weight\", \"layer4.2.layer2.1.bias\", \"layer4.2.layer2.1.running_mean\", \"layer4.2.layer2.1.running_var\", \"layer4.2.layer2.1.num_batches_tracked\", \"layer4.3.layer1.0.weight\", \"layer4.3.layer1.0.bias\", \"layer4.3.layer1.1.weight\", \"layer4.3.layer1.1.bias\", \"layer4.3.layer1.1.running_mean\", \"layer4.3.layer1.1.running_var\", \"layer4.3.layer1.1.num_batches_tracked\", \"layer4.3.layer2.0.weight\", \"layer4.3.layer2.0.bias\", \"layer4.3.layer2.1.weight\", \"layer4.3.layer2.1.bias\", \"layer4.3.layer2.1.running_mean\", \"layer4.3.layer2.1.running_var\", \"layer4.3.layer2.1.num_batches_tracked\", \"layer4.4.layer1.0.weight\", \"layer4.4.layer1.0.bias\", \"layer4.4.layer1.1.weight\", \"layer4.4.layer1.1.bias\", \"layer4.4.layer1.1.running_mean\", \"layer4.4.layer1.1.running_var\", \"layer4.4.layer1.1.num_batches_tracked\", \"layer4.4.layer2.0.weight\", \"layer4.4.layer2.0.bias\", \"layer4.4.layer2.1.weight\", \"layer4.4.layer2.1.bias\", \"layer4.4.layer2.1.running_mean\", \"layer4.4.layer2.1.running_var\", \"layer4.4.layer2.1.num_batches_tracked\", \"layer4.5.layer1.0.weight\", \"layer4.5.layer1.0.bias\", \"layer4.5.layer1.1.weight\", \"layer4.5.layer1.1.bias\", \"layer4.5.layer1.1.running_mean\", \"layer4.5.layer1.1.running_var\", \"layer4.5.layer1.1.num_batches_tracked\", \"layer4.5.layer2.0.weight\", \"layer4.5.layer2.0.bias\", \"layer4.5.layer2.1.weight\", \"layer4.5.layer2.1.bias\", \"layer4.5.layer2.1.running_mean\", \"layer4.5.layer2.1.running_var\", \"layer4.5.layer2.1.num_batches_tracked\", \"layer5.0.layer1.0.weight\", \"layer5.0.layer1.0.bias\", \"layer5.0.layer1.1.weight\", \"layer5.0.layer1.1.bias\", \"layer5.0.layer1.1.running_mean\", \"layer5.0.layer1.1.running_var\", \"layer5.0.layer1.1.num_batches_tracked\", \"layer5.0.layer2.0.weight\", \"layer5.0.layer2.0.bias\", \"layer5.0.layer2.1.weight\", \"layer5.0.layer2.1.bias\", \"layer5.0.layer2.1.running_mean\", \"layer5.0.layer2.1.running_var\", \"layer5.0.layer2.1.num_batches_tracked\", \"layer5.1.layer1.0.weight\", \"layer5.1.layer1.0.bias\", \"layer5.1.layer1.1.weight\", \"layer5.1.layer1.1.bias\", \"layer5.1.layer1.1.running_mean\", \"layer5.1.layer1.1.running_var\", \"layer5.1.layer1.1.num_batches_tracked\", \"layer5.1.layer2.0.weight\", \"layer5.1.layer2.0.bias\", \"layer5.1.layer2.1.weight\", \"layer5.1.layer2.1.bias\", \"layer5.1.layer2.1.running_mean\", \"layer5.1.layer2.1.running_var\", \"layer5.1.layer2.1.num_batches_tracked\", \"layer5.2.layer1.0.weight\", \"layer5.2.layer1.0.bias\", \"layer5.2.layer1.1.weight\", \"layer5.2.layer1.1.bias\", \"layer5.2.layer1.1.running_mean\", \"layer5.2.layer1.1.running_var\", \"layer5.2.layer1.1.num_batches_tracked\", \"layer5.2.layer2.0.weight\", \"layer5.2.layer2.0.bias\", \"layer5.2.layer2.1.weight\", \"layer5.2.layer2.1.bias\", \"layer5.2.layer2.1.running_mean\", \"layer5.2.layer2.1.running_var\", \"layer5.2.layer2.1.num_batches_tracked\". \n\tsize mismatch for layer3.0.p_layer.weight: copying a param with shape torch.Size([128, 64, 1, 1]) from checkpoint, the shape in current model is torch.Size([512, 256, 1, 1]).\n\tsize mismatch for layer3.0.p_layer.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for layer4.0.p_layer.weight: copying a param with shape torch.Size([256, 128, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 512, 1, 1]).\n\tsize mismatch for layer4.0.p_layer.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for layer5.0.p_layer.weight: copying a param with shape torch.Size([512, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([2048, 1024, 1, 1]).\n\tsize mismatch for layer5.0.p_layer.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for layer6.3.weight: copying a param with shape torch.Size([91, 512]) from checkpoint, the shape in current model is torch.Size([1024, 2048]).\n\tsize mismatch for layer6.3.bias: copying a param with shape torch.Size([91]) from checkpoint, the shape in current model is torch.Size([1024]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[51], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m### MODEL COMPARISONS ###\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Load the best model weights\u001b[39;00m\n\u001b[1;32m      4\u001b[0m model2 \u001b[38;5;241m=\u001b[39m ResNet()\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m----> 5\u001b[0m \u001b[43mmodel2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcheckpoint.pth\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Calculate and present final scores\u001b[39;00m\n\u001b[1;32m      8\u001b[0m final_test_acc \u001b[38;5;241m=\u001b[39m accuracy(model2, test_loader)\n",
      "File \u001b[0;32m~/Desktop/Neural Computing/Py1/lib/python3.10/site-packages/torch/nn/modules/module.py:2593\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2585\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[1;32m   2586\u001b[0m             \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m   2587\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2588\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)\n\u001b[1;32m   2589\u001b[0m             ),\n\u001b[1;32m   2590\u001b[0m         )\n\u001b[1;32m   2592\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 2593\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   2594\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2595\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)\n\u001b[1;32m   2596\u001b[0m         )\n\u001b[1;32m   2597\u001b[0m     )\n\u001b[1;32m   2598\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for ResNet:\n\tMissing key(s) in state_dict: \"layer2.0.layer.0.weight\", \"layer2.0.layer.0.bias\", \"layer2.0.layer.2.weight\", \"layer2.0.layer.2.bias\", \"layer2.0.layer.2.running_mean\", \"layer2.0.layer.2.running_var\", \"layer2.0.layer.3.weight\", \"layer2.0.layer.3.bias\", \"layer2.0.layer.5.weight\", \"layer2.0.layer.5.bias\", \"layer2.0.layer.6.weight\", \"layer2.0.layer.6.bias\", \"layer2.0.layer.6.running_mean\", \"layer2.0.layer.6.running_var\", \"layer2.0.p_layer.weight\", \"layer2.0.p_layer.bias\", \"layer2.1.layer.0.weight\", \"layer2.1.layer.0.bias\", \"layer2.1.layer.2.weight\", \"layer2.1.layer.2.bias\", \"layer2.1.layer.2.running_mean\", \"layer2.1.layer.2.running_var\", \"layer2.1.layer.3.weight\", \"layer2.1.layer.3.bias\", \"layer2.1.layer.5.weight\", \"layer2.1.layer.5.bias\", \"layer2.1.layer.6.weight\", \"layer2.1.layer.6.bias\", \"layer2.1.layer.6.running_mean\", \"layer2.1.layer.6.running_var\", \"layer2.2.layer.0.weight\", \"layer2.2.layer.0.bias\", \"layer2.2.layer.2.weight\", \"layer2.2.layer.2.bias\", \"layer2.2.layer.2.running_mean\", \"layer2.2.layer.2.running_var\", \"layer2.2.layer.3.weight\", \"layer2.2.layer.3.bias\", \"layer2.2.layer.5.weight\", \"layer2.2.layer.5.bias\", \"layer2.2.layer.6.weight\", \"layer2.2.layer.6.bias\", \"layer2.2.layer.6.running_mean\", \"layer2.2.layer.6.running_var\", \"layer3.0.layer.0.weight\", \"layer3.0.layer.0.bias\", \"layer3.0.layer.2.weight\", \"layer3.0.layer.2.bias\", \"layer3.0.layer.2.running_mean\", \"layer3.0.layer.2.running_var\", \"layer3.0.layer.3.weight\", \"layer3.0.layer.3.bias\", \"layer3.0.layer.5.weight\", \"layer3.0.layer.5.bias\", \"layer3.0.layer.6.weight\", \"layer3.0.layer.6.bias\", \"layer3.0.layer.6.running_mean\", \"layer3.0.layer.6.running_var\", \"layer3.1.layer.0.weight\", \"layer3.1.layer.0.bias\", \"layer3.1.layer.2.weight\", \"layer3.1.layer.2.bias\", \"layer3.1.layer.2.running_mean\", \"layer3.1.layer.2.running_var\", \"layer3.1.layer.3.weight\", \"layer3.1.layer.3.bias\", \"layer3.1.layer.5.weight\", \"layer3.1.layer.5.bias\", \"layer3.1.layer.6.weight\", \"layer3.1.layer.6.bias\", \"layer3.1.layer.6.running_mean\", \"layer3.1.layer.6.running_var\", \"layer3.2.layer.0.weight\", \"layer3.2.layer.0.bias\", \"layer3.2.layer.2.weight\", \"layer3.2.layer.2.bias\", \"layer3.2.layer.2.running_mean\", \"layer3.2.layer.2.running_var\", \"layer3.2.layer.3.weight\", \"layer3.2.layer.3.bias\", \"layer3.2.layer.5.weight\", \"layer3.2.layer.5.bias\", \"layer3.2.layer.6.weight\", \"layer3.2.layer.6.bias\", \"layer3.2.layer.6.running_mean\", \"layer3.2.layer.6.running_var\", \"layer3.3.layer.0.weight\", \"layer3.3.layer.0.bias\", \"layer3.3.layer.2.weight\", \"layer3.3.layer.2.bias\", \"layer3.3.layer.2.running_mean\", \"layer3.3.layer.2.running_var\", \"layer3.3.layer.3.weight\", \"layer3.3.layer.3.bias\", \"layer3.3.layer.5.weight\", \"layer3.3.layer.5.bias\", \"layer3.3.layer.6.weight\", \"layer3.3.layer.6.bias\", \"layer3.3.layer.6.running_mean\", \"layer3.3.layer.6.running_var\", \"layer4.0.layer.0.weight\", \"layer4.0.layer.0.bias\", \"layer4.0.layer.2.weight\", \"layer4.0.layer.2.bias\", \"layer4.0.layer.2.running_mean\", \"layer4.0.layer.2.running_var\", \"layer4.0.layer.3.weight\", \"layer4.0.layer.3.bias\", \"layer4.0.layer.5.weight\", \"layer4.0.layer.5.bias\", \"layer4.0.layer.6.weight\", \"layer4.0.layer.6.bias\", \"layer4.0.layer.6.running_mean\", \"layer4.0.layer.6.running_var\", \"layer4.1.layer.0.weight\", \"layer4.1.layer.0.bias\", \"layer4.1.layer.2.weight\", \"layer4.1.layer.2.bias\", \"layer4.1.layer.2.running_mean\", \"layer4.1.layer.2.running_var\", \"layer4.1.layer.3.weight\", \"layer4.1.layer.3.bias\", \"layer4.1.layer.5.weight\", \"layer4.1.layer.5.bias\", \"layer4.1.layer.6.weight\", \"layer4.1.layer.6.bias\", \"layer4.1.layer.6.running_mean\", \"layer4.1.layer.6.running_var\", \"layer4.2.layer.0.weight\", \"layer4.2.layer.0.bias\", \"layer4.2.layer.2.weight\", \"layer4.2.layer.2.bias\", \"layer4.2.layer.2.running_mean\", \"layer4.2.layer.2.running_var\", \"layer4.2.layer.3.weight\", \"layer4.2.layer.3.bias\", \"layer4.2.layer.5.weight\", \"layer4.2.layer.5.bias\", \"layer4.2.layer.6.weight\", \"layer4.2.layer.6.bias\", \"layer4.2.layer.6.running_mean\", \"layer4.2.layer.6.running_var\", \"layer4.3.layer.0.weight\", \"layer4.3.layer.0.bias\", \"layer4.3.layer.2.weight\", \"layer4.3.layer.2.bias\", \"layer4.3.layer.2.running_mean\", \"layer4.3.layer.2.running_var\", \"layer4.3.layer.3.weight\", \"layer4.3.layer.3.bias\", \"layer4.3.layer.5.weight\", \"layer4.3.layer.5.bias\", \"layer4.3.layer.6.weight\", \"layer4.3.layer.6.bias\", \"layer4.3.layer.6.running_mean\", \"layer4.3.layer.6.running_var\", \"layer4.4.layer.0.weight\", \"layer4.4.layer.0.bias\", \"layer4.4.layer.2.weight\", \"layer4.4.layer.2.bias\", \"layer4.4.layer.2.running_mean\", \"layer4.4.layer.2.running_var\", \"layer4.4.layer.3.weight\", \"layer4.4.layer.3.bias\", \"layer4.4.layer.5.weight\", \"layer4.4.layer.5.bias\", \"layer4.4.layer.6.weight\", \"layer4.4.layer.6.bias\", \"layer4.4.layer.6.running_mean\", \"layer4.4.layer.6.running_var\", \"layer4.5.layer.0.weight\", \"layer4.5.layer.0.bias\", \"layer4.5.layer.2.weight\", \"layer4.5.layer.2.bias\", \"layer4.5.layer.2.running_mean\", \"layer4.5.layer.2.running_var\", \"layer4.5.layer.3.weight\", \"layer4.5.layer.3.bias\", \"layer4.5.layer.5.weight\", \"layer4.5.layer.5.bias\", \"layer4.5.layer.6.weight\", \"layer4.5.layer.6.bias\", \"layer4.5.layer.6.running_mean\", \"layer4.5.layer.6.running_var\", \"layer5.0.layer.0.weight\", \"layer5.0.layer.0.bias\", \"layer5.0.layer.2.weight\", \"layer5.0.layer.2.bias\", \"layer5.0.layer.2.running_mean\", \"layer5.0.layer.2.running_var\", \"layer5.0.layer.3.weight\", \"layer5.0.layer.3.bias\", \"layer5.0.layer.5.weight\", \"layer5.0.layer.5.bias\", \"layer5.0.layer.6.weight\", \"layer5.0.layer.6.bias\", \"layer5.0.layer.6.running_mean\", \"layer5.0.layer.6.running_var\", \"layer5.1.layer.0.weight\", \"layer5.1.layer.0.bias\", \"layer5.1.layer.2.weight\", \"layer5.1.layer.2.bias\", \"layer5.1.layer.2.running_mean\", \"layer5.1.layer.2.running_var\", \"layer5.1.layer.3.weight\", \"layer5.1.layer.3.bias\", \"layer5.1.layer.5.weight\", \"layer5.1.layer.5.bias\", \"layer5.1.layer.6.weight\", \"layer5.1.layer.6.bias\", \"layer5.1.layer.6.running_mean\", \"layer5.1.layer.6.running_var\", \"layer5.2.layer.0.weight\", \"layer5.2.layer.0.bias\", \"layer5.2.layer.2.weight\", \"layer5.2.layer.2.bias\", \"layer5.2.layer.2.running_mean\", \"layer5.2.layer.2.running_var\", \"layer5.2.layer.3.weight\", \"layer5.2.layer.3.bias\", \"layer5.2.layer.5.weight\", \"layer5.2.layer.5.bias\", \"layer5.2.layer.6.weight\", \"layer5.2.layer.6.bias\", \"layer5.2.layer.6.running_mean\", \"layer5.2.layer.6.running_var\", \"layer6.6.weight\", \"layer6.6.bias\". \n\tUnexpected key(s) in state_dict: \"layer1.2.weight\", \"layer1.2.bias\", \"layer1.2.running_mean\", \"layer1.2.running_var\", \"layer1.2.num_batches_tracked\", \"layer2.0.layer1.0.weight\", \"layer2.0.layer1.0.bias\", \"layer2.0.layer1.1.weight\", \"layer2.0.layer1.1.bias\", \"layer2.0.layer1.1.running_mean\", \"layer2.0.layer1.1.running_var\", \"layer2.0.layer1.1.num_batches_tracked\", \"layer2.0.layer2.0.weight\", \"layer2.0.layer2.0.bias\", \"layer2.0.layer2.1.weight\", \"layer2.0.layer2.1.bias\", \"layer2.0.layer2.1.running_mean\", \"layer2.0.layer2.1.running_var\", \"layer2.0.layer2.1.num_batches_tracked\", \"layer2.1.layer1.0.weight\", \"layer2.1.layer1.0.bias\", \"layer2.1.layer1.1.weight\", \"layer2.1.layer1.1.bias\", \"layer2.1.layer1.1.running_mean\", \"layer2.1.layer1.1.running_var\", \"layer2.1.layer1.1.num_batches_tracked\", \"layer2.1.layer2.0.weight\", \"layer2.1.layer2.0.bias\", \"layer2.1.layer2.1.weight\", \"layer2.1.layer2.1.bias\", \"layer2.1.layer2.1.running_mean\", \"layer2.1.layer2.1.running_var\", \"layer2.1.layer2.1.num_batches_tracked\", \"layer2.2.layer1.0.weight\", \"layer2.2.layer1.0.bias\", \"layer2.2.layer1.1.weight\", \"layer2.2.layer1.1.bias\", \"layer2.2.layer1.1.running_mean\", \"layer2.2.layer1.1.running_var\", \"layer2.2.layer1.1.num_batches_tracked\", \"layer2.2.layer2.0.weight\", \"layer2.2.layer2.0.bias\", \"layer2.2.layer2.1.weight\", \"layer2.2.layer2.1.bias\", \"layer2.2.layer2.1.running_mean\", \"layer2.2.layer2.1.running_var\", \"layer2.2.layer2.1.num_batches_tracked\", \"layer3.0.layer1.0.weight\", \"layer3.0.layer1.0.bias\", \"layer3.0.layer1.1.weight\", \"layer3.0.layer1.1.bias\", \"layer3.0.layer1.1.running_mean\", \"layer3.0.layer1.1.running_var\", \"layer3.0.layer1.1.num_batches_tracked\", \"layer3.0.layer2.0.weight\", \"layer3.0.layer2.0.bias\", \"layer3.0.layer2.1.weight\", \"layer3.0.layer2.1.bias\", \"layer3.0.layer2.1.running_mean\", \"layer3.0.layer2.1.running_var\", \"layer3.0.layer2.1.num_batches_tracked\", \"layer3.1.layer1.0.weight\", \"layer3.1.layer1.0.bias\", \"layer3.1.layer1.1.weight\", \"layer3.1.layer1.1.bias\", \"layer3.1.layer1.1.running_mean\", \"layer3.1.layer1.1.running_var\", \"layer3.1.layer1.1.num_batches_tracked\", \"layer3.1.layer2.0.weight\", \"layer3.1.layer2.0.bias\", \"layer3.1.layer2.1.weight\", \"layer3.1.layer2.1.bias\", \"layer3.1.layer2.1.running_mean\", \"layer3.1.layer2.1.running_var\", \"layer3.1.layer2.1.num_batches_tracked\", \"layer3.2.layer1.0.weight\", \"layer3.2.layer1.0.bias\", \"layer3.2.layer1.1.weight\", \"layer3.2.layer1.1.bias\", \"layer3.2.layer1.1.running_mean\", \"layer3.2.layer1.1.running_var\", \"layer3.2.layer1.1.num_batches_tracked\", \"layer3.2.layer2.0.weight\", \"layer3.2.layer2.0.bias\", \"layer3.2.layer2.1.weight\", \"layer3.2.layer2.1.bias\", \"layer3.2.layer2.1.running_mean\", \"layer3.2.layer2.1.running_var\", \"layer3.2.layer2.1.num_batches_tracked\", \"layer3.3.layer1.0.weight\", \"layer3.3.layer1.0.bias\", \"layer3.3.layer1.1.weight\", \"layer3.3.layer1.1.bias\", \"layer3.3.layer1.1.running_mean\", \"layer3.3.layer1.1.running_var\", \"layer3.3.layer1.1.num_batches_tracked\", \"layer3.3.layer2.0.weight\", \"layer3.3.layer2.0.bias\", \"layer3.3.layer2.1.weight\", \"layer3.3.layer2.1.bias\", \"layer3.3.layer2.1.running_mean\", \"layer3.3.layer2.1.running_var\", \"layer3.3.layer2.1.num_batches_tracked\", \"layer4.0.layer1.0.weight\", \"layer4.0.layer1.0.bias\", \"layer4.0.layer1.1.weight\", \"layer4.0.layer1.1.bias\", \"layer4.0.layer1.1.running_mean\", \"layer4.0.layer1.1.running_var\", \"layer4.0.layer1.1.num_batches_tracked\", \"layer4.0.layer2.0.weight\", \"layer4.0.layer2.0.bias\", \"layer4.0.layer2.1.weight\", \"layer4.0.layer2.1.bias\", \"layer4.0.layer2.1.running_mean\", \"layer4.0.layer2.1.running_var\", \"layer4.0.layer2.1.num_batches_tracked\", \"layer4.1.layer1.0.weight\", \"layer4.1.layer1.0.bias\", \"layer4.1.layer1.1.weight\", \"layer4.1.layer1.1.bias\", \"layer4.1.layer1.1.running_mean\", \"layer4.1.layer1.1.running_var\", \"layer4.1.layer1.1.num_batches_tracked\", \"layer4.1.layer2.0.weight\", \"layer4.1.layer2.0.bias\", \"layer4.1.layer2.1.weight\", \"layer4.1.layer2.1.bias\", \"layer4.1.layer2.1.running_mean\", \"layer4.1.layer2.1.running_var\", \"layer4.1.layer2.1.num_batches_tracked\", \"layer4.2.layer1.0.weight\", \"layer4.2.layer1.0.bias\", \"layer4.2.layer1.1.weight\", \"layer4.2.layer1.1.bias\", \"layer4.2.layer1.1.running_mean\", \"layer4.2.layer1.1.running_var\", \"layer4.2.layer1.1.num_batches_tracked\", \"layer4.2.layer2.0.weight\", \"layer4.2.layer2.0.bias\", \"layer4.2.layer2.1.weight\", \"layer4.2.layer2.1.bias\", \"layer4.2.layer2.1.running_mean\", \"layer4.2.layer2.1.running_var\", \"layer4.2.layer2.1.num_batches_tracked\", \"layer4.3.layer1.0.weight\", \"layer4.3.layer1.0.bias\", \"layer4.3.layer1.1.weight\", \"layer4.3.layer1.1.bias\", \"layer4.3.layer1.1.running_mean\", \"layer4.3.layer1.1.running_var\", \"layer4.3.layer1.1.num_batches_tracked\", \"layer4.3.layer2.0.weight\", \"layer4.3.layer2.0.bias\", \"layer4.3.layer2.1.weight\", \"layer4.3.layer2.1.bias\", \"layer4.3.layer2.1.running_mean\", \"layer4.3.layer2.1.running_var\", \"layer4.3.layer2.1.num_batches_tracked\", \"layer4.4.layer1.0.weight\", \"layer4.4.layer1.0.bias\", \"layer4.4.layer1.1.weight\", \"layer4.4.layer1.1.bias\", \"layer4.4.layer1.1.running_mean\", \"layer4.4.layer1.1.running_var\", \"layer4.4.layer1.1.num_batches_tracked\", \"layer4.4.layer2.0.weight\", \"layer4.4.layer2.0.bias\", \"layer4.4.layer2.1.weight\", \"layer4.4.layer2.1.bias\", \"layer4.4.layer2.1.running_mean\", \"layer4.4.layer2.1.running_var\", \"layer4.4.layer2.1.num_batches_tracked\", \"layer4.5.layer1.0.weight\", \"layer4.5.layer1.0.bias\", \"layer4.5.layer1.1.weight\", \"layer4.5.layer1.1.bias\", \"layer4.5.layer1.1.running_mean\", \"layer4.5.layer1.1.running_var\", \"layer4.5.layer1.1.num_batches_tracked\", \"layer4.5.layer2.0.weight\", \"layer4.5.layer2.0.bias\", \"layer4.5.layer2.1.weight\", \"layer4.5.layer2.1.bias\", \"layer4.5.layer2.1.running_mean\", \"layer4.5.layer2.1.running_var\", \"layer4.5.layer2.1.num_batches_tracked\", \"layer5.0.layer1.0.weight\", \"layer5.0.layer1.0.bias\", \"layer5.0.layer1.1.weight\", \"layer5.0.layer1.1.bias\", \"layer5.0.layer1.1.running_mean\", \"layer5.0.layer1.1.running_var\", \"layer5.0.layer1.1.num_batches_tracked\", \"layer5.0.layer2.0.weight\", \"layer5.0.layer2.0.bias\", \"layer5.0.layer2.1.weight\", \"layer5.0.layer2.1.bias\", \"layer5.0.layer2.1.running_mean\", \"layer5.0.layer2.1.running_var\", \"layer5.0.layer2.1.num_batches_tracked\", \"layer5.1.layer1.0.weight\", \"layer5.1.layer1.0.bias\", \"layer5.1.layer1.1.weight\", \"layer5.1.layer1.1.bias\", \"layer5.1.layer1.1.running_mean\", \"layer5.1.layer1.1.running_var\", \"layer5.1.layer1.1.num_batches_tracked\", \"layer5.1.layer2.0.weight\", \"layer5.1.layer2.0.bias\", \"layer5.1.layer2.1.weight\", \"layer5.1.layer2.1.bias\", \"layer5.1.layer2.1.running_mean\", \"layer5.1.layer2.1.running_var\", \"layer5.1.layer2.1.num_batches_tracked\", \"layer5.2.layer1.0.weight\", \"layer5.2.layer1.0.bias\", \"layer5.2.layer1.1.weight\", \"layer5.2.layer1.1.bias\", \"layer5.2.layer1.1.running_mean\", \"layer5.2.layer1.1.running_var\", \"layer5.2.layer1.1.num_batches_tracked\", \"layer5.2.layer2.0.weight\", \"layer5.2.layer2.0.bias\", \"layer5.2.layer2.1.weight\", \"layer5.2.layer2.1.bias\", \"layer5.2.layer2.1.running_mean\", \"layer5.2.layer2.1.running_var\", \"layer5.2.layer2.1.num_batches_tracked\". \n\tsize mismatch for layer3.0.p_layer.weight: copying a param with shape torch.Size([128, 64, 1, 1]) from checkpoint, the shape in current model is torch.Size([512, 256, 1, 1]).\n\tsize mismatch for layer3.0.p_layer.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for layer4.0.p_layer.weight: copying a param with shape torch.Size([256, 128, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 512, 1, 1]).\n\tsize mismatch for layer4.0.p_layer.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for layer5.0.p_layer.weight: copying a param with shape torch.Size([512, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([2048, 1024, 1, 1]).\n\tsize mismatch for layer5.0.p_layer.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for layer6.3.weight: copying a param with shape torch.Size([91, 512]) from checkpoint, the shape in current model is torch.Size([1024, 2048]).\n\tsize mismatch for layer6.3.bias: copying a param with shape torch.Size([91]) from checkpoint, the shape in current model is torch.Size([1024])."
     ]
    }
   ],
   "source": [
    "### MODEL COMPARISONS ###\n",
    "\n",
    "# Load the best model weights\n",
    "model2 = ResNet().to(device)\n",
    "model2.load_state_dict(torch.load(\"checkpoint.pth\", weights_only=True))\n",
    "\n",
    "# Calculate and present final scores\n",
    "final_test_acc = accuracy(model2, test_loader)\n",
    "print(f\"Final Test Accuracy: {final_test_acc:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ecc6f7f921591e",
   "metadata": {},
   "source": [
    "# Summary of hyperparameters\n",
    "Report the hyperparameters ( learning rate etc ) that you used in your final model for reproducibility."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b6a524e28b431a",
   "metadata": {},
   "source": [
    "# Simulation of random user\n",
    "Pick 10 random pictures of the test set to simulate a user uploading images and report which categories occur how often in these: 1pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b6e8175cacc8dfe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-02T17:04:06.539916Z",
     "start_time": "2025-04-02T17:04:05.929092Z"
    },
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Your code here\n",
    "# Below an example showing the format of the code output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e7a3634bf6861f",
   "metadata": {},
   "source": [
    "# Bonus point\n",
    "Use an LLM (API) to generate a description of the food preference of a user based on 10 images that a potential user could provide. \n",
    "Please include an example of the output of your code, especially if you used an API other than the OpenAI API.\n",
    "\n",
    "This should work well even with differing test images by setting different random seeds for the image selector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6819fa0042485dae",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IPy1",
   "language": "python",
   "name": "ipy1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
