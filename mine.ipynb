{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf1be1b2f55b62c0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Food Classification with CNN - Building a Restaurant Recommendation System\n",
    "\n",
    "This assignment focuses on developing a deep learning-based food classification system using Convolutional Neural Networks (CNNs). You will build a model that can recognize different food categories and use it to return the food preferences of a user.\n",
    "\n",
    "## Learning Objectives\n",
    "- Implement CNNs for image classification\n",
    "- Work with real-world food image datasets\n",
    "- Build a preference-detector system\n",
    "\n",
    "## Background: AI-Powered Food Preference Discovery\n",
    "\n",
    "The system's core idea is simple:\n",
    "\n",
    "1. Users upload 10 photos of dishes they enjoy\n",
    "2. Your CNN classifies these images into the 91 categories\n",
    "3. Based on these categories, the system returns the user's taste profile\n",
    "\n",
    "Your task is to develop the core computer vision component that will power this detection engine.\n",
    "\n",
    "You are given a training (\"train\" folder) and a test (\"test\" folder) dataset which have ~45k and ~22k samples respectively. For each one of the 91 classes there is a subdirectory containing the images of the respective class.\n",
    "\n",
    "## Assignment Requirements\n",
    "\n",
    "### Technical Requirements\n",
    "- Implement your own pytorch CNN architecture for food image classification\n",
    "- Use only the provided training dataset split for training\n",
    "- Train the network from scratch ; No pretrained weights can be used\n",
    "- Report test-accuracy after every epoch\n",
    "- Report all hyperparameters of final model\n",
    "- Use a fixed seed and do not use any CUDA-features that break reproducibility\n",
    "- Use Pytorch 2.6\n",
    "\n",
    "### Deliverables\n",
    "1. Jupyter Notebook with CNN implementation, training code etc.\n",
    "2. README file\n",
    "3. Report (max 3 pages)\n",
    "\n",
    "Submit your report, README and all code files as a single zip file named GROUP_[number]_NC2425_PA. The names and IDs of the group components must be mentioned in the README.\n",
    "Do not include the dataset in your submission.\n",
    "\n",
    "### Grading\n",
    "\n",
    "1. Correct CNN implementation, training runs on the uni DSLab computers according to the README.MD instructions without ANY exceptions on the DSLab machines: 3pt\n",
    "2. Perfect 1:1 reproducibility on DSLab machines: 1pt\n",
    "3. Very clear github-repo-style README.MD with instructions for running the code: 1pt\n",
    "4. Report: 1pt\n",
    "5. Model test performance on test-set: interpolated from 30-80% test-accuracy: 0-3pt\n",
    "6. Pick 10 random pictures of the test set to simulate a user uploading images and report which categories occur how often in these: 1pt\n",
    "7. Bonus point: use an LLM (API) to generate short description / profile of preferences of the simulated user\n",
    "\n",
    "**If there is anything unclear about this assignment please post your question in the Brightspace discussions forum or send an email**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c222e5c4ff1b26",
   "metadata": {},
   "source": [
    "# Loading the datasets\n",
    "The dataset is already split into a train and test set in the directories \"train\" and \"test\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "416f413f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### HYPER-PARAMETER SET-UP ###\n",
    "\n",
    "# Randomization\n",
    "random_seed = 13\n",
    "\n",
    "# Model training\n",
    "workers = 8\n",
    "batch_size = 32\n",
    "num_epochs = 50\n",
    "lr = 0.01\n",
    "momentum = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3e5a5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### IMPORTS AND DEVICE ###\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets\n",
    "from torch.autograd import Variable\n",
    "from datetime import datetime as dt\n",
    "from torchvision.transforms import v2\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "\n",
    "\n",
    "# Use the GPU to speed up the training\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aed23ce7b9cbfbf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### DATA LOADING ###\n",
    "\n",
    "# Allow repeatability\n",
    "np.random.seed(random_seed)\n",
    "torch.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed_all(random_seed)\n",
    "\n",
    "# Define the transformer for the data\n",
    "train_transform = v2.Compose([\n",
    "    v2.Resize((256, 256)),\n",
    "    v2.RandomApply([v2.TrivialAugmentWide()], p=0.5),\n",
    "    v2.ToImage(), \n",
    "    v2.ToDtype(torch.float32, scale=True),\n",
    "    v2.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "test_transform = v2.Compose([\n",
    "    v2.Resize((256, 256)),\n",
    "    v2.ToImage(), \n",
    "    v2.ToDtype(torch.float32, scale=True),\n",
    "    v2.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "# Collect the data and set the augmentation\n",
    "train_dataset = datasets.ImageFolder(root='../train', transform=train_transform)\n",
    "test_dataset = datasets.ImageFolder(root='../test', transform=test_transform) \n",
    "\n",
    "# Prepare the data loaders with the batches, shuffling, and workers\n",
    "train_loader = DataLoader(train_dataset, batch_size, shuffle=True, num_workers=workers)\n",
    "test_loader = DataLoader(test_dataset, batch_size, shuffle=False, num_workers=workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0c424fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1429, 704)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader), len(test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7bb30ae14ffa42",
   "metadata": {},
   "source": [
    "# CNN Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fab0ebdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ResNet ###\n",
    "\n",
    "class Block(nn.Module):\n",
    "    def __init__(self, in_channels, mid_channels, stride=1, expansion=4):\n",
    "        super().__init__()\n",
    "        # Convolutional block\n",
    "        self.layer = nn.Sequential(nn.Conv2d(in_channels, mid_channels, 1, 1, 0),\n",
    "                                   nn.SELU(),\n",
    "                                   nn.BatchNorm2d(mid_channels),\n",
    "                                   nn.Conv2d(mid_channels, mid_channels, 3, stride, 1),\n",
    "                                   nn.SELU(),\n",
    "                                   nn.Conv2d(mid_channels, mid_channels*expansion, 1, 1, 0),\n",
    "                                   nn.BatchNorm2d(mid_channels*expansion))\n",
    "\n",
    "        # In case the dimensionality of the data changes\n",
    "        self.proj = False\n",
    "        if in_channels != (mid_channels*expansion) or stride != 1:\n",
    "            self.proj = True\n",
    "            self.p_layer = nn.Conv2d(in_channels, mid_channels*4, 1, stride)\n",
    "\n",
    "    def forward(self, x):\n",
    "        res = x\n",
    "        out = self.layer(x)\n",
    "        # Add the residual of the original data to allow for an identity function\n",
    "        if self.proj:\n",
    "            res = self.p_layer(x)\n",
    "        return nn.SELU()(out+res)\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    \"\"\"\n",
    "    Made to emulate the Residual Network.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_blocks=None):\n",
    "        super().__init__()\n",
    "        if num_blocks is None:\n",
    "            num_blocks = [3, 4, 6, 3]\n",
    "        self.layer1 = nn.Sequential(nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3),\n",
    "                                    nn.SELU(),\n",
    "                                    nn.MaxPool2d(3, 2, 1))          # 64\n",
    "\n",
    "        self.layer2 = self._make_layer(64, 64, num_blocks[0], 1)\n",
    "        self.layer3 = self._make_layer(256, 128, num_blocks[1])     # 32\n",
    "        self.layer4 = self._make_layer(512, 256, num_blocks[2])     # 16\n",
    "        self.layer5 = self._make_layer(1024, 512, num_blocks[3])    # 8\n",
    "\n",
    "        self.layer6 = nn.Sequential(nn.AvgPool2d(8),\n",
    "                                    nn.Flatten(),\n",
    "                                    nn.Dropout(0.25),\n",
    "                                    nn.Linear(2048, 1024),\n",
    "                                    nn.ReLU(),\n",
    "                                    nn.Dropout(0.25),\n",
    "                                    nn.Linear(1024, 91))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.layer5(x)\n",
    "        x = self.layer6(x)\n",
    "        return x\n",
    "    \n",
    "    def _make_layer(self, in_channels, mid_channels, blocks, stride=2, expansion=4):\n",
    "        layers = [Block(in_channels, mid_channels, stride, expansion)]\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(Block(mid_channels*expansion, mid_channels, expansion=expansion))\n",
    "        return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "607c9951",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 91])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(batch_size, 3, 256, 256)\n",
    "trial = ResNet()\n",
    "print(trial(x).shape)\n",
    "\n",
    "import gc\n",
    "del x\n",
    "del trial\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c602d154e795a27",
   "metadata": {},
   "source": [
    "# Training the model\n",
    "Implement your training process below. Report the test-accuracy after every epoch for the training run of the final model.\n",
    "\n",
    "Hint: before training your model make sure to reset the seed in the training cell, as otherwise the seed may have changed due to previous training runs in the notebook\n",
    "\n",
    "Note: If you implement automatic hyperparameter tuning, split the train set into train and validation subsets for the objective function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ff7d9d84c06f5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### TRAINING FUNCTIONS ###\n",
    "\n",
    "def train(model, dataloader, optimizer, loss_fn, updates):\n",
    "    \"\"\"\n",
    "    One epoch of model training.\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "\n",
    "    running_loss = 0.0\n",
    "    running_accuracy = 0.0\n",
    "\n",
    "    total_loss = 0.0\n",
    "    total_accuracy = 0.0\n",
    "    \n",
    "    for idx, data in enumerate(dataloader):\n",
    "        images, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "        # Forward propagate\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        correct = sum(labels == torch.argmax(outputs, 1)).item()\n",
    "        acc = correct/batch_size\n",
    "        running_accuracy += acc\n",
    "        total_accuracy += acc\n",
    "\n",
    "        # Back-propagate and optimize\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        running_loss += loss.item()\n",
    "        total_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Print a snapshot of the training\n",
    "        if idx % updates == (updates-1):\n",
    "            avg_loss_across_batches = running_loss / updates\n",
    "            avg_acc_across_batches = (running_accuracy / updates) * 100\n",
    "            print('Batch {}, Loss: {:.3f}, Accuracy: {:.2f}%'.format(idx+1, avg_loss_across_batches, avg_acc_across_batches))\n",
    "            running_loss = 0.0\n",
    "            running_accuracy = 0.0\n",
    "\n",
    "    avg_loss = total_loss / (idx+1)\n",
    "    avg_accuracy = (total_accuracy / (idx+1)) * 100\n",
    "\n",
    "    print('Training loss: {:.3f}, accuracy: {:.2f}%'.format(avg_loss, avg_accuracy))\n",
    "    return avg_accuracy, avg_loss\n",
    "\n",
    "\n",
    "def accuracy(model, dataloader, loss_fn):\n",
    "    \"\"\"\n",
    "    One test accuracy test, can be used for validation as well.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    running_loss = 0.0\n",
    "    running_accuracy = 0.0\n",
    "    for data in iter(dataloader):\n",
    "        images, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(images)\n",
    "            correct = sum(labels == torch.argmax(outputs, 1)).item()\n",
    "            running_accuracy += correct/batch_size\n",
    "            \n",
    "            loss = loss_fn(outputs, labels)\n",
    "            running_loss += loss.item()\n",
    "\n",
    "    avg_loss_across_batches = running_loss / len(dataloader)\n",
    "    avg_acc_across_batches = (running_accuracy / len(dataloader)) * 100\n",
    "    \n",
    "    print('Testing loss: {:.3f}, accuracy: {:.2f}%'.format(avg_loss_across_batches, avg_acc_across_batches))\n",
    "    return avg_acc_across_batches, avg_loss_across_batches\n",
    "\n",
    "\n",
    "def run_epochs(num_epochs, model, optimizer, loss_fn, scheduler=None, epoch=0, best_acc=0.0, updates=500):\n",
    "    \"\"\"\n",
    "    An entire training session.\n",
    "    \"\"\"\n",
    "    upper = epoch+num_epochs\n",
    "    train_accuracies, train_losses = [], []\n",
    "    test_accuracies, test_losses = [], []\n",
    "    \n",
    "    for epoch in range(epoch, upper):\n",
    "        # Start epoch\n",
    "        print(f\"Epoch {epoch+1} begin: {dt.now()}.\")\n",
    "        start = time()\n",
    "\n",
    "        # Train the model\n",
    "        train_acc, train_loss = train(model, train_loader, optimizer, loss_fn, updates)\n",
    "        train_accuracies.append(train_acc)\n",
    "        train_losses.append(train_loss)\n",
    "        print('Completed training after {:.2f} seconds.'.format((time() - start)))\n",
    "        check_point = time()\n",
    "\n",
    "        # Test the model\n",
    "        test_acc, test_loss = accuracy(model, test_loader, loss_fn)\n",
    "        test_accuracies.append(test_acc)\n",
    "        test_losses.append(test_loss)\n",
    "        print('Completed testing after {:.2f} seconds.'.format((time() - check_point)))\n",
    "\n",
    "        # Update learning rate\n",
    "        if scheduler is not None:\n",
    "            scheduler.step(test_loss)\n",
    "\n",
    "        # Output an update\n",
    "        print('Total epoch time: {:.2f} seconds.'.format((time() - start)))\n",
    "        print('Epoch [{}/{}]'.format(epoch+1, upper))\n",
    "        check_point = time()\n",
    "\n",
    "        # Save best model\n",
    "        if best_acc < test_acc:\n",
    "            best_acc = test_acc\n",
    "            print(\"Check-point!\")\n",
    "            torch.save(model.state_dict(), \"./checkpoint.pth\")\n",
    "        print(\"####################################################################################################\")\n",
    "    return train_accuracies, train_losses, test_accuracies, test_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde65578",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 begin: 2025-05-16 16:46:15.933258.\n",
      "Batch 285, Loss: 4.434, Accuracy: 3.06%\n",
      "Batch 570, Loss: 4.287, Accuracy: 4.80%\n",
      "Batch 855, Loss: 4.190, Accuracy: 6.40%\n",
      "Batch 1140, Loss: 4.127, Accuracy: 6.96%\n",
      "Batch 1425, Loss: 4.081, Accuracy: 7.98%\n",
      "Completed training after 249.53 seconds.\n",
      "Testing loss: 4.034, accuracy: 7.99%\n",
      "Completed testing after 47.23 seconds.\n",
      "Total epoch time: 296.77 seconds.\n",
      "Epoch [1/50]\n",
      "Check-point!\n",
      "####################################################################################################\n",
      "Epoch 2 begin: 2025-05-16 16:51:13.500746.\n",
      "Batch 285, Loss: 3.999, Accuracy: 8.77%\n",
      "Batch 570, Loss: 3.936, Accuracy: 10.00%\n",
      "Batch 855, Loss: 3.896, Accuracy: 9.84%\n",
      "Batch 1140, Loss: 3.854, Accuracy: 11.04%\n",
      "Batch 1425, Loss: 3.822, Accuracy: 11.28%\n",
      "Completed training after 250.95 seconds.\n",
      "Testing loss: 4.066, accuracy: 9.65%\n",
      "Completed testing after 48.13 seconds.\n",
      "Total epoch time: 299.08 seconds.\n",
      "Epoch [2/50]\n",
      "Check-point!\n",
      "####################################################################################################\n",
      "Epoch 3 begin: 2025-05-16 16:56:13.312397.\n",
      "Batch 285, Loss: 3.710, Accuracy: 13.07%\n",
      "Batch 570, Loss: 3.676, Accuracy: 13.84%\n",
      "Batch 855, Loss: 3.663, Accuracy: 14.29%\n",
      "Batch 1140, Loss: 3.608, Accuracy: 15.15%\n",
      "Batch 1425, Loss: 3.570, Accuracy: 15.58%\n",
      "Completed training after 251.30 seconds.\n",
      "Testing loss: 3.491, accuracy: 16.68%\n",
      "Completed testing after 47.23 seconds.\n",
      "Total epoch time: 298.53 seconds.\n",
      "Epoch [3/50]\n",
      "Check-point!\n",
      "####################################################################################################\n",
      "Epoch 4 begin: 2025-05-16 17:01:12.576769.\n",
      "Batch 285, Loss: 3.457, Accuracy: 17.52%\n",
      "Batch 570, Loss: 3.442, Accuracy: 18.18%\n",
      "Batch 855, Loss: 3.415, Accuracy: 18.77%\n",
      "Batch 1140, Loss: 3.356, Accuracy: 20.05%\n",
      "Batch 1425, Loss: 3.354, Accuracy: 19.71%\n",
      "Completed training after 247.52 seconds.\n",
      "Testing loss: 3.366, accuracy: 20.40%\n",
      "Completed testing after 47.72 seconds.\n",
      "Total epoch time: 295.24 seconds.\n",
      "Epoch [4/50]\n",
      "Check-point!\n",
      "####################################################################################################\n",
      "Epoch 5 begin: 2025-05-16 17:06:08.554998.\n",
      "Batch 285, Loss: 3.262, Accuracy: 21.47%\n",
      "Batch 570, Loss: 3.236, Accuracy: 22.14%\n",
      "Batch 855, Loss: 3.192, Accuracy: 22.99%\n",
      "Batch 1140, Loss: 3.218, Accuracy: 22.43%\n",
      "Batch 1425, Loss: 3.124, Accuracy: 24.64%\n",
      "Completed training after 249.87 seconds.\n",
      "Testing loss: 3.025, accuracy: 25.89%\n",
      "Completed testing after 47.58 seconds.\n",
      "Total epoch time: 297.44 seconds.\n",
      "Epoch [5/50]\n",
      "Check-point!\n",
      "####################################################################################################\n",
      "Epoch 6 begin: 2025-05-16 17:11:06.733067.\n",
      "Batch 285, Loss: 3.066, Accuracy: 25.64%\n",
      "Batch 570, Loss: 3.048, Accuracy: 25.09%\n",
      "Batch 855, Loss: 3.043, Accuracy: 25.82%\n",
      "Batch 1140, Loss: 2.995, Accuracy: 27.00%\n",
      "Batch 1425, Loss: 2.977, Accuracy: 27.58%\n",
      "Completed training after 247.07 seconds.\n",
      "Testing loss: 2.858, accuracy: 29.74%\n",
      "Completed testing after 47.74 seconds.\n",
      "Total epoch time: 294.82 seconds.\n",
      "Epoch [6/50]\n",
      "Check-point!\n",
      "####################################################################################################\n",
      "Epoch 7 begin: 2025-05-16 17:16:02.285063.\n",
      "Batch 285, Loss: 2.837, Accuracy: 30.23%\n",
      "Batch 570, Loss: 2.877, Accuracy: 29.42%\n",
      "Batch 855, Loss: 2.876, Accuracy: 29.36%\n",
      "Batch 1140, Loss: 2.890, Accuracy: 29.19%\n",
      "Batch 1425, Loss: 2.847, Accuracy: 29.98%\n",
      "Completed training after 248.87 seconds.\n",
      "Testing loss: 3.207, accuracy: 24.85%\n",
      "Completed testing after 47.20 seconds.\n",
      "Total epoch time: 296.08 seconds.\n",
      "Epoch [7/50]\n",
      "####################################################################################################\n",
      "Epoch 8 begin: 2025-05-16 17:20:58.360136.\n",
      "Batch 285, Loss: 2.721, Accuracy: 32.51%\n",
      "Batch 570, Loss: 2.717, Accuracy: 32.40%\n",
      "Batch 855, Loss: 2.695, Accuracy: 33.03%\n",
      "Batch 1140, Loss: 2.700, Accuracy: 32.79%\n",
      "Batch 1425, Loss: 2.723, Accuracy: 32.71%\n",
      "Completed training after 248.99 seconds.\n",
      "Testing loss: 2.630, accuracy: 34.96%\n",
      "Completed testing after 47.38 seconds.\n",
      "Total epoch time: 296.37 seconds.\n",
      "Epoch [8/50]\n",
      "Check-point!\n",
      "####################################################################################################\n",
      "Epoch 9 begin: 2025-05-16 17:25:55.464082.\n",
      "Batch 285, Loss: 2.564, Accuracy: 36.15%\n",
      "Batch 570, Loss: 2.556, Accuracy: 36.02%\n",
      "Batch 855, Loss: 2.558, Accuracy: 35.89%\n"
     ]
    }
   ],
   "source": [
    "### TRAINING ###\n",
    "\n",
    "# Allow repeatability\n",
    "np.random.seed(random_seed)\n",
    "torch.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed_all(random_seed)\n",
    "\n",
    "# Create model object and connect it to the corresponding processing\n",
    "model = ResNet([2, 3, 5, 2]).to(device)\n",
    "\n",
    "# Define loss and optimizer\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
    "scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, patience=4)\n",
    "\n",
    "# Define mental state and start\n",
    "train_accuracies, train_losses, test_accuracies, test_losses = run_epochs(num_epochs, model, optimizer, loss_fn, scheduler, updates=285)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09a27bf-239f-4caf-9d7d-bd7f2cbc3898",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training\")\n",
    "print(train_accuracies)\n",
    "print(train_losses)\n",
    "\n",
    "print(\"Testing\")\n",
    "print(test_accuracies)\n",
    "print(test_losses)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(9, 3))\n",
    "\n",
    "# Plot the training and test accuracies to showcase the divergence at overfitting\n",
    "ax1.plot(train_accuracies, label='Training')\n",
    "ax1.plot(test_accuracies, label='Testing')\n",
    "ax1.set_title('Accuracy')\n",
    "ax1.legend()\n",
    "\n",
    "# Plot the training and test losses to show the point of overfitting\n",
    "ax2.plot(train_losses, label='Training')\n",
    "ax2.plot(test_losses, label='Testing')\n",
    "ax2.set_title('Loss')\n",
    "ax2.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1c8b0bea-7537-4bcd-acd8-dc2a5b30e212",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(ResNet(\n",
       "   (layer1): Sequential(\n",
       "     (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
       "     (1): SELU()\n",
       "     (2): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "   )\n",
       "   (layer2): Sequential(\n",
       "     (0): Block(\n",
       "       (layer): Sequential(\n",
       "         (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "         (1): SELU()\n",
       "         (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "         (4): SELU()\n",
       "         (5): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "         (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       )\n",
       "       (p_layer): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "     )\n",
       "     (1): Block(\n",
       "       (layer): Sequential(\n",
       "         (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "         (1): SELU()\n",
       "         (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "         (4): SELU()\n",
       "         (5): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "         (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       )\n",
       "     )\n",
       "     (2): Block(\n",
       "       (layer): Sequential(\n",
       "         (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "         (1): SELU()\n",
       "         (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "         (4): SELU()\n",
       "         (5): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "         (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (layer3): Sequential(\n",
       "     (0): Block(\n",
       "       (layer): Sequential(\n",
       "         (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "         (1): SELU()\n",
       "         (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "         (4): SELU()\n",
       "         (5): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "         (6): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       )\n",
       "       (p_layer): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2))\n",
       "     )\n",
       "     (1): Block(\n",
       "       (layer): Sequential(\n",
       "         (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "         (1): SELU()\n",
       "         (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "         (4): SELU()\n",
       "         (5): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "         (6): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       )\n",
       "     )\n",
       "     (2): Block(\n",
       "       (layer): Sequential(\n",
       "         (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "         (1): SELU()\n",
       "         (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "         (4): SELU()\n",
       "         (5): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "         (6): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       )\n",
       "     )\n",
       "     (3): Block(\n",
       "       (layer): Sequential(\n",
       "         (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "         (1): SELU()\n",
       "         (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "         (4): SELU()\n",
       "         (5): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "         (6): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (layer4): Sequential(\n",
       "     (0): Block(\n",
       "       (layer): Sequential(\n",
       "         (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "         (1): SELU()\n",
       "         (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "         (4): SELU()\n",
       "         (5): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "         (6): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       )\n",
       "       (p_layer): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2))\n",
       "     )\n",
       "     (1): Block(\n",
       "       (layer): Sequential(\n",
       "         (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "         (1): SELU()\n",
       "         (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "         (4): SELU()\n",
       "         (5): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "         (6): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       )\n",
       "     )\n",
       "     (2): Block(\n",
       "       (layer): Sequential(\n",
       "         (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "         (1): SELU()\n",
       "         (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "         (4): SELU()\n",
       "         (5): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "         (6): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       )\n",
       "     )\n",
       "     (3): Block(\n",
       "       (layer): Sequential(\n",
       "         (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "         (1): SELU()\n",
       "         (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "         (4): SELU()\n",
       "         (5): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "         (6): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       )\n",
       "     )\n",
       "     (4): Block(\n",
       "       (layer): Sequential(\n",
       "         (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "         (1): SELU()\n",
       "         (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "         (4): SELU()\n",
       "         (5): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "         (6): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       )\n",
       "     )\n",
       "     (5): Block(\n",
       "       (layer): Sequential(\n",
       "         (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "         (1): SELU()\n",
       "         (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "         (4): SELU()\n",
       "         (5): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "         (6): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (layer5): Sequential(\n",
       "     (0): Block(\n",
       "       (layer): Sequential(\n",
       "         (0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "         (1): SELU()\n",
       "         (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "         (4): SELU()\n",
       "         (5): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
       "         (6): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       )\n",
       "       (p_layer): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2))\n",
       "     )\n",
       "     (1): Block(\n",
       "       (layer): Sequential(\n",
       "         (0): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "         (1): SELU()\n",
       "         (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "         (4): SELU()\n",
       "         (5): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
       "         (6): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       )\n",
       "     )\n",
       "     (2): Block(\n",
       "       (layer): Sequential(\n",
       "         (0): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "         (1): SELU()\n",
       "         (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "         (4): SELU()\n",
       "         (5): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
       "         (6): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (layer6): Sequential(\n",
       "     (0): AvgPool2d(kernel_size=8, stride=8, padding=0)\n",
       "     (1): Flatten(start_dim=1, end_dim=-1)\n",
       "     (2): Dropout(p=0.25, inplace=False)\n",
       "     (3): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "     (4): ReLU()\n",
       "     (5): Dropout(p=0.25, inplace=False)\n",
       "     (6): Linear(in_features=1024, out_features=91, bias=True)\n",
       "   )\n",
       " ),\n",
       " 13,\n",
       " 32,\n",
       " 0.01,\n",
       " 0.75,\n",
       " CrossEntropyLoss(),\n",
       " SGD (\n",
       " Parameter Group 0\n",
       "     dampening: 0\n",
       "     differentiable: False\n",
       "     foreach: None\n",
       "     fused: None\n",
       "     lr: 1.0000000000000004e-08\n",
       "     maximize: False\n",
       "     momentum: 0.75\n",
       "     nesterov: False\n",
       "     weight_decay: 0\n",
       " ),\n",
       " <torch.optim.lr_scheduler.ReduceLROnPlateau at 0x7fdfed909c90>)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_seed, batch_size, lr, momentum, loss_fn, optimizer, scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d580ebe-a3a0-4ebf-b92f-fd6bc8e0a635",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "16d0ace4-606a-42f2-a650-45313353acbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "807"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del model\n",
    "del loss_fn\n",
    "del optimizer\n",
    "del scheduler\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb476e18bd30968c",
   "metadata": {},
   "source": [
    "# Calculating model performance\n",
    "Load the best version of your model ( which should be produced and saved by previous cells ), calculate and report the test accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1eaa35096547d04",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for ResNet:\n\tMissing key(s) in state_dict: \"layer2.0.layer.0.weight\", \"layer2.0.layer.0.bias\", \"layer2.0.layer.2.weight\", \"layer2.0.layer.2.bias\", \"layer2.0.layer.2.running_mean\", \"layer2.0.layer.2.running_var\", \"layer2.0.layer.3.weight\", \"layer2.0.layer.3.bias\", \"layer2.0.layer.5.weight\", \"layer2.0.layer.5.bias\", \"layer2.0.layer.6.weight\", \"layer2.0.layer.6.bias\", \"layer2.0.layer.6.running_mean\", \"layer2.0.layer.6.running_var\", \"layer2.0.p_layer.weight\", \"layer2.0.p_layer.bias\", \"layer2.1.layer.0.weight\", \"layer2.1.layer.0.bias\", \"layer2.1.layer.2.weight\", \"layer2.1.layer.2.bias\", \"layer2.1.layer.2.running_mean\", \"layer2.1.layer.2.running_var\", \"layer2.1.layer.3.weight\", \"layer2.1.layer.3.bias\", \"layer2.1.layer.5.weight\", \"layer2.1.layer.5.bias\", \"layer2.1.layer.6.weight\", \"layer2.1.layer.6.bias\", \"layer2.1.layer.6.running_mean\", \"layer2.1.layer.6.running_var\", \"layer2.2.layer.0.weight\", \"layer2.2.layer.0.bias\", \"layer2.2.layer.2.weight\", \"layer2.2.layer.2.bias\", \"layer2.2.layer.2.running_mean\", \"layer2.2.layer.2.running_var\", \"layer2.2.layer.3.weight\", \"layer2.2.layer.3.bias\", \"layer2.2.layer.5.weight\", \"layer2.2.layer.5.bias\", \"layer2.2.layer.6.weight\", \"layer2.2.layer.6.bias\", \"layer2.2.layer.6.running_mean\", \"layer2.2.layer.6.running_var\", \"layer3.0.layer.0.weight\", \"layer3.0.layer.0.bias\", \"layer3.0.layer.2.weight\", \"layer3.0.layer.2.bias\", \"layer3.0.layer.2.running_mean\", \"layer3.0.layer.2.running_var\", \"layer3.0.layer.3.weight\", \"layer3.0.layer.3.bias\", \"layer3.0.layer.5.weight\", \"layer3.0.layer.5.bias\", \"layer3.0.layer.6.weight\", \"layer3.0.layer.6.bias\", \"layer3.0.layer.6.running_mean\", \"layer3.0.layer.6.running_var\", \"layer3.1.layer.0.weight\", \"layer3.1.layer.0.bias\", \"layer3.1.layer.2.weight\", \"layer3.1.layer.2.bias\", \"layer3.1.layer.2.running_mean\", \"layer3.1.layer.2.running_var\", \"layer3.1.layer.3.weight\", \"layer3.1.layer.3.bias\", \"layer3.1.layer.5.weight\", \"layer3.1.layer.5.bias\", \"layer3.1.layer.6.weight\", \"layer3.1.layer.6.bias\", \"layer3.1.layer.6.running_mean\", \"layer3.1.layer.6.running_var\", \"layer3.2.layer.0.weight\", \"layer3.2.layer.0.bias\", \"layer3.2.layer.2.weight\", \"layer3.2.layer.2.bias\", \"layer3.2.layer.2.running_mean\", \"layer3.2.layer.2.running_var\", \"layer3.2.layer.3.weight\", \"layer3.2.layer.3.bias\", \"layer3.2.layer.5.weight\", \"layer3.2.layer.5.bias\", \"layer3.2.layer.6.weight\", \"layer3.2.layer.6.bias\", \"layer3.2.layer.6.running_mean\", \"layer3.2.layer.6.running_var\", \"layer3.3.layer.0.weight\", \"layer3.3.layer.0.bias\", \"layer3.3.layer.2.weight\", \"layer3.3.layer.2.bias\", \"layer3.3.layer.2.running_mean\", \"layer3.3.layer.2.running_var\", \"layer3.3.layer.3.weight\", \"layer3.3.layer.3.bias\", \"layer3.3.layer.5.weight\", \"layer3.3.layer.5.bias\", \"layer3.3.layer.6.weight\", \"layer3.3.layer.6.bias\", \"layer3.3.layer.6.running_mean\", \"layer3.3.layer.6.running_var\", \"layer4.0.layer.0.weight\", \"layer4.0.layer.0.bias\", \"layer4.0.layer.2.weight\", \"layer4.0.layer.2.bias\", \"layer4.0.layer.2.running_mean\", \"layer4.0.layer.2.running_var\", \"layer4.0.layer.3.weight\", \"layer4.0.layer.3.bias\", \"layer4.0.layer.5.weight\", \"layer4.0.layer.5.bias\", \"layer4.0.layer.6.weight\", \"layer4.0.layer.6.bias\", \"layer4.0.layer.6.running_mean\", \"layer4.0.layer.6.running_var\", \"layer4.1.layer.0.weight\", \"layer4.1.layer.0.bias\", \"layer4.1.layer.2.weight\", \"layer4.1.layer.2.bias\", \"layer4.1.layer.2.running_mean\", \"layer4.1.layer.2.running_var\", \"layer4.1.layer.3.weight\", \"layer4.1.layer.3.bias\", \"layer4.1.layer.5.weight\", \"layer4.1.layer.5.bias\", \"layer4.1.layer.6.weight\", \"layer4.1.layer.6.bias\", \"layer4.1.layer.6.running_mean\", \"layer4.1.layer.6.running_var\", \"layer4.2.layer.0.weight\", \"layer4.2.layer.0.bias\", \"layer4.2.layer.2.weight\", \"layer4.2.layer.2.bias\", \"layer4.2.layer.2.running_mean\", \"layer4.2.layer.2.running_var\", \"layer4.2.layer.3.weight\", \"layer4.2.layer.3.bias\", \"layer4.2.layer.5.weight\", \"layer4.2.layer.5.bias\", \"layer4.2.layer.6.weight\", \"layer4.2.layer.6.bias\", \"layer4.2.layer.6.running_mean\", \"layer4.2.layer.6.running_var\", \"layer4.3.layer.0.weight\", \"layer4.3.layer.0.bias\", \"layer4.3.layer.2.weight\", \"layer4.3.layer.2.bias\", \"layer4.3.layer.2.running_mean\", \"layer4.3.layer.2.running_var\", \"layer4.3.layer.3.weight\", \"layer4.3.layer.3.bias\", \"layer4.3.layer.5.weight\", \"layer4.3.layer.5.bias\", \"layer4.3.layer.6.weight\", \"layer4.3.layer.6.bias\", \"layer4.3.layer.6.running_mean\", \"layer4.3.layer.6.running_var\", \"layer4.4.layer.0.weight\", \"layer4.4.layer.0.bias\", \"layer4.4.layer.2.weight\", \"layer4.4.layer.2.bias\", \"layer4.4.layer.2.running_mean\", \"layer4.4.layer.2.running_var\", \"layer4.4.layer.3.weight\", \"layer4.4.layer.3.bias\", \"layer4.4.layer.5.weight\", \"layer4.4.layer.5.bias\", \"layer4.4.layer.6.weight\", \"layer4.4.layer.6.bias\", \"layer4.4.layer.6.running_mean\", \"layer4.4.layer.6.running_var\", \"layer4.5.layer.0.weight\", \"layer4.5.layer.0.bias\", \"layer4.5.layer.2.weight\", \"layer4.5.layer.2.bias\", \"layer4.5.layer.2.running_mean\", \"layer4.5.layer.2.running_var\", \"layer4.5.layer.3.weight\", \"layer4.5.layer.3.bias\", \"layer4.5.layer.5.weight\", \"layer4.5.layer.5.bias\", \"layer4.5.layer.6.weight\", \"layer4.5.layer.6.bias\", \"layer4.5.layer.6.running_mean\", \"layer4.5.layer.6.running_var\", \"layer5.0.layer.0.weight\", \"layer5.0.layer.0.bias\", \"layer5.0.layer.2.weight\", \"layer5.0.layer.2.bias\", \"layer5.0.layer.2.running_mean\", \"layer5.0.layer.2.running_var\", \"layer5.0.layer.3.weight\", \"layer5.0.layer.3.bias\", \"layer5.0.layer.5.weight\", \"layer5.0.layer.5.bias\", \"layer5.0.layer.6.weight\", \"layer5.0.layer.6.bias\", \"layer5.0.layer.6.running_mean\", \"layer5.0.layer.6.running_var\", \"layer5.1.layer.0.weight\", \"layer5.1.layer.0.bias\", \"layer5.1.layer.2.weight\", \"layer5.1.layer.2.bias\", \"layer5.1.layer.2.running_mean\", \"layer5.1.layer.2.running_var\", \"layer5.1.layer.3.weight\", \"layer5.1.layer.3.bias\", \"layer5.1.layer.5.weight\", \"layer5.1.layer.5.bias\", \"layer5.1.layer.6.weight\", \"layer5.1.layer.6.bias\", \"layer5.1.layer.6.running_mean\", \"layer5.1.layer.6.running_var\", \"layer5.2.layer.0.weight\", \"layer5.2.layer.0.bias\", \"layer5.2.layer.2.weight\", \"layer5.2.layer.2.bias\", \"layer5.2.layer.2.running_mean\", \"layer5.2.layer.2.running_var\", \"layer5.2.layer.3.weight\", \"layer5.2.layer.3.bias\", \"layer5.2.layer.5.weight\", \"layer5.2.layer.5.bias\", \"layer5.2.layer.6.weight\", \"layer5.2.layer.6.bias\", \"layer5.2.layer.6.running_mean\", \"layer5.2.layer.6.running_var\", \"layer6.6.weight\", \"layer6.6.bias\". \n\tUnexpected key(s) in state_dict: \"layer1.2.weight\", \"layer1.2.bias\", \"layer1.2.running_mean\", \"layer1.2.running_var\", \"layer1.2.num_batches_tracked\", \"layer2.0.layer1.0.weight\", \"layer2.0.layer1.0.bias\", \"layer2.0.layer1.1.weight\", \"layer2.0.layer1.1.bias\", \"layer2.0.layer1.1.running_mean\", \"layer2.0.layer1.1.running_var\", \"layer2.0.layer1.1.num_batches_tracked\", \"layer2.0.layer2.0.weight\", \"layer2.0.layer2.0.bias\", \"layer2.0.layer2.1.weight\", \"layer2.0.layer2.1.bias\", \"layer2.0.layer2.1.running_mean\", \"layer2.0.layer2.1.running_var\", \"layer2.0.layer2.1.num_batches_tracked\", \"layer2.1.layer1.0.weight\", \"layer2.1.layer1.0.bias\", \"layer2.1.layer1.1.weight\", \"layer2.1.layer1.1.bias\", \"layer2.1.layer1.1.running_mean\", \"layer2.1.layer1.1.running_var\", \"layer2.1.layer1.1.num_batches_tracked\", \"layer2.1.layer2.0.weight\", \"layer2.1.layer2.0.bias\", \"layer2.1.layer2.1.weight\", \"layer2.1.layer2.1.bias\", \"layer2.1.layer2.1.running_mean\", \"layer2.1.layer2.1.running_var\", \"layer2.1.layer2.1.num_batches_tracked\", \"layer2.2.layer1.0.weight\", \"layer2.2.layer1.0.bias\", \"layer2.2.layer1.1.weight\", \"layer2.2.layer1.1.bias\", \"layer2.2.layer1.1.running_mean\", \"layer2.2.layer1.1.running_var\", \"layer2.2.layer1.1.num_batches_tracked\", \"layer2.2.layer2.0.weight\", \"layer2.2.layer2.0.bias\", \"layer2.2.layer2.1.weight\", \"layer2.2.layer2.1.bias\", \"layer2.2.layer2.1.running_mean\", \"layer2.2.layer2.1.running_var\", \"layer2.2.layer2.1.num_batches_tracked\", \"layer3.0.layer1.0.weight\", \"layer3.0.layer1.0.bias\", \"layer3.0.layer1.1.weight\", \"layer3.0.layer1.1.bias\", \"layer3.0.layer1.1.running_mean\", \"layer3.0.layer1.1.running_var\", \"layer3.0.layer1.1.num_batches_tracked\", \"layer3.0.layer2.0.weight\", \"layer3.0.layer2.0.bias\", \"layer3.0.layer2.1.weight\", \"layer3.0.layer2.1.bias\", \"layer3.0.layer2.1.running_mean\", \"layer3.0.layer2.1.running_var\", \"layer3.0.layer2.1.num_batches_tracked\", \"layer3.1.layer1.0.weight\", \"layer3.1.layer1.0.bias\", \"layer3.1.layer1.1.weight\", \"layer3.1.layer1.1.bias\", \"layer3.1.layer1.1.running_mean\", \"layer3.1.layer1.1.running_var\", \"layer3.1.layer1.1.num_batches_tracked\", \"layer3.1.layer2.0.weight\", \"layer3.1.layer2.0.bias\", \"layer3.1.layer2.1.weight\", \"layer3.1.layer2.1.bias\", \"layer3.1.layer2.1.running_mean\", \"layer3.1.layer2.1.running_var\", \"layer3.1.layer2.1.num_batches_tracked\", \"layer3.2.layer1.0.weight\", \"layer3.2.layer1.0.bias\", \"layer3.2.layer1.1.weight\", \"layer3.2.layer1.1.bias\", \"layer3.2.layer1.1.running_mean\", \"layer3.2.layer1.1.running_var\", \"layer3.2.layer1.1.num_batches_tracked\", \"layer3.2.layer2.0.weight\", \"layer3.2.layer2.0.bias\", \"layer3.2.layer2.1.weight\", \"layer3.2.layer2.1.bias\", \"layer3.2.layer2.1.running_mean\", \"layer3.2.layer2.1.running_var\", \"layer3.2.layer2.1.num_batches_tracked\", \"layer3.3.layer1.0.weight\", \"layer3.3.layer1.0.bias\", \"layer3.3.layer1.1.weight\", \"layer3.3.layer1.1.bias\", \"layer3.3.layer1.1.running_mean\", \"layer3.3.layer1.1.running_var\", \"layer3.3.layer1.1.num_batches_tracked\", \"layer3.3.layer2.0.weight\", \"layer3.3.layer2.0.bias\", \"layer3.3.layer2.1.weight\", \"layer3.3.layer2.1.bias\", \"layer3.3.layer2.1.running_mean\", \"layer3.3.layer2.1.running_var\", \"layer3.3.layer2.1.num_batches_tracked\", \"layer4.0.layer1.0.weight\", \"layer4.0.layer1.0.bias\", \"layer4.0.layer1.1.weight\", \"layer4.0.layer1.1.bias\", \"layer4.0.layer1.1.running_mean\", \"layer4.0.layer1.1.running_var\", \"layer4.0.layer1.1.num_batches_tracked\", \"layer4.0.layer2.0.weight\", \"layer4.0.layer2.0.bias\", \"layer4.0.layer2.1.weight\", \"layer4.0.layer2.1.bias\", \"layer4.0.layer2.1.running_mean\", \"layer4.0.layer2.1.running_var\", \"layer4.0.layer2.1.num_batches_tracked\", \"layer4.1.layer1.0.weight\", \"layer4.1.layer1.0.bias\", \"layer4.1.layer1.1.weight\", \"layer4.1.layer1.1.bias\", \"layer4.1.layer1.1.running_mean\", \"layer4.1.layer1.1.running_var\", \"layer4.1.layer1.1.num_batches_tracked\", \"layer4.1.layer2.0.weight\", \"layer4.1.layer2.0.bias\", \"layer4.1.layer2.1.weight\", \"layer4.1.layer2.1.bias\", \"layer4.1.layer2.1.running_mean\", \"layer4.1.layer2.1.running_var\", \"layer4.1.layer2.1.num_batches_tracked\", \"layer4.2.layer1.0.weight\", \"layer4.2.layer1.0.bias\", \"layer4.2.layer1.1.weight\", \"layer4.2.layer1.1.bias\", \"layer4.2.layer1.1.running_mean\", \"layer4.2.layer1.1.running_var\", \"layer4.2.layer1.1.num_batches_tracked\", \"layer4.2.layer2.0.weight\", \"layer4.2.layer2.0.bias\", \"layer4.2.layer2.1.weight\", \"layer4.2.layer2.1.bias\", \"layer4.2.layer2.1.running_mean\", \"layer4.2.layer2.1.running_var\", \"layer4.2.layer2.1.num_batches_tracked\", \"layer4.3.layer1.0.weight\", \"layer4.3.layer1.0.bias\", \"layer4.3.layer1.1.weight\", \"layer4.3.layer1.1.bias\", \"layer4.3.layer1.1.running_mean\", \"layer4.3.layer1.1.running_var\", \"layer4.3.layer1.1.num_batches_tracked\", \"layer4.3.layer2.0.weight\", \"layer4.3.layer2.0.bias\", \"layer4.3.layer2.1.weight\", \"layer4.3.layer2.1.bias\", \"layer4.3.layer2.1.running_mean\", \"layer4.3.layer2.1.running_var\", \"layer4.3.layer2.1.num_batches_tracked\", \"layer4.4.layer1.0.weight\", \"layer4.4.layer1.0.bias\", \"layer4.4.layer1.1.weight\", \"layer4.4.layer1.1.bias\", \"layer4.4.layer1.1.running_mean\", \"layer4.4.layer1.1.running_var\", \"layer4.4.layer1.1.num_batches_tracked\", \"layer4.4.layer2.0.weight\", \"layer4.4.layer2.0.bias\", \"layer4.4.layer2.1.weight\", \"layer4.4.layer2.1.bias\", \"layer4.4.layer2.1.running_mean\", \"layer4.4.layer2.1.running_var\", \"layer4.4.layer2.1.num_batches_tracked\", \"layer4.5.layer1.0.weight\", \"layer4.5.layer1.0.bias\", \"layer4.5.layer1.1.weight\", \"layer4.5.layer1.1.bias\", \"layer4.5.layer1.1.running_mean\", \"layer4.5.layer1.1.running_var\", \"layer4.5.layer1.1.num_batches_tracked\", \"layer4.5.layer2.0.weight\", \"layer4.5.layer2.0.bias\", \"layer4.5.layer2.1.weight\", \"layer4.5.layer2.1.bias\", \"layer4.5.layer2.1.running_mean\", \"layer4.5.layer2.1.running_var\", \"layer4.5.layer2.1.num_batches_tracked\", \"layer5.0.layer1.0.weight\", \"layer5.0.layer1.0.bias\", \"layer5.0.layer1.1.weight\", \"layer5.0.layer1.1.bias\", \"layer5.0.layer1.1.running_mean\", \"layer5.0.layer1.1.running_var\", \"layer5.0.layer1.1.num_batches_tracked\", \"layer5.0.layer2.0.weight\", \"layer5.0.layer2.0.bias\", \"layer5.0.layer2.1.weight\", \"layer5.0.layer2.1.bias\", \"layer5.0.layer2.1.running_mean\", \"layer5.0.layer2.1.running_var\", \"layer5.0.layer2.1.num_batches_tracked\", \"layer5.1.layer1.0.weight\", \"layer5.1.layer1.0.bias\", \"layer5.1.layer1.1.weight\", \"layer5.1.layer1.1.bias\", \"layer5.1.layer1.1.running_mean\", \"layer5.1.layer1.1.running_var\", \"layer5.1.layer1.1.num_batches_tracked\", \"layer5.1.layer2.0.weight\", \"layer5.1.layer2.0.bias\", \"layer5.1.layer2.1.weight\", \"layer5.1.layer2.1.bias\", \"layer5.1.layer2.1.running_mean\", \"layer5.1.layer2.1.running_var\", \"layer5.1.layer2.1.num_batches_tracked\", \"layer5.2.layer1.0.weight\", \"layer5.2.layer1.0.bias\", \"layer5.2.layer1.1.weight\", \"layer5.2.layer1.1.bias\", \"layer5.2.layer1.1.running_mean\", \"layer5.2.layer1.1.running_var\", \"layer5.2.layer1.1.num_batches_tracked\", \"layer5.2.layer2.0.weight\", \"layer5.2.layer2.0.bias\", \"layer5.2.layer2.1.weight\", \"layer5.2.layer2.1.bias\", \"layer5.2.layer2.1.running_mean\", \"layer5.2.layer2.1.running_var\", \"layer5.2.layer2.1.num_batches_tracked\". \n\tsize mismatch for layer3.0.p_layer.weight: copying a param with shape torch.Size([128, 64, 1, 1]) from checkpoint, the shape in current model is torch.Size([512, 256, 1, 1]).\n\tsize mismatch for layer3.0.p_layer.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for layer4.0.p_layer.weight: copying a param with shape torch.Size([256, 128, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 512, 1, 1]).\n\tsize mismatch for layer4.0.p_layer.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for layer5.0.p_layer.weight: copying a param with shape torch.Size([512, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([2048, 1024, 1, 1]).\n\tsize mismatch for layer5.0.p_layer.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for layer6.3.weight: copying a param with shape torch.Size([91, 512]) from checkpoint, the shape in current model is torch.Size([1024, 2048]).\n\tsize mismatch for layer6.3.bias: copying a param with shape torch.Size([91]) from checkpoint, the shape in current model is torch.Size([1024]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[51], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m### MODEL COMPARISONS ###\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Load the best model weights\u001b[39;00m\n\u001b[1;32m      4\u001b[0m model2 \u001b[38;5;241m=\u001b[39m ResNet()\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m----> 5\u001b[0m \u001b[43mmodel2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcheckpoint.pth\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Calculate and present final scores\u001b[39;00m\n\u001b[1;32m      8\u001b[0m final_test_acc \u001b[38;5;241m=\u001b[39m accuracy(model2, test_loader)\n",
      "File \u001b[0;32m~/Desktop/Neural Computing/Py1/lib/python3.10/site-packages/torch/nn/modules/module.py:2593\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2585\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[1;32m   2586\u001b[0m             \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m   2587\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2588\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)\n\u001b[1;32m   2589\u001b[0m             ),\n\u001b[1;32m   2590\u001b[0m         )\n\u001b[1;32m   2592\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 2593\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   2594\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2595\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)\n\u001b[1;32m   2596\u001b[0m         )\n\u001b[1;32m   2597\u001b[0m     )\n\u001b[1;32m   2598\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for ResNet:\n\tMissing key(s) in state_dict: \"layer2.0.layer.0.weight\", \"layer2.0.layer.0.bias\", \"layer2.0.layer.2.weight\", \"layer2.0.layer.2.bias\", \"layer2.0.layer.2.running_mean\", \"layer2.0.layer.2.running_var\", \"layer2.0.layer.3.weight\", \"layer2.0.layer.3.bias\", \"layer2.0.layer.5.weight\", \"layer2.0.layer.5.bias\", \"layer2.0.layer.6.weight\", \"layer2.0.layer.6.bias\", \"layer2.0.layer.6.running_mean\", \"layer2.0.layer.6.running_var\", \"layer2.0.p_layer.weight\", \"layer2.0.p_layer.bias\", \"layer2.1.layer.0.weight\", \"layer2.1.layer.0.bias\", \"layer2.1.layer.2.weight\", \"layer2.1.layer.2.bias\", \"layer2.1.layer.2.running_mean\", \"layer2.1.layer.2.running_var\", \"layer2.1.layer.3.weight\", \"layer2.1.layer.3.bias\", \"layer2.1.layer.5.weight\", \"layer2.1.layer.5.bias\", \"layer2.1.layer.6.weight\", \"layer2.1.layer.6.bias\", \"layer2.1.layer.6.running_mean\", \"layer2.1.layer.6.running_var\", \"layer2.2.layer.0.weight\", \"layer2.2.layer.0.bias\", \"layer2.2.layer.2.weight\", \"layer2.2.layer.2.bias\", \"layer2.2.layer.2.running_mean\", \"layer2.2.layer.2.running_var\", \"layer2.2.layer.3.weight\", \"layer2.2.layer.3.bias\", \"layer2.2.layer.5.weight\", \"layer2.2.layer.5.bias\", \"layer2.2.layer.6.weight\", \"layer2.2.layer.6.bias\", \"layer2.2.layer.6.running_mean\", \"layer2.2.layer.6.running_var\", \"layer3.0.layer.0.weight\", \"layer3.0.layer.0.bias\", \"layer3.0.layer.2.weight\", \"layer3.0.layer.2.bias\", \"layer3.0.layer.2.running_mean\", \"layer3.0.layer.2.running_var\", \"layer3.0.layer.3.weight\", \"layer3.0.layer.3.bias\", \"layer3.0.layer.5.weight\", \"layer3.0.layer.5.bias\", \"layer3.0.layer.6.weight\", \"layer3.0.layer.6.bias\", \"layer3.0.layer.6.running_mean\", \"layer3.0.layer.6.running_var\", \"layer3.1.layer.0.weight\", \"layer3.1.layer.0.bias\", \"layer3.1.layer.2.weight\", \"layer3.1.layer.2.bias\", \"layer3.1.layer.2.running_mean\", \"layer3.1.layer.2.running_var\", \"layer3.1.layer.3.weight\", \"layer3.1.layer.3.bias\", \"layer3.1.layer.5.weight\", \"layer3.1.layer.5.bias\", \"layer3.1.layer.6.weight\", \"layer3.1.layer.6.bias\", \"layer3.1.layer.6.running_mean\", \"layer3.1.layer.6.running_var\", \"layer3.2.layer.0.weight\", \"layer3.2.layer.0.bias\", \"layer3.2.layer.2.weight\", \"layer3.2.layer.2.bias\", \"layer3.2.layer.2.running_mean\", \"layer3.2.layer.2.running_var\", \"layer3.2.layer.3.weight\", \"layer3.2.layer.3.bias\", \"layer3.2.layer.5.weight\", \"layer3.2.layer.5.bias\", \"layer3.2.layer.6.weight\", \"layer3.2.layer.6.bias\", \"layer3.2.layer.6.running_mean\", \"layer3.2.layer.6.running_var\", \"layer3.3.layer.0.weight\", \"layer3.3.layer.0.bias\", \"layer3.3.layer.2.weight\", \"layer3.3.layer.2.bias\", \"layer3.3.layer.2.running_mean\", \"layer3.3.layer.2.running_var\", \"layer3.3.layer.3.weight\", \"layer3.3.layer.3.bias\", \"layer3.3.layer.5.weight\", \"layer3.3.layer.5.bias\", \"layer3.3.layer.6.weight\", \"layer3.3.layer.6.bias\", \"layer3.3.layer.6.running_mean\", \"layer3.3.layer.6.running_var\", \"layer4.0.layer.0.weight\", \"layer4.0.layer.0.bias\", \"layer4.0.layer.2.weight\", \"layer4.0.layer.2.bias\", \"layer4.0.layer.2.running_mean\", \"layer4.0.layer.2.running_var\", \"layer4.0.layer.3.weight\", \"layer4.0.layer.3.bias\", \"layer4.0.layer.5.weight\", \"layer4.0.layer.5.bias\", \"layer4.0.layer.6.weight\", \"layer4.0.layer.6.bias\", \"layer4.0.layer.6.running_mean\", \"layer4.0.layer.6.running_var\", \"layer4.1.layer.0.weight\", \"layer4.1.layer.0.bias\", \"layer4.1.layer.2.weight\", \"layer4.1.layer.2.bias\", \"layer4.1.layer.2.running_mean\", \"layer4.1.layer.2.running_var\", \"layer4.1.layer.3.weight\", \"layer4.1.layer.3.bias\", \"layer4.1.layer.5.weight\", \"layer4.1.layer.5.bias\", \"layer4.1.layer.6.weight\", \"layer4.1.layer.6.bias\", \"layer4.1.layer.6.running_mean\", \"layer4.1.layer.6.running_var\", \"layer4.2.layer.0.weight\", \"layer4.2.layer.0.bias\", \"layer4.2.layer.2.weight\", \"layer4.2.layer.2.bias\", \"layer4.2.layer.2.running_mean\", \"layer4.2.layer.2.running_var\", \"layer4.2.layer.3.weight\", \"layer4.2.layer.3.bias\", \"layer4.2.layer.5.weight\", \"layer4.2.layer.5.bias\", \"layer4.2.layer.6.weight\", \"layer4.2.layer.6.bias\", \"layer4.2.layer.6.running_mean\", \"layer4.2.layer.6.running_var\", \"layer4.3.layer.0.weight\", \"layer4.3.layer.0.bias\", \"layer4.3.layer.2.weight\", \"layer4.3.layer.2.bias\", \"layer4.3.layer.2.running_mean\", \"layer4.3.layer.2.running_var\", \"layer4.3.layer.3.weight\", \"layer4.3.layer.3.bias\", \"layer4.3.layer.5.weight\", \"layer4.3.layer.5.bias\", \"layer4.3.layer.6.weight\", \"layer4.3.layer.6.bias\", \"layer4.3.layer.6.running_mean\", \"layer4.3.layer.6.running_var\", \"layer4.4.layer.0.weight\", \"layer4.4.layer.0.bias\", \"layer4.4.layer.2.weight\", \"layer4.4.layer.2.bias\", \"layer4.4.layer.2.running_mean\", \"layer4.4.layer.2.running_var\", \"layer4.4.layer.3.weight\", \"layer4.4.layer.3.bias\", \"layer4.4.layer.5.weight\", \"layer4.4.layer.5.bias\", \"layer4.4.layer.6.weight\", \"layer4.4.layer.6.bias\", \"layer4.4.layer.6.running_mean\", \"layer4.4.layer.6.running_var\", \"layer4.5.layer.0.weight\", \"layer4.5.layer.0.bias\", \"layer4.5.layer.2.weight\", \"layer4.5.layer.2.bias\", \"layer4.5.layer.2.running_mean\", \"layer4.5.layer.2.running_var\", \"layer4.5.layer.3.weight\", \"layer4.5.layer.3.bias\", \"layer4.5.layer.5.weight\", \"layer4.5.layer.5.bias\", \"layer4.5.layer.6.weight\", \"layer4.5.layer.6.bias\", \"layer4.5.layer.6.running_mean\", \"layer4.5.layer.6.running_var\", \"layer5.0.layer.0.weight\", \"layer5.0.layer.0.bias\", \"layer5.0.layer.2.weight\", \"layer5.0.layer.2.bias\", \"layer5.0.layer.2.running_mean\", \"layer5.0.layer.2.running_var\", \"layer5.0.layer.3.weight\", \"layer5.0.layer.3.bias\", \"layer5.0.layer.5.weight\", \"layer5.0.layer.5.bias\", \"layer5.0.layer.6.weight\", \"layer5.0.layer.6.bias\", \"layer5.0.layer.6.running_mean\", \"layer5.0.layer.6.running_var\", \"layer5.1.layer.0.weight\", \"layer5.1.layer.0.bias\", \"layer5.1.layer.2.weight\", \"layer5.1.layer.2.bias\", \"layer5.1.layer.2.running_mean\", \"layer5.1.layer.2.running_var\", \"layer5.1.layer.3.weight\", \"layer5.1.layer.3.bias\", \"layer5.1.layer.5.weight\", \"layer5.1.layer.5.bias\", \"layer5.1.layer.6.weight\", \"layer5.1.layer.6.bias\", \"layer5.1.layer.6.running_mean\", \"layer5.1.layer.6.running_var\", \"layer5.2.layer.0.weight\", \"layer5.2.layer.0.bias\", \"layer5.2.layer.2.weight\", \"layer5.2.layer.2.bias\", \"layer5.2.layer.2.running_mean\", \"layer5.2.layer.2.running_var\", \"layer5.2.layer.3.weight\", \"layer5.2.layer.3.bias\", \"layer5.2.layer.5.weight\", \"layer5.2.layer.5.bias\", \"layer5.2.layer.6.weight\", \"layer5.2.layer.6.bias\", \"layer5.2.layer.6.running_mean\", \"layer5.2.layer.6.running_var\", \"layer6.6.weight\", \"layer6.6.bias\". \n\tUnexpected key(s) in state_dict: \"layer1.2.weight\", \"layer1.2.bias\", \"layer1.2.running_mean\", \"layer1.2.running_var\", \"layer1.2.num_batches_tracked\", \"layer2.0.layer1.0.weight\", \"layer2.0.layer1.0.bias\", \"layer2.0.layer1.1.weight\", \"layer2.0.layer1.1.bias\", \"layer2.0.layer1.1.running_mean\", \"layer2.0.layer1.1.running_var\", \"layer2.0.layer1.1.num_batches_tracked\", \"layer2.0.layer2.0.weight\", \"layer2.0.layer2.0.bias\", \"layer2.0.layer2.1.weight\", \"layer2.0.layer2.1.bias\", \"layer2.0.layer2.1.running_mean\", \"layer2.0.layer2.1.running_var\", \"layer2.0.layer2.1.num_batches_tracked\", \"layer2.1.layer1.0.weight\", \"layer2.1.layer1.0.bias\", \"layer2.1.layer1.1.weight\", \"layer2.1.layer1.1.bias\", \"layer2.1.layer1.1.running_mean\", \"layer2.1.layer1.1.running_var\", \"layer2.1.layer1.1.num_batches_tracked\", \"layer2.1.layer2.0.weight\", \"layer2.1.layer2.0.bias\", \"layer2.1.layer2.1.weight\", \"layer2.1.layer2.1.bias\", \"layer2.1.layer2.1.running_mean\", \"layer2.1.layer2.1.running_var\", \"layer2.1.layer2.1.num_batches_tracked\", \"layer2.2.layer1.0.weight\", \"layer2.2.layer1.0.bias\", \"layer2.2.layer1.1.weight\", \"layer2.2.layer1.1.bias\", \"layer2.2.layer1.1.running_mean\", \"layer2.2.layer1.1.running_var\", \"layer2.2.layer1.1.num_batches_tracked\", \"layer2.2.layer2.0.weight\", \"layer2.2.layer2.0.bias\", \"layer2.2.layer2.1.weight\", \"layer2.2.layer2.1.bias\", \"layer2.2.layer2.1.running_mean\", \"layer2.2.layer2.1.running_var\", \"layer2.2.layer2.1.num_batches_tracked\", \"layer3.0.layer1.0.weight\", \"layer3.0.layer1.0.bias\", \"layer3.0.layer1.1.weight\", \"layer3.0.layer1.1.bias\", \"layer3.0.layer1.1.running_mean\", \"layer3.0.layer1.1.running_var\", \"layer3.0.layer1.1.num_batches_tracked\", \"layer3.0.layer2.0.weight\", \"layer3.0.layer2.0.bias\", \"layer3.0.layer2.1.weight\", \"layer3.0.layer2.1.bias\", \"layer3.0.layer2.1.running_mean\", \"layer3.0.layer2.1.running_var\", \"layer3.0.layer2.1.num_batches_tracked\", \"layer3.1.layer1.0.weight\", \"layer3.1.layer1.0.bias\", \"layer3.1.layer1.1.weight\", \"layer3.1.layer1.1.bias\", \"layer3.1.layer1.1.running_mean\", \"layer3.1.layer1.1.running_var\", \"layer3.1.layer1.1.num_batches_tracked\", \"layer3.1.layer2.0.weight\", \"layer3.1.layer2.0.bias\", \"layer3.1.layer2.1.weight\", \"layer3.1.layer2.1.bias\", \"layer3.1.layer2.1.running_mean\", \"layer3.1.layer2.1.running_var\", \"layer3.1.layer2.1.num_batches_tracked\", \"layer3.2.layer1.0.weight\", \"layer3.2.layer1.0.bias\", \"layer3.2.layer1.1.weight\", \"layer3.2.layer1.1.bias\", \"layer3.2.layer1.1.running_mean\", \"layer3.2.layer1.1.running_var\", \"layer3.2.layer1.1.num_batches_tracked\", \"layer3.2.layer2.0.weight\", \"layer3.2.layer2.0.bias\", \"layer3.2.layer2.1.weight\", \"layer3.2.layer2.1.bias\", \"layer3.2.layer2.1.running_mean\", \"layer3.2.layer2.1.running_var\", \"layer3.2.layer2.1.num_batches_tracked\", \"layer3.3.layer1.0.weight\", \"layer3.3.layer1.0.bias\", \"layer3.3.layer1.1.weight\", \"layer3.3.layer1.1.bias\", \"layer3.3.layer1.1.running_mean\", \"layer3.3.layer1.1.running_var\", \"layer3.3.layer1.1.num_batches_tracked\", \"layer3.3.layer2.0.weight\", \"layer3.3.layer2.0.bias\", \"layer3.3.layer2.1.weight\", \"layer3.3.layer2.1.bias\", \"layer3.3.layer2.1.running_mean\", \"layer3.3.layer2.1.running_var\", \"layer3.3.layer2.1.num_batches_tracked\", \"layer4.0.layer1.0.weight\", \"layer4.0.layer1.0.bias\", \"layer4.0.layer1.1.weight\", \"layer4.0.layer1.1.bias\", \"layer4.0.layer1.1.running_mean\", \"layer4.0.layer1.1.running_var\", \"layer4.0.layer1.1.num_batches_tracked\", \"layer4.0.layer2.0.weight\", \"layer4.0.layer2.0.bias\", \"layer4.0.layer2.1.weight\", \"layer4.0.layer2.1.bias\", \"layer4.0.layer2.1.running_mean\", \"layer4.0.layer2.1.running_var\", \"layer4.0.layer2.1.num_batches_tracked\", \"layer4.1.layer1.0.weight\", \"layer4.1.layer1.0.bias\", \"layer4.1.layer1.1.weight\", \"layer4.1.layer1.1.bias\", \"layer4.1.layer1.1.running_mean\", \"layer4.1.layer1.1.running_var\", \"layer4.1.layer1.1.num_batches_tracked\", \"layer4.1.layer2.0.weight\", \"layer4.1.layer2.0.bias\", \"layer4.1.layer2.1.weight\", \"layer4.1.layer2.1.bias\", \"layer4.1.layer2.1.running_mean\", \"layer4.1.layer2.1.running_var\", \"layer4.1.layer2.1.num_batches_tracked\", \"layer4.2.layer1.0.weight\", \"layer4.2.layer1.0.bias\", \"layer4.2.layer1.1.weight\", \"layer4.2.layer1.1.bias\", \"layer4.2.layer1.1.running_mean\", \"layer4.2.layer1.1.running_var\", \"layer4.2.layer1.1.num_batches_tracked\", \"layer4.2.layer2.0.weight\", \"layer4.2.layer2.0.bias\", \"layer4.2.layer2.1.weight\", \"layer4.2.layer2.1.bias\", \"layer4.2.layer2.1.running_mean\", \"layer4.2.layer2.1.running_var\", \"layer4.2.layer2.1.num_batches_tracked\", \"layer4.3.layer1.0.weight\", \"layer4.3.layer1.0.bias\", \"layer4.3.layer1.1.weight\", \"layer4.3.layer1.1.bias\", \"layer4.3.layer1.1.running_mean\", \"layer4.3.layer1.1.running_var\", \"layer4.3.layer1.1.num_batches_tracked\", \"layer4.3.layer2.0.weight\", \"layer4.3.layer2.0.bias\", \"layer4.3.layer2.1.weight\", \"layer4.3.layer2.1.bias\", \"layer4.3.layer2.1.running_mean\", \"layer4.3.layer2.1.running_var\", \"layer4.3.layer2.1.num_batches_tracked\", \"layer4.4.layer1.0.weight\", \"layer4.4.layer1.0.bias\", \"layer4.4.layer1.1.weight\", \"layer4.4.layer1.1.bias\", \"layer4.4.layer1.1.running_mean\", \"layer4.4.layer1.1.running_var\", \"layer4.4.layer1.1.num_batches_tracked\", \"layer4.4.layer2.0.weight\", \"layer4.4.layer2.0.bias\", \"layer4.4.layer2.1.weight\", \"layer4.4.layer2.1.bias\", \"layer4.4.layer2.1.running_mean\", \"layer4.4.layer2.1.running_var\", \"layer4.4.layer2.1.num_batches_tracked\", \"layer4.5.layer1.0.weight\", \"layer4.5.layer1.0.bias\", \"layer4.5.layer1.1.weight\", \"layer4.5.layer1.1.bias\", \"layer4.5.layer1.1.running_mean\", \"layer4.5.layer1.1.running_var\", \"layer4.5.layer1.1.num_batches_tracked\", \"layer4.5.layer2.0.weight\", \"layer4.5.layer2.0.bias\", \"layer4.5.layer2.1.weight\", \"layer4.5.layer2.1.bias\", \"layer4.5.layer2.1.running_mean\", \"layer4.5.layer2.1.running_var\", \"layer4.5.layer2.1.num_batches_tracked\", \"layer5.0.layer1.0.weight\", \"layer5.0.layer1.0.bias\", \"layer5.0.layer1.1.weight\", \"layer5.0.layer1.1.bias\", \"layer5.0.layer1.1.running_mean\", \"layer5.0.layer1.1.running_var\", \"layer5.0.layer1.1.num_batches_tracked\", \"layer5.0.layer2.0.weight\", \"layer5.0.layer2.0.bias\", \"layer5.0.layer2.1.weight\", \"layer5.0.layer2.1.bias\", \"layer5.0.layer2.1.running_mean\", \"layer5.0.layer2.1.running_var\", \"layer5.0.layer2.1.num_batches_tracked\", \"layer5.1.layer1.0.weight\", \"layer5.1.layer1.0.bias\", \"layer5.1.layer1.1.weight\", \"layer5.1.layer1.1.bias\", \"layer5.1.layer1.1.running_mean\", \"layer5.1.layer1.1.running_var\", \"layer5.1.layer1.1.num_batches_tracked\", \"layer5.1.layer2.0.weight\", \"layer5.1.layer2.0.bias\", \"layer5.1.layer2.1.weight\", \"layer5.1.layer2.1.bias\", \"layer5.1.layer2.1.running_mean\", \"layer5.1.layer2.1.running_var\", \"layer5.1.layer2.1.num_batches_tracked\", \"layer5.2.layer1.0.weight\", \"layer5.2.layer1.0.bias\", \"layer5.2.layer1.1.weight\", \"layer5.2.layer1.1.bias\", \"layer5.2.layer1.1.running_mean\", \"layer5.2.layer1.1.running_var\", \"layer5.2.layer1.1.num_batches_tracked\", \"layer5.2.layer2.0.weight\", \"layer5.2.layer2.0.bias\", \"layer5.2.layer2.1.weight\", \"layer5.2.layer2.1.bias\", \"layer5.2.layer2.1.running_mean\", \"layer5.2.layer2.1.running_var\", \"layer5.2.layer2.1.num_batches_tracked\". \n\tsize mismatch for layer3.0.p_layer.weight: copying a param with shape torch.Size([128, 64, 1, 1]) from checkpoint, the shape in current model is torch.Size([512, 256, 1, 1]).\n\tsize mismatch for layer3.0.p_layer.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for layer4.0.p_layer.weight: copying a param with shape torch.Size([256, 128, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 512, 1, 1]).\n\tsize mismatch for layer4.0.p_layer.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for layer5.0.p_layer.weight: copying a param with shape torch.Size([512, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([2048, 1024, 1, 1]).\n\tsize mismatch for layer5.0.p_layer.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for layer6.3.weight: copying a param with shape torch.Size([91, 512]) from checkpoint, the shape in current model is torch.Size([1024, 2048]).\n\tsize mismatch for layer6.3.bias: copying a param with shape torch.Size([91]) from checkpoint, the shape in current model is torch.Size([1024])."
     ]
    }
   ],
   "source": [
    "### MODEL COMPARISONS ###\n",
    "\n",
    "# Load the best model weights\n",
    "model2 = ResNet([2, 3, 5, 2]).to(device)\n",
    "model2.load_state_dict(torch.load(\"checkpoint.pth\", weights_only=True))\n",
    "\n",
    "# Calculate and present final scores\n",
    "final_test_acc = accuracy(model2, test_loader)\n",
    "print(f\"Final Test Accuracy: {final_test_acc:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ecc6f7f921591e",
   "metadata": {},
   "source": [
    "# Summary of hyperparameters\n",
    "Report the hyperparameters ( learning rate etc ) that you used in your final model for reproducibility."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b6a524e28b431a",
   "metadata": {},
   "source": [
    "# Simulation of random user\n",
    "Pick 10 random pictures of the test set to simulate a user uploading images and report which categories occur how often in these: 1pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b6e8175cacc8dfe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-02T17:04:06.539916Z",
     "start_time": "2025-04-02T17:04:05.929092Z"
    },
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Your code here\n",
    "# Below an example showing the format of the code output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e7a3634bf6861f",
   "metadata": {},
   "source": [
    "# Bonus point\n",
    "Use an LLM (API) to generate a description of the food preference of a user based on 10 images that a potential user could provide. \n",
    "Please include an example of the output of your code, especially if you used an API other than the OpenAI API.\n",
    "\n",
    "This should work well even with differing test images by setting different random seeds for the image selector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6819fa0042485dae",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IPy1",
   "language": "python",
   "name": "ipy1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
